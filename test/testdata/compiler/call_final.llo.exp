; ModuleID = 'payload'
source_filename = "compiler/IREmitter/Payload/payload.c"
target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.1, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.1 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.RBasic = type { i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%union.anon.0 = type { i64 }
%struct.OnigEncodingTypeST = type { i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i8*, i32, i32, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8**, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i32 (i32, i32*, i32, i8*)*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, i8*, %struct.OnigCaseFoldCodeItem*, %struct.OnigEncodingTypeST*)*, i32 (%struct.OnigEncodingTypeST*, i8*, i8*)*, i32 (i32, i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i32*, i32**, %struct.OnigEncodingTypeST*)*, i8* (i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32*, i8**, i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32, i32 }
%struct.OnigCaseFoldCodeItem = type { i32, i32, [3 x i32] }
%struct.RTypedData = type { %struct.RBasic, %struct.rb_data_type_struct*, i64, i8* }
%struct.sorbet_Closure = type { i32, [0 x i64] }

@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@rb_cObject = external local_unnamed_addr constant i64, align 8
@ruby_vm_global_constant_state = external local_unnamed_addr global i64, align 8
@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@.str.1 = private unnamed_addr constant [29 x i8] c"wrong constant name %li\0B%li\0B\00", align 1
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.2 = private unnamed_addr constant [36 x i8] c"%li\0B does not refer to class/module\00", align 1
@sorbet_getConstantAt.rb_intern_id_cache = internal unnamed_addr global i64 0, align 8
@.str.3 = private unnamed_addr constant [14 x i8] c"const_missing\00", align 1
@.str.4 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.7 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@.str.8 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@closureInfo = constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.8, i32 0, i32 0), %struct.anon.1 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@rb_cData = external local_unnamed_addr constant i64, align 8
@rb_cModule = external local_unnamed_addr constant i64, align 8
@"rubyIdPrecomputed_<static-init>" = internal unnamed_addr global i64 0, align 8
@"str_<static-init>" = private unnamed_addr constant [14 x i8] c"<static-init>\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@str_A = private unnamed_addr constant [2 x i8] c"A\00", align 1
@str_B = private unnamed_addr constant [2 x i8] c"B\00", align 1
@str_sig = private unnamed_addr constant [4 x i8] c"sig\00", align 1
@str_Integer = private unnamed_addr constant [8 x i8] c"Integer\00", align 1
@rubyIdPrecomputed_foo = internal unnamed_addr global i64 0, align 8
@str_foo = private unnamed_addr constant [4 x i8] c"foo\00", align 1
@"str_T.class_of(A)" = private unnamed_addr constant [14 x i8] c"T.class_of(A)\00", align 1
@rubyIdPrecomputed_final = internal unnamed_addr global i64 0, align 8
@str_final = private unnamed_addr constant [6 x i8] c"final\00", align 1
@rubyIdPrecomputed_sig = internal unnamed_addr global i64 0, align 8
@"str_T::Sig::WithoutRuntime" = private unnamed_addr constant [23 x i8] c"T::Sig::WithoutRuntime\00", align 1
@rubyIdPrecomputed_n = internal unnamed_addr global i64 0, align 8
@str_n = private unnamed_addr constant [2 x i8] c"n\00", align 1
@rubyIdPrecomputed_params = internal unnamed_addr global i64 0, align 8
@str_params = private unnamed_addr constant [7 x i8] c"params\00", align 1
@rubyIdPrecomputed_returns = internal unnamed_addr global i64 0, align 8
@str_returns = private unnamed_addr constant [8 x i8] c"returns\00", align 1
@rubyIdPrecomputed_caller = internal unnamed_addr global i64 0, align 8
@str_caller = private unnamed_addr constant [7 x i8] c"caller\00", align 1
@llvm.global_ctors = appending global [9 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<static-init>", i8* bitcast (i64* @"rubyIdPrecomputed_<static-init>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_foo, i8* bitcast (i64* @rubyIdPrecomputed_foo to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_final, i8* bitcast (i64* @rubyIdPrecomputed_final to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_sig, i8* bitcast (i64* @rubyIdPrecomputed_sig to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_n, i8* bitcast (i64* @rubyIdPrecomputed_n to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_params, i8* bitcast (i64* @rubyIdPrecomputed_params to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_returns, i8* bitcast (i64* @rubyIdPrecomputed_returns to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_caller, i8* bitcast (i64* @rubyIdPrecomputed_caller to i8*) }]
@guard_epoch_A = linkonce local_unnamed_addr global i64 0
@guarded_const_A = linkonce local_unnamed_addr global i64 0
@"guard_epoch_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@"guarded_const_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@guard_epoch_B = linkonce local_unnamed_addr global i64 0
@guarded_const_B = linkonce local_unnamed_addr global i64 0
@rb_cInteger = external local_unnamed_addr constant i64

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i8* @rb_id2name(i64 %0) #18
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #18
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !0
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #18
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !5
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #1

declare i64 @rb_hash_new() local_unnamed_addr #1

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #1

declare i64 @rb_id2sym(i64) local_unnamed_addr #1

declare i8* @rb_obj_classname(i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstantAt(i64 %0, i64 %1) unnamed_addr #2 {
  %3 = tail call i64 @rb_id2sym(i64 %1) #18
  %4 = tail call %struct.OnigEncodingTypeST* @rb_enc_get(i64 %3) #18
  %5 = tail call i8* @rb_id2name(i64 %1) #18
  %6 = tail call i64 @strlen(i8* nonnull dereferenceable(1) %5)
  %7 = getelementptr inbounds i8, i8* %5, i64 %6
  %8 = icmp sgt i64 %6, 0
  br i1 %8, label %9, label %.loopexit11

9:                                                ; preds = %2
  %10 = ptrtoint i8* %5 to i64
  br label %13

.loopexit10:                                      ; preds = %91, %44, %41, %28, %107
  %11 = phi i64 [ %108, %107 ], [ %3, %28 ], [ %3, %44 ], [ %3, %41 ], [ %66, %91 ]
  %12 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %12, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.1, i64 0, i64 0), i64 %14, i64 %11) #19
  unreachable

13:                                               ; preds = %115, %9
  %14 = phi i64 [ %0, %9 ], [ %116, %115 ]
  %15 = phi i8* [ %5, %9 ], [ %50, %115 ]
  %16 = phi i8* [ %5, %9 ], [ %49, %115 ]
  %17 = icmp ult i8* %16, %7
  br i1 %17, label %18, label %28

18:                                               ; preds = %13
  %19 = load i8, i8* %16, align 1, !tbaa !5
  %20 = icmp eq i8 %19, 58
  br i1 %20, label %28, label %.preheader

21:                                               ; preds = %.preheader
  %22 = load i8, i8* %25, align 1, !tbaa !5
  %23 = icmp eq i8 %22, 58
  br i1 %23, label %.loopexit, label %.preheader

.preheader:                                       ; preds = %18, %21
  %24 = phi i8* [ %25, %21 ], [ %16, %18 ]
  %25 = getelementptr inbounds i8, i8* %24, i64 1
  %26 = icmp eq i8* %25, %7
  br i1 %26, label %.loopexit, label %21

.loopexit:                                        ; preds = %21, %.preheader
  %.lcssa = phi i8* [ %25, %21 ], [ %7, %.preheader ]
  %27 = icmp ult i8* %.lcssa, %7
  br label %28

28:                                               ; preds = %.loopexit, %18, %13
  %29 = phi i8* [ %16, %13 ], [ %16, %18 ], [ %.lcssa, %.loopexit ]
  %30 = phi i1 [ false, %13 ], [ true, %18 ], [ %27, %.loopexit ]
  %31 = icmp eq i8* %15, %29
  br i1 %31, label %.loopexit10, label %32

32:                                               ; preds = %28
  %33 = ptrtoint i8* %29 to i64
  %34 = ptrtoint i8* %15 to i64
  %35 = sub i64 %33, %34
  %36 = tail call i64 @rb_check_id_cstr(i8* %15, i64 %35, %struct.OnigEncodingTypeST* %4) #18
  %37 = sub i64 %34, %10
  br i1 %30, label %38, label %48

38:                                               ; preds = %32
  %39 = load i8, i8* %29, align 1, !tbaa !5
  %40 = icmp eq i8 %39, 58
  br i1 %40, label %41, label %48

41:                                               ; preds = %38
  %42 = getelementptr inbounds i8, i8* %29, i64 2
  %43 = icmp ult i8* %42, %7
  br i1 %43, label %44, label %.loopexit10

44:                                               ; preds = %41
  %45 = getelementptr inbounds i8, i8* %29, i64 1
  %46 = load i8, i8* %45, align 1, !tbaa !5
  %47 = icmp eq i8 %46, 58
  br i1 %47, label %48, label %.loopexit10

48:                                               ; preds = %44, %38, %32
  %49 = phi i8* [ %29, %38 ], [ %29, %32 ], [ %42, %44 ]
  %50 = phi i8* [ %15, %38 ], [ %15, %32 ], [ %42, %44 ]
  %51 = and i64 %14, 7
  %52 = icmp ne i64 %51, 0
  %53 = and i64 %14, -9
  %54 = icmp eq i64 %53, 0
  %55 = or i1 %52, %54
  br i1 %55, label %61, label %56

56:                                               ; preds = %48
  %57 = inttoptr i64 %14 to %struct.RBasic*
  %58 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 0
  %59 = load i64, i64* %58, align 8, !tbaa !0
  %60 = and i64 %59, 30
  %switch = icmp eq i64 %60, 2
  br i1 %switch, label %63, label %61

61:                                               ; preds = %56, %48
  %62 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %62, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.2, i64 0, i64 0), i64 %3) #19
  unreachable

63:                                               ; preds = %56
  %64 = icmp eq i64 %36, 0
  br i1 %64, label %65, label %104

65:                                               ; preds = %63
  %66 = tail call i64 @rb_str_subseq(i64 %3, i64 %37, i64 %35) #18
  %67 = and i64 %66, 7
  %68 = icmp ne i64 %67, 0
  %69 = and i64 %66, -9
  %70 = icmp eq i64 %69, 0
  %71 = or i1 %68, %70
  br i1 %71, label %rb_obj_freeze_inline.exit, label %72

72:                                               ; preds = %65
  %73 = inttoptr i64 %66 to %struct.RBasic*
  %74 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 0
  %75 = load i64, i64* %74, align 8, !tbaa !0
  %76 = and i64 %75, 31
  %77 = icmp eq i64 %76, 27
  br i1 %77, label %rb_obj_freeze_inline.exit, label %78

78:                                               ; preds = %72
  %79 = or i64 %75, 2048
  store i64 %79, i64* %74, align 8, !tbaa !0
  %80 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 1
  %81 = load i64, i64* %80, align 8, !tbaa !7
  %82 = icmp ne i64 %81, 0
  %83 = and i64 %75, 4096
  %84 = icmp eq i64 %83, 0
  %85 = and i1 %84, %82
  br i1 %85, label %86, label %rb_obj_freeze_inline.exit

86:                                               ; preds = %78
  tail call void @rb_freeze_singleton_class(i64 %66) #18
  br label %rb_obj_freeze_inline.exit

rb_obj_freeze_inline.exit:                        ; preds = %65, %72, %78, %86
  %87 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %89, label %91

89:                                               ; preds = %rb_obj_freeze_inline.exit
  %90 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.3, i64 0, i64 0), i64 13) #18
  store i64 %90, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  br label %91

91:                                               ; preds = %89, %rb_obj_freeze_inline.exit
  %92 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %93 = tail call i32 @rb_is_const_name(i64 %66) #18
  %94 = icmp eq i32 %93, 0
  br i1 %94, label %.loopexit10, label %rb_class_of.exit

rb_class_of.exit:                                 ; preds = %91
  %95 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 1
  %96 = load i64, i64* %95, align 8, !tbaa !6
  %97 = tail call i32 @rb_method_basic_definition_p(i64 %96, i64 %92) #18
  %98 = icmp eq i32 %97, 0
  br i1 %98, label %99, label %102

99:                                               ; preds = %rb_class_of.exit
  %100 = tail call i64 @rb_str_intern(i64 %66) #18
  %101 = tail call i64 @rb_const_missing(i64 %14, i64 %100) #18
  br label %115

102:                                              ; preds = %rb_class_of.exit
  %103 = tail call i64 @rb_mod_const_missing(i64 %14, i64 %66) #19
  unreachable

104:                                              ; preds = %63
  %105 = tail call i32 @rb_is_const_id(i64 %36) #5
  %106 = icmp eq i32 %105, 0
  br i1 %106, label %107, label %109

107:                                              ; preds = %104
  %108 = tail call i64 @rb_id2sym(i64 %36) #18
  br label %.loopexit10

109:                                              ; preds = %104
  %110 = icmp eq i64 %37, 0
  br i1 %110, label %111, label %113

111:                                              ; preds = %109
  %112 = tail call i64 @rb_const_get(i64 %14, i64 %36) #18
  br label %115

113:                                              ; preds = %109
  %114 = tail call i64 @rb_const_get_from(i64 %14, i64 %36) #18
  br label %115

115:                                              ; preds = %113, %111, %99
  %116 = phi i64 [ %101, %99 ], [ %112, %111 ], [ %114, %113 ]
  %117 = icmp ult i8* %49, %7
  br i1 %117, label %13, label %.loopexit11

.loopexit11:                                      ; preds = %115, %2
  %118 = phi i64 [ %0, %2 ], [ %116, %115 ]
  ret i64 %118
}

declare %struct.OnigEncodingTypeST* @rb_enc_get(i64) local_unnamed_addr #1

; Function Attrs: argmemonly nofree nounwind readonly
declare i64 @strlen(i8* nocapture) local_unnamed_addr #3

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #4

declare i64 @rb_check_id_cstr(i8*, i64, %struct.OnigEncodingTypeST*) local_unnamed_addr #1

declare i64 @rb_str_subseq(i64, i64, i64) local_unnamed_addr #1

declare i32 @rb_is_const_name(i64) local_unnamed_addr #1

declare i32 @rb_method_basic_definition_p(i64, i64) local_unnamed_addr #1

declare i64 @rb_str_intern(i64) local_unnamed_addr #1

declare i64 @rb_const_missing(i64, i64) local_unnamed_addr #1

; Function Attrs: noreturn
declare i64 @rb_mod_const_missing(i64, i64) local_unnamed_addr #4

; Function Attrs: nounwind readnone
declare i32 @rb_is_const_id(i64) local_unnamed_addr #5

declare i64 @rb_const_get(i64, i64) local_unnamed_addr #1

declare i64 @rb_const_get_from(i64, i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstant(i8* %0, i64 %1) unnamed_addr #2 {
  %3 = load i64, i64* @rb_cObject, align 8, !tbaa !6
  %4 = tail call i64 @rb_intern2(i8* %0, i64 %1) #18
  %5 = tail call fastcc i64 @sorbet_getConstantAt(i64 %3, i64 %4)
  ret i64 %5
}

declare i64 @rb_define_class(i8*, i64) local_unnamed_addr #1

declare void @rb_define_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #1

declare void @rb_define_singleton_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #1

declare i64 @rb_funcallv(i64, i64, i32, i64*) local_unnamed_addr #1

declare i64 @rb_block_call(i64, i64, i32, i64*, i64 (...)*, i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32 %0) unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.4, i64 0, i64 0), i32 %0, i32 1) #18
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !6
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #18
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #1

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64 %0, i8* %1, i8* %2) unnamed_addr #6 {
  %4 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  %5 = tail call i8* @rb_obj_classname(i64 %0) #18
  tail call void (i64, i8*, ...) @rb_raise(i64 %4, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.7, i64 0, i64 0), i8* %1, i8* %2, i8* %5, i64 %0) #19
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_raiseArity(i32 %0) unnamed_addr #7 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #19
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #4

; Function Attrs: inaccessiblememonly
declare i32 @ruby_stack_check() local_unnamed_addr #8

declare i8* @ruby_xmalloc(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8* %0) #0 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #18
  ret void
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #1

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly %0) #9 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

declare i64 @rb_data_typed_object_wrap(i64, i8*, %struct.rb_data_type_struct*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #5

; Function Attrs: nounwind readnone
declare i64 @rb_class_inherited_p(i64, i64) local_unnamed_addr #5

declare void @rb_hash_bulk_insert(i64, i64*, i64) local_unnamed_addr #1

declare void @rb_ary_detransient(i64) local_unnamed_addr #1

declare void @rb_freeze_singleton_class(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<static-init>"() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_<static-init>", i64 0, i64 0), i64 13) #18
  store i64 %0, i64* @"rubyIdPrecomputed_<static-init>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #18
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_compiler_call_final() local_unnamed_addr #11 {
afterSymCallIntrinsic_unsafe.i:
  %callArgs.i.i.i = alloca [2 x i64], align 8
  %0 = load i64, i64* @rb_cObject, align 8
  %1 = tail call i64 @rb_define_class(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_A, i64 0, i64 0), i64 %0) #18
  %2 = load i64, i64* @guard_epoch_A, align 8
  %3 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath = icmp eq i64 %2, %3
  br i1 %needTakeSlowPath, label %5, label %4, !prof !12

4:                                                ; preds = %afterSymCallIntrinsic_unsafe.i
  tail call void @const_recompute_A() #18
  br label %5

5:                                                ; preds = %afterSymCallIntrinsic_unsafe.i, %4
  %6 = load i64, i64* @guarded_const_A, align 8
  %7 = load i64, i64* @guard_epoch_A, align 8
  %8 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated = icmp eq i64 %7, %8
  tail call void @llvm.assume(i1 %guardUpdated)
  %9 = bitcast [2 x i64]* %callArgs.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #18
  %10 = tail call i8* @ruby_xmalloc(i64 16) #18
  %11 = bitcast i8* %10 to i32*
  store i32 1, i32* %11, align 8, !tbaa !8
  %12 = load i64, i64* @rb_cData, align 8, !tbaa !6
  %13 = tail call i64 @rb_data_typed_object_wrap(i64 %12, i8* %10, %struct.rb_data_type_struct* nonnull @closureInfo) #18
  %14 = inttoptr i64 %13 to %struct.RTypedData*
  %15 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %14, i64 0, i32 3
  %16 = bitcast i8** %15 to %struct.sorbet_Closure**
  %17 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %16, align 8, !tbaa !13
  %18 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %17, i64 0, i32 1, i64 0
  store i64 8, i64* %18, align 8
  %rubyId_final.i.i.i = load i64, i64* @rubyIdPrecomputed_final, align 8
  %rubyId_sig.i.i.i = load i64, i64* @rubyIdPrecomputed_sig, align 8
  %rubyId_foo.i.i.i = load i64, i64* @rubyIdPrecomputed_foo, align 8
  %19 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %16, align 8, !tbaa !13
  %20 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %19, i64 0, i32 1, i64 0
  store i64 %6, i64* %20, align 8
  %21 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %16, align 8, !tbaa !13
  %22 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %21, i64 0, i32 1, i64 0
  %23 = load i64, i64* %22, align 8
  %24 = icmp eq i64 %23, %6
  br i1 %24, label %"func_<root>.<static-init>$111.exit", label %25

25:                                               ; preds = %5
  %26 = load i64, i64* @rb_cModule, align 8, !tbaa !6
  %27 = tail call i64 @rb_obj_is_kind_of(i64 %23, i64 %26) #5
  %28 = icmp eq i64 %27, 0
  br i1 %28, label %codeRepl, label %sorbet_isa_class_of.exit.i.i.i, !prof !16

sorbet_isa_class_of.exit.i.i.i:                   ; preds = %25
  %29 = tail call i64 @rb_class_inherited_p(i64 %23, i64 %6) #5
  %30 = icmp eq i64 %29, 0
  br i1 %30, label %codeRepl, label %"func_<root>.<static-init>$111.exit", !prof !17, !misexpect !18

codeRepl:                                         ; preds = %25, %sorbet_isa_class_of.exit.i.i.i
  tail call fastcc void @Init_test_testdata_compiler_call_final.cold.1(i64 %23) #20
  unreachable

"func_<root>.<static-init>$111.exit":             ; preds = %5, %sorbet_isa_class_of.exit.i.i.i
  %rawSym.i.i.i = tail call i64 @rb_id2sym(i64 %rubyId_final.i.i.i) #18
  %callArgsAddr.i.i.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i.i.i, i64 0, i64 0
  store i64 %rawSym.i.i.i, i64* %callArgsAddr.i.i.i, align 8
  %31 = load i64, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  %32 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath6 = icmp eq i64 %31, %32
  br i1 %needTakeSlowPath6, label %34, label %33, !prof !12

33:                                               ; preds = %"func_<root>.<static-init>$111.exit"
  tail call void @"const_recompute_T::Sig::WithoutRuntime"() #18
  br label %34

34:                                               ; preds = %"func_<root>.<static-init>$111.exit", %33
  %35 = load i64, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  %36 = load i64, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  %37 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated7 = icmp eq i64 %36, %37
  tail call void @llvm.assume(i1 %guardUpdated7)
  %38 = call i64 @rb_block_call(i64 %35, i64 %rubyId_sig.i.i.i, i32 1, i64* nonnull %callArgsAddr.i.i.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_A.<static-init>$block_1" to i64 (...)*), i64 %13) #18
  store i64 %0, i64* %callArgsAddr.i.i.i, align 8
  %rawSym31.i.i.i = call i64 @rb_id2sym(i64 %rubyId_foo.i.i.i) #18
  call void @rb_define_singleton_method(i64 %6, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @func_A.foo to i64 (...)*), i32 -1) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #18
  %39 = call i64 @rb_define_class(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_B, i64 0, i64 0), i64 %0) #18
  %40 = load i64, i64* @guard_epoch_B, align 8
  %41 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath8 = icmp eq i64 %40, %41
  br i1 %needTakeSlowPath8, label %43, label %42, !prof !12

42:                                               ; preds = %34
  call void @const_recompute_B() #18
  br label %43

43:                                               ; preds = %34, %42
  %44 = load i64, i64* @guarded_const_B, align 8
  %45 = load i64, i64* @guard_epoch_B, align 8
  %46 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated9 = icmp eq i64 %45, %46
  call void @llvm.assume(i1 %guardUpdated9)
  %rubyId_caller.i.i.i = load i64, i64* @rubyIdPrecomputed_caller, align 8
  %rawSym.i.i1.i = call i64 @rb_id2sym(i64 %rubyId_caller.i.i.i) #18
  call void @rb_define_method(i64 %44, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_caller, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_B#caller" to i64 (...)*), i32 -1) #18
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @func_A.foo(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #12 {
functionEntryInitializers:
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !19, !misexpect !20

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %rawArg_n = load i64, i64* %argArray, align 8
  %1 = and i64 %rawArg_n, 1
  %2 = icmp eq i64 %1, 0
  br i1 %2, label %codeRepl, label %typeTestSuccess7, !prof !17, !misexpect !18

codeRepl:                                         ; preds = %fillRequiredArgs
  tail call fastcc void @func_A.foo.cold.1(i64 %rawArg_n) #20
  unreachable

typeTestSuccess7:                                 ; preds = %fillRequiredArgs
  %3 = load i64, i64* @guard_epoch_A, align 8
  %4 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath = icmp eq i64 %3, %4
  br i1 %needTakeSlowPath, label %6, label %5, !prof !12

5:                                                ; preds = %typeTestSuccess7
  tail call void @const_recompute_A() #18
  br label %6

6:                                                ; preds = %typeTestSuccess7, %5
  %7 = load i64, i64* @guarded_const_A, align 8
  %8 = load i64, i64* @guard_epoch_A, align 8
  %9 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated = icmp eq i64 %8, %9
  tail call void @llvm.assume(i1 %guardUpdated)
  %10 = icmp eq i64 %7, %selfRaw
  br i1 %10, label %typeTestSuccess10, label %11

11:                                               ; preds = %6
  %12 = load i64, i64* @rb_cModule, align 8, !tbaa !6
  %13 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %12) #5
  %14 = icmp eq i64 %13, 0
  br i1 %14, label %codeRepl18, label %sorbet_isa_class_of.exit, !prof !16

sorbet_isa_class_of.exit:                         ; preds = %11
  %15 = tail call i64 @rb_class_inherited_p(i64 %selfRaw, i64 %7) #5
  %16 = icmp eq i64 %15, 0
  br i1 %16, label %codeRepl18, label %typeTestSuccess10, !prof !17, !misexpect !18

typeTestSuccess10:                                ; preds = %sorbet_isa_class_of.exit, %6
  ret i64 %rawArg_n

codeRepl18:                                       ; preds = %11, %sorbet_isa_class_of.exit
  tail call fastcc void @func_A.foo.cold.2(i64 %selfRaw) #20
  unreachable
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_foo() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 3) #18
  store i64 %0, i64* @rubyIdPrecomputed_foo, align 8
  ret void
}

; Function Attrs: ssp
define internal i64 @"func_A.<static-init>$block_1"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readonly %argArray, i64 %blockArg) #13 {
functionEntryInitializers:
  %callArgs = alloca [2 x i64], align 8
  %rubyId_n = load i64, i64* @rubyIdPrecomputed_n, align 8
  %rubyId_params = load i64, i64* @rubyIdPrecomputed_params, align 8
  %rubyId_returns = load i64, i64* @rubyIdPrecomputed_returns, align 8
  %arrayExpansionSizeGuard = icmp eq i32 %argc, 1
  br i1 %arrayExpansionSizeGuard, label %argArrayExpandArrayTest, label %fillRequiredArgs

argArrayExpandArrayTest:                          ; preds = %functionEntryInitializers
  %arg1_maybeExpandToFullArgs = load i64, i64* %argArray, align 8
  %0 = and i64 %arg1_maybeExpandToFullArgs, 7
  %1 = icmp ne i64 %0, 0
  %2 = and i64 %arg1_maybeExpandToFullArgs, -9
  %3 = icmp eq i64 %2, 0
  %4 = or i1 %1, %3
  br i1 %4, label %fillRequiredArgs, label %sorbet_isa_Array.exit

sorbet_isa_Array.exit:                            ; preds = %argArrayExpandArrayTest
  %5 = inttoptr i64 %arg1_maybeExpandToFullArgs to %struct.RBasic*
  %6 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %5, i64 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !0
  %8 = and i64 %7, 33554463
  %9 = icmp eq i64 %8, 33554439
  br i1 %9, label %10, label %fillRequiredArgs

10:                                               ; preds = %sorbet_isa_Array.exit
  tail call void @rb_ary_detransient(i64 %arg1_maybeExpandToFullArgs) #18
  br label %fillRequiredArgs

fillRequiredArgs:                                 ; preds = %sorbet_isa_Array.exit, %argArrayExpandArrayTest, %10, %functionEntryInitializers
  %rawSym = tail call i64 @rb_id2sym(i64 %rubyId_n)
  %callArgsAddr = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 0
  store i64 %rawSym, i64* %callArgsAddr, align 8
  %11 = load i64, i64* @rb_cInteger, align 8
  %callArgsAddr12 = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 1
  store i64 %11, i64* %callArgsAddr12, align 8
  %12 = tail call i64 @rb_hash_new() #18, !noalias !21
  call void @rb_hash_bulk_insert(i64 2, i64* nonnull %callArgsAddr, i64 %12) #18
  store i64 %12, i64* %callArgsAddr, align 8
  %13 = inttoptr i64 %captures to %struct.RTypedData*
  %14 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %13, i64 0, i32 3
  %15 = bitcast i8** %14 to %struct.sorbet_Closure**
  %16 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %15, align 8, !tbaa !13
  %17 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %16, i64 0, i32 1, i64 0
  %18 = load i64, i64* %17, align 8
  %19 = call i64 @rb_funcallv(i64 %18, i64 %rubyId_params, i32 1, i64* nonnull %callArgsAddr) #18
  store i64 %11, i64* %callArgsAddr, align 8
  %20 = call i64 @rb_funcallv(i64 %19, i64 %rubyId_returns, i32 1, i64* nonnull %callArgsAddr) #18
  ret i64 %20
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_final() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_final, i64 0, i64 0), i64 5) #18
  store i64 %0, i64* @rubyIdPrecomputed_final, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_sig() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i64 3) #18
  store i64 %0, i64* @rubyIdPrecomputed_sig, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_n() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_n, i64 0, i64 0), i64 1) #18
  store i64 %0, i64* @rubyIdPrecomputed_n, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_params() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_params, i64 0, i64 0), i64 6) #18
  store i64 %0, i64* @rubyIdPrecomputed_params, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_returns() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_returns, i64 0, i64 0), i64 7) #18
  store i64 %0, i64* @rubyIdPrecomputed_returns, align 8
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_B#caller"(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #12 {
functionEntryInitializers:
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !19, !misexpect !20

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %1 = load i64, i64* @guard_epoch_B, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath = icmp eq i64 %1, %2
  br i1 %needTakeSlowPath, label %4, label %3, !prof !12

3:                                                ; preds = %fillRequiredArgs
  tail call void @const_recompute_B() #18
  br label %4

4:                                                ; preds = %fillRequiredArgs, %3
  %5 = load i64, i64* @guarded_const_B, align 8
  %6 = load i64, i64* @guard_epoch_B, align 8
  %7 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated = icmp eq i64 %6, %7
  tail call void @llvm.assume(i1 %guardUpdated)
  %8 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %5) #5
  %9 = icmp eq i64 %8, 20
  br i1 %9, label %fastCallFinal_foo, label %codeRepl17, !prof !24, !misexpect !18

codeRepl17:                                       ; preds = %4
  tail call fastcc void @"func_B#caller.cold.2"(i64 %selfRaw) #20
  unreachable

afterCallFinal_foo:                               ; preds = %fastCallFinal_foo
  ret i64 %rawArg_a

fastCallFinal_foo:                                ; preds = %4
  %rawArg_a = load i64, i64* %argArray, align 8
  %10 = tail call i32 @ruby_stack_check() #18
  %11 = and i64 %rawArg_a, 1
  %12 = icmp eq i64 %11, 0
  br i1 %12, label %codeRepl, label %afterCallFinal_foo, !prof !17, !misexpect !18

codeRepl:                                         ; preds = %fastCallFinal_foo
  tail call fastcc void @"func_B#caller.cold.1"(i64 %rawArg_a) #20
  unreachable
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_caller() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_caller, i64 0, i64 0), i64 6) #18
  store i64 %0, i64* @rubyIdPrecomputed_caller, align 8
  ret void
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #14

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #14

; Function Attrs: cold minsize noreturn nounwind sspreq
define internal fastcc void @Init_test_testdata_compiler_call_final.cold.1(i64 %0) unnamed_addr #15 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_T.class_of(A)", i64 0, i64 0)) #18
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_A.foo.cold.1(i64 %rawArg_n) unnamed_addr #16 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %rawArg_n, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_Integer, i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_A.foo.cold.2(i64 %selfRaw) unnamed_addr #16 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_T.class_of(A)", i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_B#caller.cold.1"(i64 %rawArg_a) unnamed_addr #16 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %rawArg_a, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_Integer, i64 0, i64 0)) #18
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_B#caller.cold.2"(i64 %selfRaw) unnamed_addr #16 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_B, i64 0, i64 0))
  unreachable
}

; Function Attrs: nounwind willreturn
declare void @llvm.assume(i1) #17

; Function Attrs: ssp
define linkonce void @const_recompute_A() local_unnamed_addr #13 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_A, i64 0, i64 0), i64 1)
  store i64 %1, i64* @guarded_const_A, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  store i64 %2, i64* @guard_epoch_A, align 8
  ret void
}

; Function Attrs: ssp
define linkonce void @"const_recompute_T::Sig::WithoutRuntime"() local_unnamed_addr #13 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([23 x i8], [23 x i8]* @"str_T::Sig::WithoutRuntime", i64 0, i64 0), i64 22)
  store i64 %1, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  store i64 %2, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  ret void
}

; Function Attrs: ssp
define linkonce void @const_recompute_B() local_unnamed_addr #13 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_B, i64 0, i64 0), i64 1)
  store i64 %1, i64* @guarded_const_B, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  store i64 %2, i64* @guard_epoch_B, align 8
  ret void
}

attributes #0 = { nounwind ssp uwtable }
attributes #1 = { "addedToSilenceEmptyAttrsError" }
attributes #2 = { noinline nounwind ssp uwtable }
attributes #3 = { argmemonly nofree nounwind readonly }
attributes #4 = { noreturn }
attributes #5 = { nounwind readnone }
attributes #6 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #7 = { noreturn nounwind ssp uwtable }
attributes #8 = { inaccessiblememonly "addedToSilenceEmptyAttrsError" }
attributes #9 = { norecurse nounwind readnone ssp uwtable }
attributes #10 = { nounwind ssp }
attributes #11 = { nounwind sspreq }
attributes #12 = { nounwind sspreq uwtable }
attributes #13 = { ssp }
attributes #14 = { argmemonly nounwind willreturn }
attributes #15 = { cold minsize noreturn nounwind sspreq }
attributes #16 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #17 = { nounwind willreturn }
attributes #18 = { nounwind }
attributes #19 = { noreturn nounwind }
attributes #20 = { noinline }

!0 = !{!1, !2, i64 0}
!1 = !{!"RBasic", !2, i64 0, !2, i64 8}
!2 = !{!"long", !3, i64 0}
!3 = !{!"omnipotent char", !4, i64 0}
!4 = !{!"Simple C/C++ TBAA"}
!5 = !{!3, !3, i64 0}
!6 = !{!2, !2, i64 0}
!7 = !{!1, !2, i64 8}
!8 = !{!9, !9, i64 0}
!9 = !{!"int", !3, i64 0}
!10 = !{!11, !11, i64 0}
!11 = !{!"long long", !3, i64 0}
!12 = !{!"branch_weights", i32 10000, i32 1}
!13 = !{!14, !15, i64 32}
!14 = !{!"RTypedData", !1, i64 0, !15, i64 16, !2, i64 24, !15, i64 32}
!15 = !{!"any pointer", !3, i64 0}
!16 = !{!"branch_weights", i32 1073205, i32 2146410443}
!17 = !{!"branch_weights", i32 1, i32 2000}
!18 = !{!"misexpect", i64 0, i64 2000, i64 1}
!19 = !{!"branch_weights", i32 4000000, i32 4001}
!20 = !{!"misexpect", i64 1, i64 2000, i64 1}
!21 = !{!22}
!22 = distinct !{!22, !23, !"sorbet_buildHashIntrinsic: argument 0"}
!23 = distinct !{!23, !"sorbet_buildHashIntrinsic"}
!24 = !{!"branch_weights", i32 2000, i32 1}
