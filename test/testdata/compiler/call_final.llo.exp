; ModuleID = 'payload'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_vm_struct = type { i64, %struct.rb_global_vm_lock_struct, %struct.rb_thread_struct*, %struct.rb_thread_struct*, i8*, i64, %union.pthread_mutex_t, %union.anon.12, %union.anon.12, %union.anon.12, %union.anon.12, i64, i32, i8, i32, i64, [5 x i64], i64, i64, i64, i64, i64, i64, i64, %struct.st_table*, %struct.st_table*, %struct.anon.18, %struct.rb_hook_list_struct, %struct.st_table*, %struct.rb_postponed_job_struct*, i32, i32, %union.anon.12, %union.pthread_mutex_t, i64, i64, i64, i64, i64, i32, i64, %struct.rb_objspace*, %struct.rb_at_exit_list*, i64*, %struct.st_table*, %struct.anon.19, [28 x i16] }
%struct.rb_global_vm_lock_struct = type { %struct.rb_thread_struct*, %union.pthread_mutex_t, %union.anon.12, %struct.rb_thread_struct*, i32, %union.pthread_cond_t, %union.pthread_cond_t, i32, i32 }
%union.pthread_cond_t = type { %struct.anon.14 }
%struct.anon.14 = type { i32, i32, i64, i64, i64, i8*, i32, i32 }
%struct.rb_thread_struct = type { %struct.list_node, i64, %struct.rb_vm_struct*, %struct.rb_execution_context_struct*, i64, %struct.rb_calling_info*, i64, i64, i64, i8, i8, i32, %struct.native_thread_data_struct, i8*, i64, i64, i64, i64, %union.pthread_mutex_t, %struct.rb_unblock_callback, i64, %struct.rb_mutex_struct*, %struct.rb_thread_list_struct*, %union.anon.15, i32, i64, %struct.rb_fiber_struct*, [1 x %struct.__jmp_buf_tag], i64 }
%struct.list_node = type { %struct.list_node*, %struct.list_node* }
%struct.rb_execution_context_struct = type { i64*, i64, %struct.rb_control_frame_struct*, %struct.rb_vm_tag*, %struct.rb_vm_protect_tag*, i32, i32, %struct.rb_fiber_struct*, %struct.rb_thread_struct*, %struct.st_table*, i64, i64, i64*, i64, %struct.rb_ensure_list*, %struct.rb_trace_arg_struct*, i64, i64, i8, i8, i64, %struct.anon.11 }
%struct.rb_control_frame_struct = type { i64*, i64*, %struct.rb_iseq_struct*, i64, i64*, i8*, i64* }
%struct.rb_iseq_struct = type { i64, i64, %struct.rb_iseq_constant_body*, %union.anon.8 }
%struct.rb_iseq_constant_body = type { i32, i32, i64*, %struct.anon.1, %struct.rb_iseq_location_struct, %struct.iseq_insn_info, i64*, %struct.iseq_catch_table*, %struct.rb_iseq_struct*, %struct.rb_iseq_struct*, %union.iseq_inline_storage_entry*, %struct.rb_call_info*, %struct.rb_call_cache*, %struct.anon.7, i32, i32, i32, i32, i32, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*)*, i64, %struct.rb_mjit_unit*, i8 }
%struct.anon.1 = type { %struct.anon.2, i32, i32, i32, i32, i32, i32, i32, i64*, %struct.rb_iseq_param_keyword* }
%struct.anon.2 = type { i8, [3 x i8] }
%struct.rb_iseq_param_keyword = type { i32, i32, i32, i32, i64*, i64* }
%struct.rb_iseq_location_struct = type { i64, i64, i64, i64, i32, %struct.rb_code_location_struct }
%struct.rb_code_location_struct = type { %struct.rb_code_position_struct, %struct.rb_code_position_struct }
%struct.rb_code_position_struct = type { i32, i32 }
%struct.iseq_insn_info = type { %struct.rb_code_position_struct*, i32*, i32, %struct.succ_index_table* }
%struct.succ_index_table = type opaque
%struct.iseq_catch_table = type opaque
%union.iseq_inline_storage_entry = type { %struct.iseq_inline_cache_entry }
%struct.iseq_inline_cache_entry = type { i64, %struct.rb_cref_struct*, %union.anon.0 }
%struct.rb_cref_struct = type { i64, i64, i64, %struct.rb_cref_struct*, %struct.anon.2 }
%union.anon.0 = type { i64 }
%struct.rb_call_info = type { i64, i32, i32 }
%struct.rb_call_cache = type { i64, i64, %struct.rb_callable_method_entry_struct*, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, %struct.rb_calling_info*, %struct.rb_call_info*, %struct.rb_call_cache*)*, %union.anon.6 }
%struct.rb_callable_method_entry_struct = type { i64, i64, %struct.rb_method_definition_struct*, i64, i64 }
%struct.rb_method_definition_struct = type { i64, %union.anon.5, i64 }
%union.anon.5 = type { %struct.rb_method_cfunc_struct }
%struct.rb_method_cfunc_struct = type { i64 (...)*, i64 (i64 (...)*, i64, i32, i64*)*, i32 }
%union.anon.6 = type { i32 }
%struct.anon.7 = type { i64, i64, i64, i64* }
%struct.rb_mjit_unit = type opaque
%union.anon.8 = type { %struct.anon.9 }
%struct.anon.9 = type { i64, i32 }
%struct.rb_vm_tag = type { i64, i64, [1 x %struct.__jmp_buf_tag], %struct.rb_vm_tag*, i32 }
%struct.rb_vm_protect_tag = type { %struct.rb_vm_protect_tag* }
%struct.rb_ensure_list = type { %struct.rb_ensure_list*, %struct.rb_ensure_entry }
%struct.rb_ensure_entry = type { i64, i64 (...)*, i64 }
%struct.rb_trace_arg_struct = type { i32, %struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, i64, i64, i64, i64, i64, i32, i32, i64 }
%struct.anon.11 = type { i64*, i64*, i64, [1 x %struct.__jmp_buf_tag] }
%struct.rb_calling_info = type { i64, i64, i32 }
%struct.native_thread_data_struct = type { %union.anon.12, %union.anon.13 }
%union.anon.13 = type { %union.pthread_cond_t }
%struct.rb_unblock_callback = type { void (i8*)*, i8* }
%struct.rb_mutex_struct = type opaque
%struct.rb_thread_list_struct = type { %struct.rb_thread_list_struct*, %struct.rb_thread_struct* }
%union.anon.15 = type { %struct.RBasic }
%struct.RBasic = type { i64, i64 }
%struct.rb_fiber_struct = type opaque
%struct.__jmp_buf_tag = type { [8 x i64], i32, %struct.__sigset_t }
%struct.__sigset_t = type { [16 x i64] }
%struct.anon.18 = type { [65 x i64], [65 x i8] }
%struct.rb_hook_list_struct = type { %struct.rb_event_hook_struct*, i32, i32, i32 }
%struct.rb_event_hook_struct = type opaque
%struct.rb_postponed_job_struct = type opaque
%union.anon.12 = type { %struct.list_node }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%struct.rb_objspace = type opaque
%struct.rb_at_exit_list = type { void (%struct.rb_vm_struct*)*, %struct.rb_at_exit_list* }
%struct.st_table = type { i8, i8, i8, i32, %struct.st_hash_type*, i64, i64*, i64, i64, %struct.st_table_entry* }
%struct.st_hash_type = type { i32 (...)*, i64 (...)* }
%struct.st_table_entry = type opaque
%struct.anon.19 = type { i64, i64, i64, i64 }
%struct.rb_data_type_struct = type { i8*, %struct.anon.20, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.20 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.RTypedData = type { %struct.RBasic, %struct.rb_data_type_struct*, i64, i8* }
%struct.sorbet_Closure = type { i32, [0 x i64] }

@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@.str.1 = private unnamed_addr constant [95 x i8] c"sorbet_getBuildSCMRevision: Shared objects compiled by sorbet_llvm must be run by sorbet_ruby.\00", align 1
@.str.2 = private unnamed_addr constant [93 x i8] c"sorbet_getIsReleaseBuild: Shared objects compiled by sorbet_llvm must be run by sorbet_ruby.\00", align 1
@ruby_current_vm_ptr = external local_unnamed_addr global %struct.rb_vm_struct*, align 8
@ruby_current_execution_context_ptr = external local_unnamed_addr global %struct.rb_execution_context_struct*, align 8
@rb_cData = external local_unnamed_addr constant i64, align 8
@.str.16 = private unnamed_addr constant [24 x i8] c"$__sorbet_ruby_realpath\00", align 1
@.str.17 = private unnamed_addr constant [63 x i8] c"Invalid '$__sorbet_ruby_realpath' when loading compiled module\00", align 1
@rb_cModule = external local_unnamed_addr constant i64, align 8
@"stackFramePrecomputed_func_<root>.<static-init>$153" = internal unnamed_addr global i8* null, align 8
@"rubyIdPrecomputed_<top (required)>" = internal unnamed_addr global i64 0, align 8
@"str_<top (required)>" = private unnamed_addr constant [17 x i8] c"<top (required)>\00", align 1
@"rubyStrFrozen_<top (required)>" = internal unnamed_addr global i64 0, align 8
@"rubyStrFrozen_test/testdata/compiler/call_final.rb" = internal unnamed_addr global i64 0, align 8
@"str_test/testdata/compiler/call_final.rb" = private unnamed_addr constant [37 x i8] c"test/testdata/compiler/call_final.rb\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@"str_T.class_of(<root>)" = private unnamed_addr constant [19 x i8] c"T.class_of(<root>)\00", align 1
@str_A = private unnamed_addr constant [2 x i8] c"A\00", align 1
@str_B = private unnamed_addr constant [2 x i8] c"B\00", align 1
@stackFramePrecomputed_func_A.foo = internal unnamed_addr global i8* null, align 8
@rubyIdPrecomputed_foo = internal unnamed_addr global i64 0, align 8
@str_foo = private unnamed_addr constant [4 x i8] c"foo\00", align 1
@str_sig = private unnamed_addr constant [4 x i8] c"sig\00", align 1
@str_Integer = private unnamed_addr constant [8 x i8] c"Integer\00", align 1
@"str_T.class_of(A)" = private unnamed_addr constant [14 x i8] c"T.class_of(A)\00", align 1
@"stackFramePrecomputed_func_A.<static-init>" = internal unnamed_addr global i8* null, align 8
@rubyIdPrecomputed_final = internal unnamed_addr global i64 0, align 8
@str_final = private unnamed_addr constant [6 x i8] c"final\00", align 1
@str_n = private unnamed_addr constant [2 x i8] c"n\00", align 1
@"str_<build-hash>" = private unnamed_addr constant [13 x i8] c"<build-hash>\00", align 1
@str_params = private unnamed_addr constant [7 x i8] c"params\00", align 1
@str_returns = private unnamed_addr constant [8 x i8] c"returns\00", align 1
@str_keep_self_def = private unnamed_addr constant [14 x i8] c"keep_self_def\00", align 1
@"stackFramePrecomputed_func_B#caller" = internal unnamed_addr global i8* null, align 8
@rubyIdPrecomputed_caller = internal unnamed_addr global i64 0, align 8
@str_caller = private unnamed_addr constant [7 x i8] c"caller\00", align 1
@"stackFramePrecomputed_func_B.<static-init>" = internal unnamed_addr global i8* null, align 8
@str_keep_def = private unnamed_addr constant [9 x i8] c"keep_def\00", align 1
@rb_cObject = external local_unnamed_addr constant i64
@guard_epoch_A = linkonce local_unnamed_addr global i64 0
@guarded_const_A = linkonce local_unnamed_addr global i64 0
@guard_epoch_B = linkonce local_unnamed_addr global i64 0
@guarded_const_B = linkonce local_unnamed_addr global i64 0

; Function Attrs: nounwind ssp uwtable
define weak i8* @sorbet_getBuildSCMRevision() local_unnamed_addr #0 {
  %1 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !0
  tail call void (i64, i8*, ...) @rb_raise(i64 %1, i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.1, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak i32 @sorbet_getIsReleaseBuild() local_unnamed_addr #0 {
  %1 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !0
  tail call void (i64, i8*, ...) @rb_raise(i64 %1, i8* getelementptr inbounds ([93 x i8], [93 x i8]* @.str.2, i64 0, i64 0)) #14
  unreachable
}

declare i64 @rb_fstring_new(i8*, i64) local_unnamed_addr #2

declare void @rb_gc_register_mark_object(i64) local_unnamed_addr #2

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #2

declare i64 @rb_id2sym(i64) local_unnamed_addr #2

; Function Attrs: noinline nounwind ssp uwtable
declare i64 @sorbet_getConstant(i8*, i64) local_unnamed_addr #3

declare i64 @rb_define_class(i8*, i64) local_unnamed_addr #2

declare void @rb_define_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #2

declare void @rb_define_singleton_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #2

; Function Attrs: cold noreturn nounwind optsize ssp uwtable
declare void @sorbet_cast_failure(i64, i8*, i8*) local_unnamed_addr #4

; Function Attrs: noreturn nounwind ssp uwtable
declare void @sorbet_raiseArity(i32, i32, i32) local_unnamed_addr #5

; Function Attrs: inaccessiblememonly
declare i32 @ruby_stack_check() local_unnamed_addr #6

declare i8* @ruby_xmalloc(i64) local_unnamed_addr #2

declare %struct.rb_data_type_struct* @sorbet_getClosureInfo(...) local_unnamed_addr #2

declare i64 @rb_data_typed_object_wrap(i64, i8*, %struct.rb_data_type_struct*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
declare i8* @sorbet_allocateRubyStackFrames(i64, i64, i64, i64, i32, i32) local_unnamed_addr #0

declare i64 @rb_gv_get(i8*) local_unnamed_addr #2

declare i64 @rb_gv_set(i8*, i64) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #7

; Function Attrs: nounwind readnone
declare i64 @rb_class_inherited_p(i64, i64) local_unnamed_addr #7

; Function Attrs: alwaysinline norecurse nounwind readonly ssp uwtable
declare i64 @sorbet_getConstantEpoch() local_unnamed_addr #8

; Function Attrs: nounwind sspreq
define void @Init_call_final() local_unnamed_addr #9 {
entry:
  %0 = tail call i64 @rb_gv_get(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.16, i64 0, i64 0)) #13
  %1 = and i64 %0, 7
  %2 = icmp ne i64 %1, 0
  %3 = and i64 %0, -9
  %4 = icmp eq i64 %3, 0
  %5 = or i1 %2, %4
  br i1 %5, label %12, label %6

6:                                                ; preds = %entry
  %7 = inttoptr i64 %0 to %struct.RBasic*
  %8 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %7, i64 0, i32 0
  %9 = load i64, i64* %8, align 8, !tbaa !4
  %10 = and i64 %9, 31
  %11 = icmp eq i64 %10, 5
  br i1 %11, label %sorbet_readRealpath.exit, label %12

12:                                               ; preds = %6, %entry
  %13 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !0
  tail call void (i64, i8*, ...) @rb_raise(i64 %13, i8* getelementptr inbounds ([63 x i8], [63 x i8]* @.str.17, i64 0, i64 0)) #14
  unreachable

sorbet_readRealpath.exit:                         ; preds = %6
  %14 = tail call i64 @rb_gv_set(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.16, i64 0, i64 0), i64 8) #13
  %15 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #13
  store i64 %15, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  %16 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #13
  tail call void @rb_gc_register_mark_object(i64 %16) #13
  store i64 %16, i64* @"rubyStrFrozen_<top (required)>", align 8
  %17 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([37 x i8], [37 x i8]* @"str_test/testdata/compiler/call_final.rb", i64 0, i64 0), i64 36) #13
  tail call void @rb_gc_register_mark_object(i64 %17) #13
  store i64 %17, i64* @"rubyStrFrozen_test/testdata/compiler/call_final.rb", align 8
  %"rubyId_<top (required)>.i.i" = load i64, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  %"rubyStr_<top (required)>.i.i" = load i64, i64* @"rubyStrFrozen_<top (required)>", align 8
  %18 = tail call i8* @sorbet_allocateRubyStackFrames(i64 %"rubyStr_<top (required)>.i.i", i64 %"rubyId_<top (required)>.i.i", i64 %17, i64 %0, i32 5, i32 15) #13
  store i8* %18, i8** @"stackFramePrecomputed_func_<root>.<static-init>$153", align 8
  %19 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 3) #13
  store i64 %19, i64* @rubyIdPrecomputed_foo, align 8
  %20 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 3) #13
  tail call void @rb_gc_register_mark_object(i64 %20) #13
  %rubyId_foo.i.i = load i64, i64* @rubyIdPrecomputed_foo, align 8
  %"rubyStr_test/testdata/compiler/call_final.rb.i1.i" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/call_final.rb", align 8
  %21 = tail call i8* @sorbet_allocateRubyStackFrames(i64 %20, i64 %rubyId_foo.i.i, i64 %"rubyStr_test/testdata/compiler/call_final.rb.i1.i", i64 %0, i32 7, i32 9) #13
  store i8* %21, i8** @stackFramePrecomputed_func_A.foo, align 8
  %"rubyId_<top (required)>.i2.i" = load i64, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  %"rubyStr_<top (required)>.i3.i" = load i64, i64* @"rubyStrFrozen_<top (required)>", align 8
  %"rubyStr_test/testdata/compiler/call_final.rb.i4.i" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/call_final.rb", align 8
  %22 = tail call i8* @sorbet_allocateRubyStackFrames(i64 %"rubyStr_<top (required)>.i3.i", i64 %"rubyId_<top (required)>.i2.i", i64 %"rubyStr_test/testdata/compiler/call_final.rb.i4.i", i64 %0, i32 5, i32 5) #13
  store i8* %22, i8** @"stackFramePrecomputed_func_A.<static-init>", align 8
  %23 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_final, i64 0, i64 0), i64 5) #13
  store i64 %23, i64* @rubyIdPrecomputed_final, align 8
  %24 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i64 3) #13
  %25 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_n, i64 0, i64 0), i64 1) #13
  %26 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([13 x i8], [13 x i8]* @"str_<build-hash>", i64 0, i64 0), i64 12) #13
  %27 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_params, i64 0, i64 0), i64 6) #13
  %28 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_returns, i64 0, i64 0), i64 7) #13
  %29 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @str_keep_self_def, i64 0, i64 0), i64 13) #13
  %30 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_caller, i64 0, i64 0), i64 6) #13
  store i64 %30, i64* @rubyIdPrecomputed_caller, align 8
  %31 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_caller, i64 0, i64 0), i64 6) #13
  tail call void @rb_gc_register_mark_object(i64 %31) #13
  %rubyId_caller.i.i = load i64, i64* @rubyIdPrecomputed_caller, align 8
  %"rubyStr_test/testdata/compiler/call_final.rb.i5.i" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/call_final.rb", align 8
  %32 = tail call i8* @sorbet_allocateRubyStackFrames(i64 %31, i64 %rubyId_caller.i.i, i64 %"rubyStr_test/testdata/compiler/call_final.rb.i5.i", i64 %0, i32 12, i32 14) #13
  store i8* %32, i8** @"stackFramePrecomputed_func_B#caller", align 8
  %"rubyId_<top (required)>.i6.i" = load i64, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  %"rubyStr_<top (required)>.i7.i" = load i64, i64* @"rubyStrFrozen_<top (required)>", align 8
  %"rubyStr_test/testdata/compiler/call_final.rb.i8.i" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/call_final.rb", align 8
  %33 = tail call i8* @sorbet_allocateRubyStackFrames(i64 %"rubyStr_<top (required)>.i7.i", i64 %"rubyId_<top (required)>.i6.i", i64 %"rubyStr_test/testdata/compiler/call_final.rb.i8.i", i64 %0, i32 11, i32 11) #13
  store i8* %33, i8** @"stackFramePrecomputed_func_B.<static-init>", align 8
  %34 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str_keep_def, i64 0, i64 0), i64 8) #13
  %35 = load %struct.rb_vm_struct*, %struct.rb_vm_struct** @ruby_current_vm_ptr, align 8, !tbaa !6
  %36 = getelementptr inbounds %struct.rb_vm_struct, %struct.rb_vm_struct* %35, i64 0, i32 17
  %37 = load i64, i64* %36, align 8, !tbaa !8
  %"stackFrame_func_<root>.<static-init>$153.i" = load i8*, i8** @"stackFramePrecomputed_func_<root>.<static-init>$153", align 8
  %38 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !6
  %39 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %38, i64 0, i32 2
  %40 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %39, align 8, !tbaa !18
  %41 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %40, i64 0, i32 2
  %42 = bitcast %struct.rb_iseq_struct** %41 to i8**
  store i8* %"stackFrame_func_<root>.<static-init>$153.i", i8** %42, align 8, !tbaa !21
  %43 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %40, i64 0, i32 4
  %44 = load i64*, i64** %43, align 8, !tbaa !23
  %45 = load i64, i64* %44, align 8, !tbaa !0
  %46 = and i64 %45, -129
  store i64 %46, i64* %44, align 8, !tbaa !0
  %47 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %40, i64 0, i32 0
  %48 = getelementptr inbounds i8, i8* %"stackFrame_func_<root>.<static-init>$153.i", i64 16
  %49 = bitcast i8* %48 to %struct.rb_iseq_constant_body**
  %50 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %49, align 8, !tbaa !24
  %51 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %50, i64 0, i32 2
  %52 = load i64*, i64** %51, align 8, !tbaa !26
  %53 = getelementptr inbounds i64, i64* %52, i64 1
  store i64* %53, i64** %47, align 8, !tbaa !6
  %54 = load %struct.rb_vm_struct*, %struct.rb_vm_struct** @ruby_current_vm_ptr, align 8, !tbaa !6
  %55 = getelementptr inbounds %struct.rb_vm_struct, %struct.rb_vm_struct* %54, i64 0, i32 17
  %56 = load i64, i64* %55, align 8, !tbaa !8
  %57 = icmp eq i64 %56, %37
  br i1 %57, label %typeTestSuccess.i, label %codeRepl5, !prof !35

typeTestSuccess.i:                                ; preds = %sorbet_readRealpath.exit
  %58 = load i64, i64* @rb_cObject, align 8
  %59 = tail call i64 @rb_define_class(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_A, i64 0, i64 0), i64 %58) #13
  %60 = load i64, i64* @guard_epoch_A, align 8
  %61 = tail call i64 @sorbet_getConstantEpoch()
  %needTakeSlowPath = icmp eq i64 %60, %61
  br i1 %needTakeSlowPath, label %63, label %62, !prof !36

62:                                               ; preds = %typeTestSuccess.i
  tail call void @const_recompute_A() #13
  br label %63

63:                                               ; preds = %typeTestSuccess.i, %62
  %64 = load i64, i64* @guarded_const_A, align 8
  %65 = load i64, i64* @guard_epoch_A, align 8
  %66 = tail call i64 @sorbet_getConstantEpoch()
  %guardUpdated = icmp eq i64 %65, %66
  tail call void @llvm.assume(i1 %guardUpdated)
  %67 = tail call i8* @ruby_xmalloc(i64 16) #13
  %68 = bitcast i8* %67 to i32*
  store i32 1, i32* %68, align 8, !tbaa !37
  %69 = tail call %struct.rb_data_type_struct* (...) @sorbet_getClosureInfo() #13
  %70 = load i64, i64* @rb_cData, align 8, !tbaa !0
  %71 = tail call i64 @rb_data_typed_object_wrap(i64 %70, i8* %67, %struct.rb_data_type_struct* %69) #13
  %72 = inttoptr i64 %71 to %struct.RTypedData*
  %73 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %72, i64 0, i32 3
  %74 = bitcast i8** %73 to %struct.sorbet_Closure**
  %75 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %74, align 8, !tbaa !38
  %76 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %75, i64 0, i32 1, i64 0
  store i64 8, i64* %76, align 8
  %"stackFrame_func_A.<static-init>.i.i" = load i8*, i8** @"stackFramePrecomputed_func_A.<static-init>", align 8
  %77 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !6
  %78 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %77, i64 0, i32 2
  %79 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %78, align 8, !tbaa !18
  %80 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %79, i64 0, i32 2
  %81 = bitcast %struct.rb_iseq_struct** %80 to i8**
  store i8* %"stackFrame_func_A.<static-init>.i.i", i8** %81, align 8, !tbaa !21
  %82 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %79, i64 0, i32 4
  %83 = load i64*, i64** %82, align 8, !tbaa !23
  %84 = load i64, i64* %83, align 8, !tbaa !0
  %85 = and i64 %84, -129
  store i64 %85, i64* %83, align 8, !tbaa !0
  %86 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %79, i64 0, i32 0
  %87 = getelementptr inbounds i8, i8* %"stackFrame_func_A.<static-init>.i.i", i64 16
  %88 = bitcast i8* %87 to %struct.rb_iseq_constant_body**
  %89 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %88, align 8, !tbaa !24
  %90 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %89, i64 0, i32 2
  %91 = load i64*, i64** %90, align 8, !tbaa !26
  %92 = getelementptr inbounds i64, i64* %91, i64 1
  store i64* %92, i64** %86, align 8, !tbaa !6
  %rubyId_final.i.i = load i64, i64* @rubyIdPrecomputed_final, align 8
  %rubyId_foo.i.i1 = load i64, i64* @rubyIdPrecomputed_foo, align 8
  %93 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %74, align 8, !tbaa !38
  %94 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %93, i64 0, i32 1, i64 0
  store i64 %64, i64* %94, align 8
  store i64* %92, i64** %86, align 8, !tbaa !6
  %95 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %74, align 8, !tbaa !38
  %96 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %95, i64 0, i32 1, i64 0
  %97 = load i64, i64* %96, align 8
  %98 = icmp eq i64 %97, %64
  br i1 %98, label %"func_<root>.<static-init>$153.exit", label %99

99:                                               ; preds = %63
  %100 = load i64, i64* @rb_cModule, align 8, !tbaa !0
  %101 = tail call i64 @rb_obj_is_kind_of(i64 %97, i64 %100) #7
  %102 = icmp eq i64 %101, 0
  br i1 %102, label %codeRepl, label %sorbet_isa_class_of.exit.i1.i, !prof !40

sorbet_isa_class_of.exit.i1.i:                    ; preds = %99
  %103 = tail call i64 @rb_class_inherited_p(i64 %97, i64 %64) #7
  %104 = icmp eq i64 %103, 0
  br i1 %104, label %codeRepl, label %"func_<root>.<static-init>$153.exit", !prof !41

codeRepl:                                         ; preds = %99, %sorbet_isa_class_of.exit.i1.i
  tail call fastcc void @Init_call_final.cold.1(i64 %97) #15
  unreachable

codeRepl5:                                        ; preds = %sorbet_readRealpath.exit
  tail call fastcc void @Init_call_final.cold.2(i64 %37) #15
  unreachable

"func_<root>.<static-init>$153.exit":             ; preds = %63, %sorbet_isa_class_of.exit.i1.i
  %105 = getelementptr inbounds i64, i64* %91, i64 2
  store i64* %105, i64** %86, align 8, !tbaa !6
  %rawSym.i3.i = tail call i64 @rb_id2sym(i64 %rubyId_final.i.i) #13
  %106 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %74, align 8, !tbaa !38
  %107 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %106, i64 0, i32 1, i64 0
  %108 = load i64, i64* %107, align 8
  store i64* %105, i64** %86, align 8, !tbaa !6
  %109 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %74, align 8, !tbaa !38
  %110 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %109, i64 0, i32 1, i64 0
  store i64 %108, i64* %110, align 8
  %111 = getelementptr inbounds i64, i64* %91, i64 3
  store i64* %111, i64** %86, align 8, !tbaa !6
  %rawSym27.i.i = tail call i64 @rb_id2sym(i64 %rubyId_foo.i.i1) #13
  tail call void @rb_define_singleton_method(i64 %64, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @func_A.foo to i64 (...)*), i32 -1) #13
  %112 = getelementptr inbounds i64, i64* %52, i64 7
  store i64* %112, i64** %47, align 8, !tbaa !6
  %113 = tail call i64 @rb_define_class(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_B, i64 0, i64 0), i64 %58) #13
  %114 = load i64, i64* @guard_epoch_B, align 8
  %115 = tail call i64 @sorbet_getConstantEpoch()
  %needTakeSlowPath10 = icmp eq i64 %114, %115
  br i1 %needTakeSlowPath10, label %117, label %116, !prof !36

116:                                              ; preds = %"func_<root>.<static-init>$153.exit"
  tail call void @const_recompute_B() #13
  br label %117

117:                                              ; preds = %"func_<root>.<static-init>$153.exit", %116
  %118 = load i64, i64* @guarded_const_B, align 8
  %119 = load i64, i64* @guard_epoch_B, align 8
  %120 = tail call i64 @sorbet_getConstantEpoch()
  %guardUpdated11 = icmp eq i64 %119, %120
  tail call void @llvm.assume(i1 %guardUpdated11)
  %"stackFrame_func_B.<static-init>.i.i" = load i8*, i8** @"stackFramePrecomputed_func_B.<static-init>", align 8
  %121 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !6
  %122 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %121, i64 0, i32 2
  %123 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %122, align 8, !tbaa !18
  %124 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %123, i64 0, i32 2
  %125 = bitcast %struct.rb_iseq_struct** %124 to i8**
  store i8* %"stackFrame_func_B.<static-init>.i.i", i8** %125, align 8, !tbaa !21
  %126 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %123, i64 0, i32 4
  %127 = load i64*, i64** %126, align 8, !tbaa !23
  %128 = load i64, i64* %127, align 8, !tbaa !0
  %129 = and i64 %128, -129
  store i64 %129, i64* %127, align 8, !tbaa !0
  %130 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %123, i64 0, i32 0
  %131 = getelementptr inbounds i8, i8* %"stackFrame_func_B.<static-init>.i.i", i64 16
  %132 = bitcast i8* %131 to %struct.rb_iseq_constant_body**
  %133 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %132, align 8, !tbaa !24
  %134 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %133, i64 0, i32 2
  %135 = load i64*, i64** %134, align 8, !tbaa !26
  %rubyId_caller.i.i2 = load i64, i64* @rubyIdPrecomputed_caller, align 8
  %136 = getelementptr inbounds i64, i64* %135, i64 2
  store i64* %136, i64** %130, align 8, !tbaa !6
  %rawSym.i.i = tail call i64 @rb_id2sym(i64 %rubyId_caller.i.i2) #13
  tail call void @rb_define_method(i64 %118, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_caller, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_B#caller" to i64 (...)*), i32 -1) #13
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @func_A.foo(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #10 {
functionEntryInitializers:
  %stackFrame_func_A.foo = load i8*, i8** @stackFramePrecomputed_func_A.foo, align 8
  %0 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !6
  %1 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %0, i64 0, i32 2
  %2 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %1, align 8, !tbaa !18
  %3 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %2, i64 0, i32 2
  %4 = bitcast %struct.rb_iseq_struct** %3 to i8**
  store i8* %stackFrame_func_A.foo, i8** %4, align 8, !tbaa !21
  %5 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %2, i64 0, i32 4
  %6 = load i64*, i64** %5, align 8, !tbaa !23
  %7 = load i64, i64* %6, align 8, !tbaa !0
  %8 = and i64 %7, -129
  store i64 %8, i64* %6, align 8, !tbaa !0
  %9 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %2, i64 0, i32 0
  %10 = getelementptr inbounds i8, i8* %stackFrame_func_A.foo, i64 16
  %11 = bitcast i8* %10 to %struct.rb_iseq_constant_body**
  %12 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %11, align 8, !tbaa !24
  %13 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %12, i64 0, i32 2
  %14 = load i64*, i64** %13, align 8, !tbaa !26
  %15 = getelementptr inbounds i64, i64* %14, i64 1
  store i64* %15, i64** %9, align 8, !tbaa !6
  %16 = icmp eq i32 %argc, 1
  br i1 %16, label %fillRequiredArgs, label %argCountFailBlock, !prof !42

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call void @sorbet_raiseArity(i32 %argc, i32 1, i32 1)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %rawArg_n = load i64, i64* %argArray, align 8
  %17 = and i64 %rawArg_n, 1
  %18 = icmp eq i64 %17, 0
  br i1 %18, label %codeRepl, label %typeTestSuccess7, !prof !41

codeRepl:                                         ; preds = %fillRequiredArgs
  tail call fastcc void @func_A.foo.cold.1(i64 %rawArg_n) #15
  unreachable

typeTestSuccess7:                                 ; preds = %fillRequiredArgs
  %19 = load i64, i64* @guard_epoch_A, align 8
  %20 = tail call i64 @sorbet_getConstantEpoch()
  %needTakeSlowPath = icmp eq i64 %19, %20
  br i1 %needTakeSlowPath, label %22, label %21, !prof !36

21:                                               ; preds = %typeTestSuccess7
  tail call void @const_recompute_A() #13
  br label %22

22:                                               ; preds = %typeTestSuccess7, %21
  %23 = load i64, i64* @guarded_const_A, align 8
  %24 = load i64, i64* @guard_epoch_A, align 8
  %25 = tail call i64 @sorbet_getConstantEpoch()
  %guardUpdated = icmp eq i64 %24, %25
  tail call void @llvm.assume(i1 %guardUpdated)
  %26 = icmp eq i64 %23, %selfRaw
  br i1 %26, label %typeTestSuccess10, label %27

27:                                               ; preds = %22
  %28 = load i64, i64* @rb_cModule, align 8, !tbaa !0
  %29 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %28) #7
  %30 = icmp eq i64 %29, 0
  br i1 %30, label %codeRepl23, label %sorbet_isa_class_of.exit, !prof !40

sorbet_isa_class_of.exit:                         ; preds = %27
  %31 = tail call i64 @rb_class_inherited_p(i64 %selfRaw, i64 %23) #7
  %32 = icmp eq i64 %31, 0
  br i1 %32, label %codeRepl23, label %typeTestSuccess10, !prof !41

typeTestSuccess10:                                ; preds = %sorbet_isa_class_of.exit, %22
  %33 = getelementptr inbounds i64, i64* %14, i64 2
  store i64* %33, i64** %9, align 8, !tbaa !6
  ret i64 %rawArg_n

codeRepl23:                                       ; preds = %27, %sorbet_isa_class_of.exit
  tail call fastcc void @func_A.foo.cold.2(i64 %selfRaw) #15
  unreachable
}

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_B#caller"(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #10 {
functionEntryInitializers:
  %callArgs = alloca [1 x i64], align 8
  %"stackFrame_func_B#caller" = load i8*, i8** @"stackFramePrecomputed_func_B#caller", align 8
  %0 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !6
  %1 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %0, i64 0, i32 2
  %2 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %1, align 8, !tbaa !18
  %3 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %2, i64 0, i32 2
  %4 = bitcast %struct.rb_iseq_struct** %3 to i8**
  store i8* %"stackFrame_func_B#caller", i8** %4, align 8, !tbaa !21
  %5 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %2, i64 0, i32 4
  %6 = load i64*, i64** %5, align 8, !tbaa !23
  %7 = load i64, i64* %6, align 8, !tbaa !0
  %8 = and i64 %7, -129
  store i64 %8, i64* %6, align 8, !tbaa !0
  %9 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %2, i64 0, i32 0
  %10 = getelementptr inbounds i8, i8* %"stackFrame_func_B#caller", i64 16
  %11 = bitcast i8* %10 to %struct.rb_iseq_constant_body**
  %12 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %11, align 8, !tbaa !24
  %13 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %12, i64 0, i32 2
  %14 = load i64*, i64** %13, align 8, !tbaa !26
  %15 = getelementptr inbounds i64, i64* %14, i64 1
  store i64* %15, i64** %9, align 8, !tbaa !6
  %16 = icmp eq i32 %argc, 1
  br i1 %16, label %fillRequiredArgs, label %argCountFailBlock, !prof !42

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call void @sorbet_raiseArity(i32 %argc, i32 1, i32 1)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %17 = load i64, i64* @guard_epoch_B, align 8
  %18 = tail call i64 @sorbet_getConstantEpoch()
  %needTakeSlowPath = icmp eq i64 %17, %18
  br i1 %needTakeSlowPath, label %20, label %19, !prof !36

19:                                               ; preds = %fillRequiredArgs
  tail call void @const_recompute_B() #13
  br label %20

20:                                               ; preds = %fillRequiredArgs, %19
  %21 = load i64, i64* @guarded_const_B, align 8
  %22 = load i64, i64* @guard_epoch_B, align 8
  %23 = tail call i64 @sorbet_getConstantEpoch()
  %guardUpdated = icmp eq i64 %22, %23
  tail call void @llvm.assume(i1 %guardUpdated)
  %24 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %21) #7
  %25 = icmp eq i64 %24, 20
  br i1 %25, label %afterCallFinal_foo, label %codeRepl, !prof !35

codeRepl:                                         ; preds = %20
  tail call fastcc void @"func_B#caller.cold.1"(i64 %selfRaw) #15
  unreachable

afterCallFinal_foo:                               ; preds = %20
  %rawArg_a = load i64, i64* %argArray, align 8
  %26 = getelementptr inbounds i64, i64* %14, i64 2
  store i64* %26, i64** %9, align 8, !tbaa !6
  %27 = load i64, i64* @guard_epoch_A, align 8
  %28 = tail call i64 @sorbet_getConstantEpoch()
  %needTakeSlowPath19 = icmp eq i64 %27, %28
  br i1 %needTakeSlowPath19, label %30, label %29, !prof !36

29:                                               ; preds = %afterCallFinal_foo
  tail call void @const_recompute_A() #13
  br label %30

30:                                               ; preds = %afterCallFinal_foo, %29
  %31 = load i64, i64* @guarded_const_A, align 8
  %32 = load i64, i64* @guard_epoch_A, align 8
  %33 = tail call i64 @sorbet_getConstantEpoch()
  %guardUpdated20 = icmp eq i64 %32, %33
  tail call void @llvm.assume(i1 %guardUpdated20)
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  store i64 %rawArg_a, i64* %callArgsAddr, align 8
  %34 = tail call i32 @ruby_stack_check() #13
  %directSendResult = call i64 @func_A.foo(i32 1, i64* nonnull %callArgsAddr, i64 %31)
  ret i64 %directSendResult
}

; Function Attrs: cold minsize noreturn nounwind sspreq
define internal fastcc void @Init_call_final.cold.1(i64) unnamed_addr #11 {
newFuncRoot:
  tail call void @sorbet_cast_failure(i64 %0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_T.class_of(A)", i64 0, i64 0)) #13
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq
define internal fastcc void @Init_call_final.cold.2(i64) unnamed_addr #11 {
newFuncRoot:
  tail call void @sorbet_cast_failure(i64 %0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(<root>)", i64 0, i64 0)) #13
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_A.foo.cold.1(i64 %rawArg_n) unnamed_addr #12 {
newFuncRoot:
  tail call void @sorbet_cast_failure(i64 %rawArg_n, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_Integer, i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_A.foo.cold.2(i64 %selfRaw) unnamed_addr #12 {
newFuncRoot:
  tail call void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_T.class_of(A)", i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_B#caller.cold.1"(i64 %selfRaw) unnamed_addr #12 {
newFuncRoot:
  tail call void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_B, i64 0, i64 0))
  unreachable
}

; Function Attrs: nounwind
declare void @llvm.assume(i1) #13

define linkonce void @const_recompute_A() local_unnamed_addr {
  %1 = tail call i64 @sorbet_getConstant(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_A, i64 0, i64 0), i64 1)
  store i64 %1, i64* @guarded_const_A, align 8
  %2 = tail call i64 @sorbet_getConstantEpoch()
  store i64 %2, i64* @guard_epoch_A, align 8
  ret void
}

define linkonce void @const_recompute_B() local_unnamed_addr {
  %1 = tail call i64 @sorbet_getConstant(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_B, i64 0, i64 0), i64 1)
  store i64 %1, i64* @guarded_const_B, align 8
  %2 = tail call i64 @sorbet_getConstantEpoch()
  store i64 %2, i64* @guard_epoch_B, align 8
  ret void
}

attributes #0 = { nounwind ssp uwtable }
attributes #1 = { noreturn }
attributes #2 = { "addedToSilenceEmptyAttrsError" }
attributes #3 = { noinline nounwind ssp uwtable }
attributes #4 = { cold noreturn nounwind optsize ssp uwtable }
attributes #5 = { noreturn nounwind ssp uwtable }
attributes #6 = { inaccessiblememonly "addedToSilenceEmptyAttrsError" }
attributes #7 = { nounwind readnone }
attributes #8 = { alwaysinline norecurse nounwind readonly ssp uwtable }
attributes #9 = { nounwind sspreq }
attributes #10 = { nounwind sspreq uwtable }
attributes #11 = { cold minsize noreturn nounwind sspreq }
attributes #12 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #13 = { nounwind }
attributes #14 = { noreturn nounwind }
attributes #15 = { noinline }

!0 = !{!1, !1, i64 0}
!1 = !{!"long", !2, i64 0}
!2 = !{!"omnipotent char", !3, i64 0}
!3 = !{!"Simple C/C++ TBAA"}
!4 = !{!5, !1, i64 0}
!5 = !{!"RBasic", !1, i64 0, !1, i64 8}
!6 = !{!7, !7, i64 0}
!7 = !{!"any pointer", !2, i64 0}
!8 = !{!9, !1, i64 400}
!9 = !{!"rb_vm_struct", !1, i64 0, !10, i64 8, !7, i64 192, !7, i64 200, !7, i64 208, !14, i64 216, !2, i64 224, !11, i64 264, !11, i64 280, !11, i64 296, !11, i64 312, !1, i64 328, !13, i64 336, !13, i64 340, !13, i64 340, !13, i64 340, !13, i64 340, !13, i64 344, !1, i64 352, !2, i64 360, !1, i64 400, !1, i64 408, !1, i64 416, !1, i64 424, !1, i64 432, !1, i64 440, !1, i64 448, !7, i64 456, !7, i64 464, !15, i64 472, !16, i64 1064, !7, i64 1088, !7, i64 1096, !13, i64 1104, !13, i64 1108, !11, i64 1112, !2, i64 1128, !1, i64 1168, !1, i64 1176, !1, i64 1184, !1, i64 1192, !1, i64 1200, !13, i64 1208, !1, i64 1216, !7, i64 1224, !7, i64 1232, !7, i64 1240, !7, i64 1248, !17, i64 1256, !2, i64 1288}
!10 = !{!"rb_global_vm_lock_struct", !7, i64 0, !2, i64 8, !11, i64 48, !7, i64 64, !13, i64 72, !2, i64 80, !2, i64 128, !13, i64 176, !13, i64 180}
!11 = !{!"list_head", !12, i64 0}
!12 = !{!"list_node", !7, i64 0, !7, i64 8}
!13 = !{!"int", !2, i64 0}
!14 = !{!"long long", !2, i64 0}
!15 = !{!"", !2, i64 0, !2, i64 520}
!16 = !{!"rb_hook_list_struct", !7, i64 0, !13, i64 8, !13, i64 12, !13, i64 16}
!17 = !{!"", !1, i64 0, !1, i64 8, !1, i64 16, !1, i64 24}
!18 = !{!19, !7, i64 16}
!19 = !{!"rb_execution_context_struct", !7, i64 0, !1, i64 8, !7, i64 16, !7, i64 24, !7, i64 32, !13, i64 40, !13, i64 44, !7, i64 48, !7, i64 56, !7, i64 64, !1, i64 72, !1, i64 80, !7, i64 88, !1, i64 96, !7, i64 104, !7, i64 112, !1, i64 120, !1, i64 128, !2, i64 136, !2, i64 137, !1, i64 144, !20, i64 152}
!20 = !{!"", !7, i64 0, !7, i64 8, !1, i64 16, !2, i64 24}
!21 = !{!22, !7, i64 16}
!22 = !{!"rb_control_frame_struct", !7, i64 0, !7, i64 8, !7, i64 16, !1, i64 24, !7, i64 32, !7, i64 40, !7, i64 48}
!23 = !{!22, !7, i64 32}
!24 = !{!25, !7, i64 16}
!25 = !{!"rb_iseq_struct", !1, i64 0, !1, i64 8, !7, i64 16, !2, i64 24}
!26 = !{!27, !7, i64 8}
!27 = !{!"rb_iseq_constant_body", !2, i64 0, !13, i64 4, !7, i64 8, !28, i64 16, !30, i64 64, !33, i64 120, !7, i64 152, !7, i64 160, !7, i64 168, !7, i64 176, !7, i64 184, !7, i64 192, !7, i64 200, !34, i64 208, !13, i64 240, !13, i64 244, !13, i64 248, !13, i64 252, !13, i64 256, !7, i64 264, !1, i64 272, !7, i64 280, !2, i64 288}
!28 = !{!"", !29, i64 0, !13, i64 4, !13, i64 8, !13, i64 12, !13, i64 16, !13, i64 20, !13, i64 24, !13, i64 28, !7, i64 32, !7, i64 40}
!29 = !{!"", !13, i64 0, !13, i64 0, !13, i64 0, !13, i64 0, !13, i64 0, !13, i64 0, !13, i64 0, !13, i64 0}
!30 = !{!"rb_iseq_location_struct", !1, i64 0, !1, i64 8, !1, i64 16, !1, i64 24, !13, i64 32, !31, i64 36}
!31 = !{!"rb_code_location_struct", !32, i64 0, !32, i64 8}
!32 = !{!"rb_code_position_struct", !13, i64 0, !13, i64 4}
!33 = !{!"iseq_insn_info", !7, i64 0, !7, i64 8, !13, i64 16, !7, i64 24}
!34 = !{!"", !1, i64 0, !1, i64 8, !1, i64 16, !7, i64 24}
!35 = !{!"branch_weights", i32 2000, i32 1}
!36 = !{!"branch_weights", i32 10000, i32 1}
!37 = !{!13, !13, i64 0}
!38 = !{!39, !7, i64 32}
!39 = !{!"RTypedData", !5, i64 0, !7, i64 16, !1, i64 24, !7, i64 32}
!40 = !{!"branch_weights", i32 1073205, i32 2146410443}
!41 = !{!"branch_weights", i32 1, i32 2000}
!42 = !{!"branch_weights", i32 4000000, i32 4001}
