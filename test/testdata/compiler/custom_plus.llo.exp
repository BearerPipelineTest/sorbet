; ModuleID = 'payload'
source_filename = "compiler/IREmitter/Payload/payload.c"
target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.1, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.1 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.RBasic = type { i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%union.anon.0 = type { i64 }
%struct.OnigEncodingTypeST = type { i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i8*, i32, i32, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8**, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i32 (i32, i32*, i32, i8*)*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, i8*, %struct.OnigCaseFoldCodeItem*, %struct.OnigEncodingTypeST*)*, i32 (%struct.OnigEncodingTypeST*, i8*, i8*)*, i32 (i32, i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i32*, i32**, %struct.OnigEncodingTypeST*)*, i8* (i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32*, i8**, i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32, i32 }
%struct.OnigCaseFoldCodeItem = type { i32, i32, [3 x i32] }

@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@rb_cObject = external local_unnamed_addr constant i64, align 8
@ruby_vm_global_constant_state = external local_unnamed_addr global i64, align 8
@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@.str.1 = private unnamed_addr constant [29 x i8] c"wrong constant name %li\0B%li\0B\00", align 1
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.2 = private unnamed_addr constant [36 x i8] c"%li\0B does not refer to class/module\00", align 1
@sorbet_getConstantAt.rb_intern_id_cache = internal unnamed_addr global i64 0, align 8
@.str.3 = private unnamed_addr constant [14 x i8] c"const_missing\00", align 1
@.str.4 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.7 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@.str.8 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@closureInfo = local_unnamed_addr constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.8, i32 0, i32 0), %struct.anon.1 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@rubyIdPrecomputed_delegate = internal unnamed_addr global i64 0, align 8
@str_delegate = private unnamed_addr constant [9 x i8] c"delegate\00", align 1
@str_Object = private unnamed_addr constant [7 x i8] c"Object\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@"rubyIdPrecomputed_+" = internal unnamed_addr global i64 0, align 8
@"str_+" = private unnamed_addr constant [2 x i8] c"+\00", align 1
@"rubyIdPrecomputed_==" = internal unnamed_addr global i64 0, align 8
@"str_==" = private unnamed_addr constant [3 x i8] c"==\00", align 1
@str_fail = private unnamed_addr constant [5 x i8] c"fail\00", align 1
@rubyIdPrecomputed_puts = internal unnamed_addr global i64 0, align 8
@str_puts = private unnamed_addr constant [5 x i8] c"puts\00", align 1
@str_ok = private unnamed_addr constant [3 x i8] c"ok\00", align 1
@"rubyIdPrecomputed_<static-init>" = internal unnamed_addr global i64 0, align 8
@"str_<static-init>" = private unnamed_addr constant [14 x i8] c"<static-init>\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@str_A = private unnamed_addr constant [2 x i8] c"A\00", align 1
@rubyIdPrecomputed_new = internal unnamed_addr global i64 0, align 8
@str_new = private unnamed_addr constant [4 x i8] c"new\00", align 1
@llvm.global_ctors = appending global [7 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_delegate, i8* bitcast (i64* @rubyIdPrecomputed_delegate to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_+", i8* bitcast (i64* @"rubyIdPrecomputed_+" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_==", i8* bitcast (i64* @"rubyIdPrecomputed_==" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_puts, i8* bitcast (i64* @rubyIdPrecomputed_puts to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<static-init>", i8* bitcast (i64* @"rubyIdPrecomputed_<static-init>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_new, i8* bitcast (i64* @rubyIdPrecomputed_new to i8*) }]
@guard_epoch_A = linkonce local_unnamed_addr global i64 0
@guarded_const_A = linkonce local_unnamed_addr global i64 0

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i8* @rb_id2name(i64 %0) #17
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #17
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !0
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #17
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !5
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #1

declare i64 @rb_str_new(i8*, i64) local_unnamed_addr #1

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #1

declare i64 @rb_id2sym(i64) local_unnamed_addr #1

declare i8* @rb_obj_classname(i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstantAt(i64 %0, i64 %1) unnamed_addr #2 {
  %3 = tail call i64 @rb_id2sym(i64 %1) #17
  %4 = tail call %struct.OnigEncodingTypeST* @rb_enc_get(i64 %3) #17
  %5 = tail call i8* @rb_id2name(i64 %1) #17
  %6 = tail call i64 @strlen(i8* nonnull dereferenceable(1) %5)
  %7 = getelementptr inbounds i8, i8* %5, i64 %6
  %8 = icmp sgt i64 %6, 0
  br i1 %8, label %9, label %.loopexit11

9:                                                ; preds = %2
  %10 = ptrtoint i8* %5 to i64
  br label %13

.loopexit10:                                      ; preds = %91, %44, %41, %28, %107
  %11 = phi i64 [ %108, %107 ], [ %3, %28 ], [ %3, %44 ], [ %3, %41 ], [ %66, %91 ]
  %12 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %12, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.1, i64 0, i64 0), i64 %14, i64 %11) #18
  unreachable

13:                                               ; preds = %115, %9
  %14 = phi i64 [ %0, %9 ], [ %116, %115 ]
  %15 = phi i8* [ %5, %9 ], [ %50, %115 ]
  %16 = phi i8* [ %5, %9 ], [ %49, %115 ]
  %17 = icmp ult i8* %16, %7
  br i1 %17, label %18, label %28

18:                                               ; preds = %13
  %19 = load i8, i8* %16, align 1, !tbaa !5
  %20 = icmp eq i8 %19, 58
  br i1 %20, label %28, label %.preheader

21:                                               ; preds = %.preheader
  %22 = load i8, i8* %25, align 1, !tbaa !5
  %23 = icmp eq i8 %22, 58
  br i1 %23, label %.loopexit, label %.preheader

.preheader:                                       ; preds = %18, %21
  %24 = phi i8* [ %25, %21 ], [ %16, %18 ]
  %25 = getelementptr inbounds i8, i8* %24, i64 1
  %26 = icmp eq i8* %25, %7
  br i1 %26, label %.loopexit, label %21

.loopexit:                                        ; preds = %21, %.preheader
  %.lcssa = phi i8* [ %25, %21 ], [ %7, %.preheader ]
  %27 = icmp ult i8* %.lcssa, %7
  br label %28

28:                                               ; preds = %.loopexit, %18, %13
  %29 = phi i8* [ %16, %13 ], [ %16, %18 ], [ %.lcssa, %.loopexit ]
  %30 = phi i1 [ false, %13 ], [ true, %18 ], [ %27, %.loopexit ]
  %31 = icmp eq i8* %15, %29
  br i1 %31, label %.loopexit10, label %32

32:                                               ; preds = %28
  %33 = ptrtoint i8* %29 to i64
  %34 = ptrtoint i8* %15 to i64
  %35 = sub i64 %33, %34
  %36 = tail call i64 @rb_check_id_cstr(i8* %15, i64 %35, %struct.OnigEncodingTypeST* %4) #17
  %37 = sub i64 %34, %10
  br i1 %30, label %38, label %48

38:                                               ; preds = %32
  %39 = load i8, i8* %29, align 1, !tbaa !5
  %40 = icmp eq i8 %39, 58
  br i1 %40, label %41, label %48

41:                                               ; preds = %38
  %42 = getelementptr inbounds i8, i8* %29, i64 2
  %43 = icmp ult i8* %42, %7
  br i1 %43, label %44, label %.loopexit10

44:                                               ; preds = %41
  %45 = getelementptr inbounds i8, i8* %29, i64 1
  %46 = load i8, i8* %45, align 1, !tbaa !5
  %47 = icmp eq i8 %46, 58
  br i1 %47, label %48, label %.loopexit10

48:                                               ; preds = %44, %38, %32
  %49 = phi i8* [ %29, %38 ], [ %29, %32 ], [ %42, %44 ]
  %50 = phi i8* [ %15, %38 ], [ %15, %32 ], [ %42, %44 ]
  %51 = and i64 %14, 7
  %52 = icmp ne i64 %51, 0
  %53 = and i64 %14, -9
  %54 = icmp eq i64 %53, 0
  %55 = or i1 %52, %54
  br i1 %55, label %61, label %56

56:                                               ; preds = %48
  %57 = inttoptr i64 %14 to %struct.RBasic*
  %58 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 0
  %59 = load i64, i64* %58, align 8, !tbaa !0
  %60 = and i64 %59, 30
  %switch = icmp eq i64 %60, 2
  br i1 %switch, label %63, label %61

61:                                               ; preds = %56, %48
  %62 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %62, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.2, i64 0, i64 0), i64 %3) #18
  unreachable

63:                                               ; preds = %56
  %64 = icmp eq i64 %36, 0
  br i1 %64, label %65, label %104

65:                                               ; preds = %63
  %66 = tail call i64 @rb_str_subseq(i64 %3, i64 %37, i64 %35) #17
  %67 = and i64 %66, 7
  %68 = icmp ne i64 %67, 0
  %69 = and i64 %66, -9
  %70 = icmp eq i64 %69, 0
  %71 = or i1 %68, %70
  br i1 %71, label %rb_obj_freeze_inline.exit, label %72

72:                                               ; preds = %65
  %73 = inttoptr i64 %66 to %struct.RBasic*
  %74 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 0
  %75 = load i64, i64* %74, align 8, !tbaa !0
  %76 = and i64 %75, 31
  %77 = icmp eq i64 %76, 27
  br i1 %77, label %rb_obj_freeze_inline.exit, label %78

78:                                               ; preds = %72
  %79 = or i64 %75, 2048
  store i64 %79, i64* %74, align 8, !tbaa !0
  %80 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 1
  %81 = load i64, i64* %80, align 8, !tbaa !7
  %82 = icmp ne i64 %81, 0
  %83 = and i64 %75, 4096
  %84 = icmp eq i64 %83, 0
  %85 = and i1 %84, %82
  br i1 %85, label %86, label %rb_obj_freeze_inline.exit

86:                                               ; preds = %78
  tail call void @rb_freeze_singleton_class(i64 %66) #17
  br label %rb_obj_freeze_inline.exit

rb_obj_freeze_inline.exit:                        ; preds = %65, %72, %78, %86
  %87 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %89, label %91

89:                                               ; preds = %rb_obj_freeze_inline.exit
  %90 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.3, i64 0, i64 0), i64 13) #17
  store i64 %90, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  br label %91

91:                                               ; preds = %89, %rb_obj_freeze_inline.exit
  %92 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %93 = tail call i32 @rb_is_const_name(i64 %66) #17
  %94 = icmp eq i32 %93, 0
  br i1 %94, label %.loopexit10, label %rb_class_of.exit

rb_class_of.exit:                                 ; preds = %91
  %95 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 1
  %96 = load i64, i64* %95, align 8, !tbaa !6
  %97 = tail call i32 @rb_method_basic_definition_p(i64 %96, i64 %92) #17
  %98 = icmp eq i32 %97, 0
  br i1 %98, label %99, label %102

99:                                               ; preds = %rb_class_of.exit
  %100 = tail call i64 @rb_str_intern(i64 %66) #17
  %101 = tail call i64 @rb_const_missing(i64 %14, i64 %100) #17
  br label %115

102:                                              ; preds = %rb_class_of.exit
  %103 = tail call i64 @rb_mod_const_missing(i64 %14, i64 %66) #18
  unreachable

104:                                              ; preds = %63
  %105 = tail call i32 @rb_is_const_id(i64 %36) #5
  %106 = icmp eq i32 %105, 0
  br i1 %106, label %107, label %109

107:                                              ; preds = %104
  %108 = tail call i64 @rb_id2sym(i64 %36) #17
  br label %.loopexit10

109:                                              ; preds = %104
  %110 = icmp eq i64 %37, 0
  br i1 %110, label %111, label %113

111:                                              ; preds = %109
  %112 = tail call i64 @rb_const_get(i64 %14, i64 %36) #17
  br label %115

113:                                              ; preds = %109
  %114 = tail call i64 @rb_const_get_from(i64 %14, i64 %36) #17
  br label %115

115:                                              ; preds = %113, %111, %99
  %116 = phi i64 [ %101, %99 ], [ %112, %111 ], [ %114, %113 ]
  %117 = icmp ult i8* %49, %7
  br i1 %117, label %13, label %.loopexit11

.loopexit11:                                      ; preds = %115, %2
  %118 = phi i64 [ %0, %2 ], [ %116, %115 ]
  ret i64 %118
}

declare %struct.OnigEncodingTypeST* @rb_enc_get(i64) local_unnamed_addr #1

; Function Attrs: argmemonly nofree nounwind readonly
declare i64 @strlen(i8* nocapture) local_unnamed_addr #3

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #4

declare i64 @rb_check_id_cstr(i8*, i64, %struct.OnigEncodingTypeST*) local_unnamed_addr #1

declare i64 @rb_str_subseq(i64, i64, i64) local_unnamed_addr #1

declare i32 @rb_is_const_name(i64) local_unnamed_addr #1

declare i32 @rb_method_basic_definition_p(i64, i64) local_unnamed_addr #1

declare i64 @rb_str_intern(i64) local_unnamed_addr #1

declare i64 @rb_const_missing(i64, i64) local_unnamed_addr #1

; Function Attrs: noreturn
declare i64 @rb_mod_const_missing(i64, i64) local_unnamed_addr #4

; Function Attrs: nounwind readnone
declare i32 @rb_is_const_id(i64) local_unnamed_addr #5

declare i64 @rb_const_get(i64, i64) local_unnamed_addr #1

declare i64 @rb_const_get_from(i64, i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstant(i8* %0, i64 %1) unnamed_addr #2 {
  %3 = load i64, i64* @rb_cObject, align 8, !tbaa !6
  %4 = tail call i64 @rb_intern2(i8* %0, i64 %1) #17
  %5 = tail call fastcc i64 @sorbet_getConstantAt(i64 %3, i64 %4)
  ret i64 %5
}

declare i64 @rb_define_class(i8*, i64) local_unnamed_addr #1

declare void @rb_define_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #1

declare i64 @rb_funcallv(i64, i64, i32, i64*) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32 %0) unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.4, i64 0, i64 0), i32 %0, i32 1) #17
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !6
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #17
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #1

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64 %0, i8* %1) unnamed_addr #6 {
  %3 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  %4 = tail call i8* @rb_obj_classname(i64 %0) #17
  tail call void (i64, i8*, ...) @rb_raise(i64 %3, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.7, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* %1, i8* %4, i64 %0) #18
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_raiseArity(i32 %0) unnamed_addr #7 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #18
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8* %0) #0 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #17
  ret void
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #1

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly %0) #8 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #5

declare i64 @rb_int2big(i64) local_unnamed_addr #1

declare i64 @rb_int_equal(i64, i64) local_unnamed_addr #1

declare void @rb_freeze_singleton_class(i64) local_unnamed_addr #1

; Function Attrs: nounwind readnone speculatable willreturn
declare { i64, i1 } @llvm.sadd.with.overflow.i64(i64, i64) #9

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_Object#delegate"(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #10 {
functionEntryInitializers:
  %callArgs = alloca [1 x i64], align 8
  %"rubyId_+" = load i64, i64* @"rubyIdPrecomputed_+", align 8
  %"rubyId_==" = load i64, i64* @"rubyIdPrecomputed_==", align 8
  %rubyId_puts = load i64, i64* @rubyIdPrecomputed_puts, align 8
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !10, !misexpect !11

BB2:                                              ; preds = %"afterSymCallIntrinsic_=="
  %1 = call i64 @rb_str_new(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @str_ok, i64 0, i64 0), i64 2) #17
  br label %BB4

BB3:                                              ; preds = %"afterSymCallIntrinsic_=="
  %2 = call i64 @rb_str_new(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_fail, i64 0, i64 0), i64 4) #17
  br label %BB4

BB4:                                              ; preds = %BB2, %BB3
  %storemerge = phi i64 [ %1, %BB2 ], [ %2, %BB3 ]
  store i64 %storemerge, i64* %callArgsAddr, align 8
  %3 = call i64 @rb_funcallv(i64 %selfRaw, i64 %rubyId_puts, i32 1, i64* nonnull %callArgsAddr) #17
  ret i64 %3

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %rawArg_a = load i64, i64* %argArray, align 8
  %4 = load i64, i64* @rb_cObject, align 8
  %5 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %4) #5
  %6 = icmp eq i64 %5, 20
  br i1 %6, label %typeTestSuccess, label %codeRepl, !prof !12, !misexpect !13

typeTestSuccess:                                  ; preds = %fillRequiredArgs
  %7 = and i64 %rawArg_a, 1
  %8 = icmp eq i64 %7, 0
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  store i64 3, i64* %callArgsAddr, align 8
  br i1 %8, label %"slowSymCallIntrinsic_+", label %"fastSymCallIntrinsic_+", !prof !14, !misexpect !13

codeRepl:                                         ; preds = %fillRequiredArgs
  tail call fastcc void @"func_Object#delegate.cold.1"(i64 %selfRaw) #19
  unreachable

"afterSymCallIntrinsic_+":                        ; preds = %15, %"fastSymCallIntrinsic_+", %"slowSymCallIntrinsic_+"
  %"symIntrinsicRawPhi_+" = phi i64 [ %11, %"slowSymCallIntrinsic_+" ], [ %18, %15 ], [ %14, %"fastSymCallIntrinsic_+" ]
  %9 = and i64 %"symIntrinsicRawPhi_+", 1
  %10 = icmp eq i64 %9, 0
  store i64 %rawArg_a, i64* %callArgsAddr, align 8
  br i1 %10, label %"slowSymCallIntrinsic_==", label %"fastSymCallIntrinsic_==", !prof !14, !misexpect !13

"slowSymCallIntrinsic_+":                         ; preds = %typeTestSuccess
  %11 = call i64 @rb_funcallv(i64 %rawArg_a, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #17
  br label %"afterSymCallIntrinsic_+"

"fastSymCallIntrinsic_+":                         ; preds = %typeTestSuccess
  %12 = tail call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %rawArg_a, i64 2) #17
  %13 = extractvalue { i64, i1 } %12, 1
  %14 = extractvalue { i64, i1 } %12, 0
  br i1 %13, label %15, label %"afterSymCallIntrinsic_+"

15:                                               ; preds = %"fastSymCallIntrinsic_+"
  %16 = ashr i64 %14, 1
  %17 = xor i64 %16, -9223372036854775808
  %18 = tail call i64 @rb_int2big(i64 %17) #17, !noalias !15
  br label %"afterSymCallIntrinsic_+"

"afterSymCallIntrinsic_==":                       ; preds = %"slowSymCallIntrinsic_==", %"fastSymCallIntrinsic_=="
  %"symIntrinsicRawPhi_==" = phi i64 [ %22, %"fastSymCallIntrinsic_==" ], [ %21, %"slowSymCallIntrinsic_==" ]
  %19 = and i64 %"symIntrinsicRawPhi_==", -9
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %BB3, label %BB2

"slowSymCallIntrinsic_==":                        ; preds = %"afterSymCallIntrinsic_+"
  %21 = call i64 @rb_funcallv(i64 %"symIntrinsicRawPhi_+", i64 %"rubyId_==", i32 1, i64* nonnull %callArgsAddr) #17
  br label %"afterSymCallIntrinsic_=="

"fastSymCallIntrinsic_==":                        ; preds = %"afterSymCallIntrinsic_+"
  %22 = call i64 @rb_int_equal(i64 %"symIntrinsicRawPhi_+", i64 %rawArg_a) #17, !noalias !18
  br label %"afterSymCallIntrinsic_=="
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_delegate() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str_delegate, i64 0, i64 0), i64 8) #17
  store i64 %0, i64* @rubyIdPrecomputed_delegate, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_+"() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_+", i64 0, i64 0), i64 1) #17
  store i64 %0, i64* @"rubyIdPrecomputed_+", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_=="() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @"str_==", i64 0, i64 0), i64 2) #17
  store i64 %0, i64* @"rubyIdPrecomputed_==", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_puts() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_puts, i64 0, i64 0), i64 4) #17
  store i64 %0, i64* @rubyIdPrecomputed_puts, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<static-init>"() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_<static-init>", i64 0, i64 0), i64 13) #17
  store i64 %0, i64* @"rubyIdPrecomputed_<static-init>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #17
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_new() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_new, i64 0, i64 0), i64 3) #17
  store i64 %0, i64* @rubyIdPrecomputed_new, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_compiler_custom_plus() local_unnamed_addr #12 {
"func_<root>.<static-init>$111.exit":
  %callArgs.i = alloca [2 x i64], align 8
  %0 = load i64, i64* @rb_cObject, align 8
  %1 = bitcast [2 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1)
  %rubyId_new.i = load i64, i64* @rubyIdPrecomputed_new, align 8
  %rubyId_delegate.i = load i64, i64* @rubyIdPrecomputed_delegate, align 8
  %callArgsAddr.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i, i64 0, i64 0
  store i64 %0, i64* %callArgsAddr.i, align 8
  %2 = tail call i64 @rb_define_class(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_A, i64 0, i64 0), i64 %0) #17
  %3 = load i64, i64* @guard_epoch_A, align 8
  %4 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !21
  %needTakeSlowPath = icmp eq i64 %3, %4
  br i1 %needTakeSlowPath, label %6, label %5, !prof !23

5:                                                ; preds = %"func_<root>.<static-init>$111.exit"
  tail call void @const_recompute_A() #17
  br label %6

6:                                                ; preds = %"func_<root>.<static-init>$111.exit", %5
  %7 = load i64, i64* @guarded_const_A, align 8
  %8 = load i64, i64* @guard_epoch_A, align 8
  %9 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !21
  %guardUpdated = icmp eq i64 %8, %9
  tail call void @llvm.assume(i1 %guardUpdated)
  %"rubyId_+.i.i.i" = load i64, i64* @"rubyIdPrecomputed_+", align 8
  %rawSym.i.i.i = tail call i64 @rb_id2sym(i64 %"rubyId_+.i.i.i") #17
  tail call void @rb_define_method(i64 %7, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_+", i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_A#+" to i64 (...)*), i32 -1) #17
  %10 = call i64 @rb_funcallv(i64 %7, i64 %rubyId_new.i, i32 0, i64* nonnull %callArgsAddr.i) #17
  store i64 %0, i64* %callArgsAddr.i, align 8
  %rawSym.i = call i64 @rb_id2sym(i64 %rubyId_delegate.i) #17
  call void @rb_define_method(i64 %0, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str_delegate, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_Object#delegate" to i64 (...)*), i32 -1) #17
  store i64 %10, i64* %callArgsAddr.i, align 8
  %11 = call i64 @rb_funcallv(i64 %0, i64 %rubyId_delegate.i, i32 1, i64* nonnull %callArgsAddr.i) #17
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1)
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_A#+"(i32 %argc, i64* nocapture readnone %argArray, i64 returned %selfRaw) #10 {
functionEntryInitializers:
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !10, !misexpect !11

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %1 = load i64, i64* @guard_epoch_A, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !21
  %needTakeSlowPath = icmp eq i64 %1, %2
  br i1 %needTakeSlowPath, label %4, label %3, !prof !23

3:                                                ; preds = %fillRequiredArgs
  tail call void @const_recompute_A() #17
  br label %4

4:                                                ; preds = %fillRequiredArgs, %3
  %5 = load i64, i64* @guarded_const_A, align 8
  %6 = load i64, i64* @guard_epoch_A, align 8
  %7 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !21
  %guardUpdated = icmp eq i64 %6, %7
  tail call void @llvm.assume(i1 %guardUpdated)
  %8 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %5) #5
  %9 = icmp eq i64 %8, 20
  br i1 %9, label %typeTestSuccess, label %codeRepl, !prof !12, !misexpect !13

typeTestSuccess:                                  ; preds = %4
  ret i64 %selfRaw

codeRepl:                                         ; preds = %4
  tail call fastcc void @"func_A#+.cold.1"(i64 %selfRaw) #19
  unreachable
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #13

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #13

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_Object#delegate.cold.1"(i64 %selfRaw) unnamed_addr #14 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_A#+.cold.1"(i64 %selfRaw) unnamed_addr #14 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_A, i64 0, i64 0))
  unreachable
}

; Function Attrs: nounwind willreturn
declare void @llvm.assume(i1) #15

; Function Attrs: ssp
define linkonce void @const_recompute_A() local_unnamed_addr #16 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_A, i64 0, i64 0), i64 1)
  store i64 %1, i64* @guarded_const_A, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !21
  store i64 %2, i64* @guard_epoch_A, align 8
  ret void
}

attributes #0 = { nounwind ssp uwtable }
attributes #1 = { "addedToSilenceEmptyAttrsError" }
attributes #2 = { noinline nounwind ssp uwtable }
attributes #3 = { argmemonly nofree nounwind readonly }
attributes #4 = { noreturn }
attributes #5 = { nounwind readnone }
attributes #6 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #7 = { noreturn nounwind ssp uwtable }
attributes #8 = { norecurse nounwind readnone ssp uwtable }
attributes #9 = { nounwind readnone speculatable willreturn }
attributes #10 = { nounwind sspreq uwtable }
attributes #11 = { nounwind ssp }
attributes #12 = { nounwind sspreq }
attributes #13 = { argmemonly nounwind willreturn }
attributes #14 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #15 = { nounwind willreturn }
attributes #16 = { ssp }
attributes #17 = { nounwind }
attributes #18 = { noreturn nounwind }
attributes #19 = { noinline }

!0 = !{!1, !2, i64 0}
!1 = !{!"RBasic", !2, i64 0, !2, i64 8}
!2 = !{!"long", !3, i64 0}
!3 = !{!"omnipotent char", !4, i64 0}
!4 = !{!"Simple C/C++ TBAA"}
!5 = !{!3, !3, i64 0}
!6 = !{!2, !2, i64 0}
!7 = !{!1, !2, i64 8}
!8 = !{!9, !9, i64 0}
!9 = !{!"int", !3, i64 0}
!10 = !{!"branch_weights", i32 4000000, i32 4001}
!11 = !{!"misexpect", i64 1, i64 2000, i64 1}
!12 = !{!"branch_weights", i32 2000, i32 1}
!13 = !{!"misexpect", i64 0, i64 2000, i64 1}
!14 = !{!"branch_weights", i32 1, i32 2000}
!15 = !{!16}
!16 = distinct !{!16, !17, !"sorbet_rb_int_plus: argument 0"}
!17 = distinct !{!17, !"sorbet_rb_int_plus"}
!18 = !{!19}
!19 = distinct !{!19, !20, !"sorbet_rb_int_equal: argument 0"}
!20 = distinct !{!20, !"sorbet_rb_int_equal"}
!21 = !{!22, !22, i64 0}
!22 = !{!"long long", !3, i64 0}
!23 = !{!"branch_weights", i32 10000, i32 1}
