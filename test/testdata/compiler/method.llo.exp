; ModuleID = 'payload'
source_filename = "llvm-link"
target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.19, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.19 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.rb_execution_context_struct = type { i64*, i64, %struct.rb_control_frame_struct*, %struct.rb_vm_tag*, %struct.rb_vm_protect_tag*, i32, i32, %struct.rb_fiber_struct*, %struct.rb_thread_struct*, %struct.st_table*, i64, i64, i64*, i64, %struct.rb_ensure_list*, %struct.rb_trace_arg_struct*, i64, i64, i8, i8, i64, %struct.anon.18 }
%struct.rb_control_frame_struct = type { i64*, i64*, %struct.rb_iseq_struct*, i64, i64*, i8*, i64* }
%struct.rb_iseq_struct = type { i64, i64, %struct.rb_iseq_constant_body*, %union.anon.15 }
%struct.rb_iseq_constant_body = type { i32, i32, i64*, %struct.anon.1, %struct.rb_iseq_location_struct, %struct.iseq_insn_info, i64*, %struct.iseq_catch_table*, %struct.rb_iseq_struct*, %struct.rb_iseq_struct*, %union.iseq_inline_storage_entry*, %struct.rb_call_info*, %struct.rb_call_cache*, %struct.anon.14, i32, i32, i32, i32, i32, i8 }
%struct.anon.1 = type { %struct.anon.2, i32, i32, i32, i32, i32, i32, i32, i64*, %struct.rb_iseq_param_keyword* }
%struct.anon.2 = type { i8, [3 x i8] }
%struct.rb_iseq_param_keyword = type { i32, i32, i32, i32, i64*, i64* }
%struct.rb_iseq_location_struct = type { i64, i64, i64, i64, i32, %struct.rb_code_location_struct }
%struct.rb_code_location_struct = type { %struct.rb_code_position_struct, %struct.rb_code_position_struct }
%struct.rb_code_position_struct = type { i32, i32 }
%struct.iseq_insn_info = type { %struct.rb_code_position_struct*, i32*, i32, %struct.succ_index_table* }
%struct.succ_index_table = type opaque
%struct.iseq_catch_table = type opaque
%union.iseq_inline_storage_entry = type { %struct.iseq_inline_cache_entry }
%struct.iseq_inline_cache_entry = type { i64, %struct.rb_cref_struct*, %union.anon.0 }
%struct.rb_cref_struct = type { i64, i64, i64, %struct.rb_cref_struct*, %struct.anon.2 }
%union.anon.0 = type { i64 }
%struct.rb_call_info = type { i64, i32, i32 }
%struct.rb_call_cache = type { i64, i64, %struct.rb_callable_method_entry_struct*, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, %struct.rb_calling_info*, %struct.rb_call_info*, %struct.rb_call_cache*)*, %union.anon.13 }
%struct.rb_callable_method_entry_struct = type { i64, i64, %struct.rb_method_definition_struct*, i64, i64 }
%struct.rb_method_definition_struct = type { i64, %union.anon.12, i64 }
%union.anon.12 = type { %struct.rb_method_cfunc_struct }
%struct.rb_method_cfunc_struct = type { i64 (...)*, i64 (i64 (...)*, i64, i32, i64*)*, i32 }
%struct.rb_calling_info = type { i64, i64, i32 }
%union.anon.13 = type { i32 }
%struct.anon.14 = type { i64, i64, i64, i64* }
%union.anon.15 = type { %struct.anon.16 }
%struct.anon.16 = type { i64, i32 }
%struct.rb_vm_tag = type { i64, i64, [38 x i32], %struct.rb_vm_tag*, i32 }
%struct.rb_vm_protect_tag = type { %struct.rb_vm_protect_tag* }
%struct.rb_fiber_struct = type opaque
%struct.rb_thread_struct = type { %struct.list_node, i64, %struct.rb_vm_struct*, %struct.rb_execution_context_struct*, i64, %struct.rb_calling_info*, i64, i64, %struct._opaque_pthread_t*, i8, i8, i32, %struct.native_thread_data_struct, i8*, i64, i64, i64, i64, %struct._opaque_pthread_mutex_t, %struct.rb_unblock_callback, i64, %struct.rb_mutex_struct*, %struct.rb_thread_list_struct*, %union.anon.8, i32, i64, %struct.rb_fiber_struct*, [38 x i32], i64 }
%struct.list_node = type { %struct.list_node*, %struct.list_node* }
%struct.rb_vm_struct = type { i64, %struct.rb_global_vm_lock_struct, %struct.rb_thread_struct*, %struct.rb_thread_struct*, i8*, i64, %struct._opaque_pthread_mutex_t, %struct.list_head, %struct.list_head, %struct.list_head, %struct.list_head, i64, i32, i8, i32, i64, [5 x i64], i64, i64, i64, i64, i64, i64, i64, %struct.st_table*, %struct.st_table*, %struct.anon.4, %struct.rb_hook_list_struct, %struct.st_table*, %struct.rb_postponed_job_struct*, i32, i32, %struct.list_head, %struct._opaque_pthread_mutex_t, i64, i64, i64, i64, i64, i32, i64, %struct.rb_objspace*, %struct.rb_at_exit_list*, i64*, %struct.st_table*, %struct.anon.5, [28 x i16] }
%struct.rb_global_vm_lock_struct = type { %struct.rb_thread_struct*, %struct._opaque_pthread_mutex_t, %struct.list_head, %struct.rb_thread_struct*, i32, %struct._opaque_pthread_cond_t, %struct._opaque_pthread_cond_t, i32, i32 }
%struct._opaque_pthread_cond_t = type { i64, [40 x i8] }
%struct.anon.4 = type { [32 x i64], [32 x i8] }
%struct.rb_hook_list_struct = type { %struct.rb_event_hook_struct*, i32, i32, i32 }
%struct.rb_event_hook_struct = type opaque
%struct.rb_postponed_job_struct = type opaque
%struct.list_head = type { %struct.list_node }
%struct.rb_objspace = type opaque
%struct.rb_at_exit_list = type { void (%struct.rb_vm_struct*)*, %struct.rb_at_exit_list* }
%struct.anon.5 = type { i64, i64, i64, i64 }
%struct._opaque_pthread_t = type { i64, %struct.__darwin_pthread_handler_rec*, [8176 x i8] }
%struct.__darwin_pthread_handler_rec = type { void (i8*)*, i8*, %struct.__darwin_pthread_handler_rec* }
%struct.native_thread_data_struct = type { %struct.list_head, %struct.anon.7 }
%struct.anon.7 = type { %struct._opaque_pthread_cond_t, %struct._opaque_pthread_cond_t }
%struct._opaque_pthread_mutex_t = type { i64, [56 x i8] }
%struct.rb_unblock_callback = type { void (i8*)*, i8* }
%struct.rb_mutex_struct = type opaque
%struct.rb_thread_list_struct = type { %struct.rb_thread_list_struct*, %struct.rb_thread_struct* }
%union.anon.8 = type { %struct.RBasic }
%struct.RBasic = type { i64, i64 }
%struct.st_table = type { i8, i8, i8, i32, %struct.st_hash_type*, i64, i64*, i64, i64, %struct.st_table_entry* }
%struct.st_hash_type = type { i32 (...)*, i64 (...)* }
%struct.st_table_entry = type opaque
%struct.rb_ensure_list = type { %struct.rb_ensure_list*, %struct.rb_ensure_entry }
%struct.rb_ensure_entry = type { i64, i64 (...)*, i64 }
%struct.rb_trace_arg_struct = type { i32, %struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, i64, i64, i64, i64, i64, i32, i32, i64 }
%struct.anon.18 = type { i64*, i64*, i64, [37 x i32] }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%struct.rb_ast_body_struct = type { %struct.RNode*, i64, i32 }
%struct.RNode = type { i64, %union.anon.20, %union.anon.20, %union.anon.20, %struct.rb_code_location_struct, i32 }
%union.anon.20 = type { %struct.RNode* }

@closureInfo = local_unnamed_addr constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.10, i32 0, i32 0), %struct.anon.19 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@.str.10 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@ruby_current_execution_context_ptr = external local_unnamed_addr global %struct.rb_execution_context_struct*, align 8
@rb_cObject = external local_unnamed_addr constant i64, align 8
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.5 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.8 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@"stackFramePrecomputed_func_Object#hello" = internal unnamed_addr global i8* null, align 8
@rubyIdPrecomputed_hello = internal unnamed_addr global i64 0, align 8
@str_hello = private unnamed_addr constant [6 x i8] c"hello\00", align 1
@str_Object = private unnamed_addr constant [7 x i8] c"Object\00", align 1
@"str_test/testdata/compiler/method.rb" = private unnamed_addr constant [33 x i8] c"test/testdata/compiler/method.rb\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@"rubyIdPrecomputed_<" = internal unnamed_addr global i64 0, align 8
@"str_<" = private unnamed_addr constant [2 x i8] c"<\00", align 1
@"str_hello " = private unnamed_addr constant [7 x i8] c"hello \00", align 1
@"rubyIdPrecomputed_+" = internal unnamed_addr global i64 0, align 8
@"str_+" = private unnamed_addr constant [2 x i8] c"+\00", align 1
@rubyIdPrecomputed_puts = internal unnamed_addr global i64 0, align 8
@str_puts = private unnamed_addr constant [5 x i8] c"puts\00", align 1
@"stackFramePrecomputed_func_<root>.<static-init>$111" = internal unnamed_addr global i8* null, align 8
@"rubyIdPrecomputed_<top (required)>" = internal unnamed_addr global i64 0, align 8
@"str_<top (required)>" = private unnamed_addr constant [17 x i8] c"<top (required)>\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@llvm.global_ctors = appending global [8 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_hello, i8* bitcast (i64* @rubyIdPrecomputed_hello to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_Object#hello", i8* bitcast (i8** @"stackFramePrecomputed_func_Object#hello" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<", i8* bitcast (i64* @"rubyIdPrecomputed_<" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_+", i8* bitcast (i64* @"rubyIdPrecomputed_+" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_puts, i8* bitcast (i64* @rubyIdPrecomputed_puts to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<top (required)>", i8* bitcast (i64* @"rubyIdPrecomputed_<top (required)>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_<root>.<static-init>$111", i8* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }]
@str_sorbet = private unnamed_addr constant [7 x i8] c"sorbet\00", align 1

declare i64 @rb_str_plus(i64, i64) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8* %0) #1 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !0
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #14
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly %0) #2 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !0
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64 %0) local_unnamed_addr #1 {
  %2 = tail call i8* @rb_id2name(i64 %0) #14
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64 %0) local_unnamed_addr #1 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #14
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !4
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #14
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !7
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define void @stopInDebugger() local_unnamed_addr #1 {
  tail call void asm sideeffect "int $$3", "~{dirflag},~{fpsr},~{flags}"() #14, !srcloc !8
  ret void
}

declare i64 @rb_str_new(i8*, i64) local_unnamed_addr #0

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #0

declare i64 @rb_id2sym(i64) local_unnamed_addr #0

declare i8* @rb_obj_classname(i64) local_unnamed_addr #0

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #3

declare void @rb_define_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #0

declare i64 @rb_funcallv(i64, i64, i32, i64*) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32 %0) unnamed_addr #1 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.5, i64 0, i64 0), i32 %0, i32 1) #14
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !9
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #14
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #0

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64 %0) unnamed_addr #4 {
  %2 = load i64, i64* @rb_eTypeError, align 8, !tbaa !9
  %3 = tail call i8* @rb_obj_classname(i64 %0) #14
  tail call void (i64, i8*, ...) @rb_raise(i64 %2, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.8, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0), i8* %3, i64 %0) #15
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_raiseArity(i32 %0) unnamed_addr #5 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #15
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define internal fastcc i8* @sorbet_allocateRubyStackFrames(i64 %0, i64 %1, i64 %2, i32 %3) unnamed_addr #1 {
  %5 = tail call %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct* null, i64 %0, i64 %1, i64 %2, %struct.rb_iseq_struct* null, i32 1) #14
  %6 = ptrtoint %struct.rb_iseq_struct* %5 to i64
  tail call void @rb_gc_register_mark_object(i64 %6) #14
  %7 = add i32 %3, -2
  %8 = sext i32 %7 to i64
  %9 = tail call i8* @ruby_xmalloc2(i64 %8, i64 8) #14
  %10 = bitcast i8* %9 to %struct.rb_code_position_struct*
  %11 = tail call i8* @ruby_xmalloc2(i64 %8, i64 4) #14
  %12 = bitcast i8* %11 to i32*
  %13 = zext i32 %7 to i64
  %min.iters.check = icmp ult i32 %7, 8
  br i1 %min.iters.check, label %scalar.ph.preheader, label %vector.memcheck

scalar.ph.preheader:                              ; preds = %middle.block, %vector.memcheck, %4
  %.ph = phi i64 [ 0, %vector.memcheck ], [ 0, %4 ], [ %n.vec, %middle.block ]
  %14 = xor i64 %.ph, -1
  %15 = add nsw i64 %14, %13
  %xtraiter = and i64 %13, 7
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod, label %scalar.ph.prol.loopexit, label %scalar.ph.prol

scalar.ph.prol:                                   ; preds = %scalar.ph.preheader, %scalar.ph.prol
  %16 = phi i64 [ %21, %scalar.ph.prol ], [ %.ph, %scalar.ph.preheader ]
  %prol.iter = phi i64 [ %prol.iter.sub, %scalar.ph.prol ], [ %xtraiter, %scalar.ph.preheader ]
  %17 = trunc i64 %16 to i32
  %18 = add nsw i32 %17, 3
  %19 = getelementptr inbounds i32, i32* %12, i64 %16
  store i32 %17, i32* %19, align 4, !tbaa !0
  %20 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %16, i32 0
  store i32 %18, i32* %20, align 4, !tbaa !10
  %21 = add nuw nsw i64 %16, 1
  %prol.iter.sub = add nsw i64 %prol.iter, -1
  %prol.iter.cmp = icmp eq i64 %prol.iter.sub, 0
  br i1 %prol.iter.cmp, label %scalar.ph.prol.loopexit, label %scalar.ph.prol, !llvm.loop !12

scalar.ph.prol.loopexit:                          ; preds = %scalar.ph.prol, %scalar.ph.preheader
  %.unr = phi i64 [ %.ph, %scalar.ph.preheader ], [ %21, %scalar.ph.prol ]
  %22 = icmp ult i64 %15, 7
  br i1 %22, label %.loopexit, label %scalar.ph

vector.memcheck:                                  ; preds = %4
  %23 = shl nuw nsw i64 %13, 2
  %scevgep = getelementptr i8, i8* %11, i64 %23
  %24 = shl nuw nsw i64 %13, 3
  %25 = add nsw i64 %24, -4
  %scevgep1 = getelementptr i8, i8* %9, i64 %25
  %bound0 = icmp ult i8* %11, %scevgep1
  %bound1 = icmp ult i8* %9, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %scalar.ph.preheader, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %13, 4294967288
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.ind2 = phi <8 x i32> [ <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, %vector.ph ], [ %vec.ind.next3, %vector.body ]
  %26 = or i64 %index, 1
  %27 = or i64 %index, 2
  %28 = or i64 %index, 3
  %29 = or i64 %index, 4
  %30 = or i64 %index, 5
  %31 = or i64 %index, 6
  %32 = or i64 %index, 7
  %33 = add nsw <8 x i32> %vec.ind2, <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %34 = getelementptr inbounds i32, i32* %12, i64 %index
  %35 = bitcast i32* %34 to <8 x i32>*
  store <8 x i32> %vec.ind2, <8 x i32>* %35, align 4, !tbaa !0, !alias.scope !14, !noalias !17
  %36 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %index, i32 0
  %37 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %26, i32 0
  %38 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %27, i32 0
  %39 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %28, i32 0
  %40 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %29, i32 0
  %41 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %30, i32 0
  %42 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %31, i32 0
  %43 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %32, i32 0
  %44 = extractelement <8 x i32> %33, i32 0
  store i32 %44, i32* %36, align 4, !tbaa !10, !alias.scope !17
  %45 = extractelement <8 x i32> %33, i32 1
  store i32 %45, i32* %37, align 4, !tbaa !10, !alias.scope !17
  %46 = extractelement <8 x i32> %33, i32 2
  store i32 %46, i32* %38, align 4, !tbaa !10, !alias.scope !17
  %47 = extractelement <8 x i32> %33, i32 3
  store i32 %47, i32* %39, align 4, !tbaa !10, !alias.scope !17
  %48 = extractelement <8 x i32> %33, i32 4
  store i32 %48, i32* %40, align 4, !tbaa !10, !alias.scope !17
  %49 = extractelement <8 x i32> %33, i32 5
  store i32 %49, i32* %41, align 4, !tbaa !10, !alias.scope !17
  %50 = extractelement <8 x i32> %33, i32 6
  store i32 %50, i32* %42, align 4, !tbaa !10, !alias.scope !17
  %51 = extractelement <8 x i32> %33, i32 7
  store i32 %51, i32* %43, align 4, !tbaa !10, !alias.scope !17
  %index.next = add i64 %index, 8
  %vec.ind.next3 = add <8 x i32> %vec.ind2, <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %52 = icmp eq i64 %index.next, %n.vec
  br i1 %52, label %middle.block, label %vector.body, !llvm.loop !19

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 %n.vec, %13
  br i1 %cmp.n, label %.loopexit, label %scalar.ph.preheader

.loopexit:                                        ; preds = %scalar.ph, %scalar.ph.prol.loopexit, %middle.block
  %53 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %5, i64 0, i32 2
  %54 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %53, align 8, !tbaa !21
  %55 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %54, i64 0, i32 5, i32 0
  %56 = bitcast %struct.rb_code_position_struct** %55 to i8**
  store i8* %9, i8** %56, align 8, !tbaa !24
  %57 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %54, i64 0, i32 5, i32 1
  %58 = bitcast i32** %57 to i8**
  store i8* %11, i8** %58, align 8, !tbaa !33
  %59 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %54, i64 0, i32 1
  store i32 %7, i32* %59, align 4, !tbaa !34
  %60 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %54, i64 0, i32 5, i32 2
  store i32 %7, i32* %60, align 8, !tbaa !35
  tail call void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct* %5) #14
  %61 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %53, align 8, !tbaa !21
  %62 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %61, i64 0, i32 2
  store i64* null, i64** %62, align 8, !tbaa !36
  %63 = bitcast %struct.rb_iseq_struct* %5 to i8*
  ret i8* %63

scalar.ph:                                        ; preds = %scalar.ph.prol.loopexit, %scalar.ph
  %64 = phi i64 [ %104, %scalar.ph ], [ %.unr, %scalar.ph.prol.loopexit ]
  %65 = trunc i64 %64 to i32
  %66 = add nsw i32 %65, 3
  %67 = getelementptr inbounds i32, i32* %12, i64 %64
  store i32 %65, i32* %67, align 4, !tbaa !0
  %68 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %64, i32 0
  store i32 %66, i32* %68, align 4, !tbaa !10
  %69 = add nuw nsw i64 %64, 1
  %70 = trunc i64 %69 to i32
  %71 = add nsw i32 %70, 3
  %72 = getelementptr inbounds i32, i32* %12, i64 %69
  store i32 %70, i32* %72, align 4, !tbaa !0
  %73 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %69, i32 0
  store i32 %71, i32* %73, align 4, !tbaa !10
  %74 = add nuw nsw i64 %64, 2
  %75 = trunc i64 %74 to i32
  %76 = add nsw i32 %75, 3
  %77 = getelementptr inbounds i32, i32* %12, i64 %74
  store i32 %75, i32* %77, align 4, !tbaa !0
  %78 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %74, i32 0
  store i32 %76, i32* %78, align 4, !tbaa !10
  %79 = add nuw nsw i64 %64, 3
  %80 = trunc i64 %79 to i32
  %81 = add nsw i32 %80, 3
  %82 = getelementptr inbounds i32, i32* %12, i64 %79
  store i32 %80, i32* %82, align 4, !tbaa !0
  %83 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %79, i32 0
  store i32 %81, i32* %83, align 4, !tbaa !10
  %84 = add nuw nsw i64 %64, 4
  %85 = trunc i64 %84 to i32
  %86 = add nsw i32 %85, 3
  %87 = getelementptr inbounds i32, i32* %12, i64 %84
  store i32 %85, i32* %87, align 4, !tbaa !0
  %88 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %84, i32 0
  store i32 %86, i32* %88, align 4, !tbaa !10
  %89 = add nuw nsw i64 %64, 5
  %90 = trunc i64 %89 to i32
  %91 = add nsw i32 %90, 3
  %92 = getelementptr inbounds i32, i32* %12, i64 %89
  store i32 %90, i32* %92, align 4, !tbaa !0
  %93 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %89, i32 0
  store i32 %91, i32* %93, align 4, !tbaa !10
  %94 = add nuw nsw i64 %64, 6
  %95 = trunc i64 %94 to i32
  %96 = add nsw i32 %95, 3
  %97 = getelementptr inbounds i32, i32* %12, i64 %94
  store i32 %95, i32* %97, align 4, !tbaa !0
  %98 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %94, i32 0
  store i32 %96, i32* %98, align 4, !tbaa !10
  %99 = add nuw nsw i64 %64, 7
  %100 = trunc i64 %99 to i32
  %101 = add nsw i32 %100, 3
  %102 = getelementptr inbounds i32, i32* %12, i64 %99
  store i32 %100, i32* %102, align 4, !tbaa !0
  %103 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %10, i64 %99, i32 0
  store i32 %101, i32* %103, align 4, !tbaa !10
  %104 = add nuw nsw i64 %64, 8
  %105 = icmp eq i64 %104, %13
  br i1 %105, label %.loopexit, label %scalar.ph, !llvm.loop !37
}

declare %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct*, i64, i64, i64, %struct.rb_iseq_struct*, i32) local_unnamed_addr #0

declare void @rb_gc_register_mark_object(i64) local_unnamed_addr #0

declare i8* @ruby_xmalloc2(i64, i64) local_unnamed_addr #0

declare void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct*) local_unnamed_addr #0

; Function Attrs: nofree norecurse nounwind ssp uwtable
define i64** @sorbet_setRubyStackFrame(i8* %0) local_unnamed_addr #6 {
  %2 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !38
  %3 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %2, i64 0, i32 2
  %4 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %3, align 8, !tbaa !39
  %5 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 2
  %6 = bitcast %struct.rb_iseq_struct** %5 to i8**
  store i8* %0, i8** %6, align 8, !tbaa !42
  %7 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 4
  %8 = load i64*, i64** %7, align 8, !tbaa !44
  %9 = load i64, i64* %8, align 8, !tbaa !9
  %10 = and i64 %9, -129
  store i64 %10, i64* %8, align 8, !tbaa !9
  %11 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 0
  ret i64** %11
}

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #7

; Function Attrs: nounwind readnone speculatable willreturn
declare { i64, i1 } @llvm.sadd.with.overflow.i64(i64, i64) #8

declare i64 @rb_int2big(i64) local_unnamed_addr #0

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_Object#hello"(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #9 {
functionEntryInitializers:
  %callArgs = alloca [1 x i64], align 8
  %"rubyId_<" = load i64, i64* @"rubyIdPrecomputed_<", align 8
  %"rubyId_+" = load i64, i64* @"rubyIdPrecomputed_+", align 8
  %rubyId_puts = load i64, i64* @rubyIdPrecomputed_puts, align 8
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !45, !misexpect !46

BB2:                                              ; preds = %BB2.backedge, %typeTestSuccess
  %i.sroa.0.0 = phi i64 [ 1, %typeTestSuccess ], [ %i.sroa.0.0.be, %BB2.backedge ]
  store i64* inttoptr (i64 24 to i64*), i64** %23, align 8, !tbaa !38
  %1 = and i64 %i.sroa.0.0, 1
  %2 = icmp ne i64 %1, 0
  store i64 21, i64* %callArgsAddr, align 8
  br i1 %2, label %sorbet_rb_int_lt.exit, label %"slowSymCallIntrinsic_<", !prof !47, !misexpect !48

BB3:                                              ; preds = %"afterSymCallIntrinsic_<"
  store i64* inttoptr (i64 8 to i64*), i64** %23, align 8, !tbaa !38
  ret i64 8

BB5:                                              ; preds = %"afterSymCallIntrinsic_<"
  store i64* inttoptr (i64 32 to i64*), i64** %23, align 8, !tbaa !38
  %3 = call i64 @rb_str_new(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @"str_hello ", i64 0, i64 0), i64 6) #14
  %4 = and i64 %3, 7
  %5 = icmp ne i64 %4, 0
  %6 = and i64 %3, -9
  %7 = icmp eq i64 %6, 0
  %8 = or i1 %5, %7
  br i1 %8, label %sorbet_isa_String.exit.thread, label %sorbet_isa_String.exit, !prof !49

sorbet_isa_String.exit.thread:                    ; preds = %BB5
  store i64 %rawArg_name, i64* %callArgsAddr, align 8
  br label %"slowSymCallIntrinsic_+"

sorbet_isa_String.exit:                           ; preds = %BB5
  %9 = inttoptr i64 %3 to %struct.RBasic*
  %10 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %9, i64 0, i32 0
  %11 = load i64, i64* %10, align 8, !tbaa !4
  %12 = and i64 %11, 31
  %13 = icmp eq i64 %12, 5
  store i64 %rawArg_name, i64* %callArgsAddr, align 8
  br i1 %13, label %"fastSymCallIntrinsic_+", label %"slowSymCallIntrinsic_+", !prof !47, !misexpect !48

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %"stackFrame_func_Object#hello74" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_Object#hello" to i64*), align 8
  %rawArg_name = load i64, i64* %argArray, align 8
  %14 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !38
  %15 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %14, i64 0, i32 2
  %16 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %15, align 8, !tbaa !39
  %17 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %16, i64 0, i32 2
  %18 = bitcast %struct.rb_iseq_struct** %17 to i64*
  store i64 %"stackFrame_func_Object#hello74", i64* %18, align 8, !tbaa !42
  %19 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %16, i64 0, i32 4
  %20 = load i64*, i64** %19, align 8, !tbaa !44
  %21 = load i64, i64* %20, align 8, !tbaa !9
  %22 = and i64 %21, -129
  store i64 %22, i64* %20, align 8, !tbaa !9
  %23 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %16, i64 0, i32 0
  store i64* inttoptr (i64 8 to i64*), i64** %23, align 8, !tbaa !38
  %24 = load i64, i64* @rb_cObject, align 8
  %25 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %24) #7
  %26 = icmp eq i64 %25, 20
  br i1 %26, label %typeTestSuccess, label %codeRepl, !prof !47, !misexpect !48

typeTestSuccess:                                  ; preds = %fillRequiredArgs
  store i64* inttoptr (i64 16 to i64*), i64** %23, align 8, !tbaa !38
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  br label %BB2

codeRepl:                                         ; preds = %fillRequiredArgs
  tail call fastcc void @"func_Object#hello.cold.1"(i64 %selfRaw) #16
  unreachable

"afterSymCallIntrinsic_<":                        ; preds = %"slowSymCallIntrinsic_<", %sorbet_rb_int_lt.exit
  %"symIntrinsicRawPhi_<" = phi i64 [ %31, %sorbet_rb_int_lt.exit ], [ %29, %"slowSymCallIntrinsic_<" ]
  %27 = and i64 %"symIntrinsicRawPhi_<", -9
  %28 = icmp eq i64 %27, 0
  br i1 %28, label %BB3, label %BB5

"slowSymCallIntrinsic_<":                         ; preds = %BB2
  %29 = call i64 @rb_funcallv(i64 %i.sroa.0.0, i64 %"rubyId_<", i32 1, i64* nonnull %callArgsAddr) #14
  br label %"afterSymCallIntrinsic_<"

sorbet_rb_int_lt.exit:                            ; preds = %BB2
  %30 = icmp slt i64 %i.sroa.0.0, 20
  %31 = select i1 %30, i64 20, i64 0
  br label %"afterSymCallIntrinsic_<"

"afterSymCallIntrinsic_+":                        ; preds = %"slowSymCallIntrinsic_+", %"fastSymCallIntrinsic_+"
  %"symIntrinsicRawPhi_+" = phi i64 [ %34, %"fastSymCallIntrinsic_+" ], [ %33, %"slowSymCallIntrinsic_+" ]
  store i64 %"symIntrinsicRawPhi_+", i64* %callArgsAddr, align 8
  %32 = call i64 @rb_funcallv(i64 %selfRaw, i64 %rubyId_puts, i32 1, i64* nonnull %callArgsAddr) #14
  store i64* inttoptr (i64 40 to i64*), i64** %23, align 8, !tbaa !38
  store i64 3, i64* %callArgsAddr, align 8
  br i1 %2, label %"fastSymCallIntrinsic_+48", label %"slowSymCallIntrinsic_+47"

"slowSymCallIntrinsic_+":                         ; preds = %sorbet_isa_String.exit.thread, %sorbet_isa_String.exit
  %33 = call i64 @rb_funcallv(i64 %3, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #14
  br label %"afterSymCallIntrinsic_+"

"fastSymCallIntrinsic_+":                         ; preds = %sorbet_isa_String.exit
  %34 = call i64 @rb_str_plus(i64 %3, i64 %rawArg_name) #14, !noalias !50
  br label %"afterSymCallIntrinsic_+"

"slowSymCallIntrinsic_+47":                       ; preds = %"afterSymCallIntrinsic_+"
  %35 = call i64 @rb_funcallv(i64 %i.sroa.0.0, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #14
  br label %BB2.backedge

"fastSymCallIntrinsic_+48":                       ; preds = %"afterSymCallIntrinsic_+"
  %36 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %i.sroa.0.0, i64 2) #14
  %37 = extractvalue { i64, i1 } %36, 1
  %38 = extractvalue { i64, i1 } %36, 0
  br i1 %37, label %39, label %BB2.backedge

39:                                               ; preds = %"fastSymCallIntrinsic_+48"
  %40 = ashr i64 %38, 1
  %41 = xor i64 %40, -9223372036854775808
  %42 = call i64 @rb_int2big(i64 %41) #14, !noalias !53
  br label %BB2.backedge

BB2.backedge:                                     ; preds = %39, %"fastSymCallIntrinsic_+48", %"slowSymCallIntrinsic_+47"
  %i.sroa.0.0.be = phi i64 [ %35, %"slowSymCallIntrinsic_+47" ], [ %42, %39 ], [ %38, %"fastSymCallIntrinsic_+48" ]
  br label %BB2
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_Object#hello"() #10 {
entryInitializers:
  %0 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_hello, i64 0, i64 0), i64 5) #14
  %1 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([33 x i8], [33 x i8]* @"str_test/testdata/compiler/method.rb", i64 0, i64 0), i64 32) #14
  %2 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([33 x i8], [33 x i8]* @"str_test/testdata/compiler/method.rb", i64 0, i64 0), i64 32) #14
  %3 = tail call fastcc i8* @sorbet_allocateRubyStackFrames(i64 %0, i64 %1, i64 %2, i32 9)
  store i8* %3, i8** @"stackFramePrecomputed_func_Object#hello", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_hello() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_hello, i64 0, i64 0), i64 5) #14
  store i64 %0, i64* @rubyIdPrecomputed_hello, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<"() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_<", i64 0, i64 0), i64 1) #14
  store i64 %0, i64* @"rubyIdPrecomputed_<", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_+"() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_+", i64 0, i64 0), i64 1) #14
  store i64 %0, i64* @"rubyIdPrecomputed_+", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_puts() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_puts, i64 0, i64 0), i64 4) #14
  store i64 %0, i64* @rubyIdPrecomputed_puts, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_<root>.<static-init>$111"() #10 {
entryInitializers:
  %0 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #14
  %1 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([33 x i8], [33 x i8]* @"str_test/testdata/compiler/method.rb", i64 0, i64 0), i64 32) #14
  %2 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([33 x i8], [33 x i8]* @"str_test/testdata/compiler/method.rb", i64 0, i64 0), i64 32) #14
  %3 = tail call fastcc i8* @sorbet_allocateRubyStackFrames(i64 %0, i64 %1, i64 %2, i32 10)
  store i8* %3, i8** @"stackFramePrecomputed_func_<root>.<static-init>$111", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<top (required)>"() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #14
  store i64 %0, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #10 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #14
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_compiler_method() local_unnamed_addr #11 {
"func_<root>.<static-init>$111.exit":
  %callArgs.i = alloca [2 x i64], align 8
  %0 = load i64, i64* @rb_cObject, align 8
  %1 = bitcast [2 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1)
  %rubyId_hello.i = load i64, i64* @rubyIdPrecomputed_hello, align 8
  %"stackFrame_func_<root>.<static-init>$1112.i" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i64*), align 8
  %2 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !38
  %3 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %2, i64 0, i32 2
  %4 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %3, align 8, !tbaa !39
  %5 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 2
  %6 = bitcast %struct.rb_iseq_struct** %5 to i64*
  store i64 %"stackFrame_func_<root>.<static-init>$1112.i", i64* %6, align 8, !tbaa !42
  %7 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 4
  %8 = load i64*, i64** %7, align 8, !tbaa !44
  %9 = load i64, i64* %8, align 8, !tbaa !9
  %10 = and i64 %9, -129
  store i64 %10, i64* %8, align 8, !tbaa !9
  %11 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 0
  store i64* inttoptr (i64 8 to i64*), i64** %11, align 8, !tbaa !38
  %callArgsAddr.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i, i64 0, i64 0
  %rawSym.i = tail call i64 @rb_id2sym(i64 %rubyId_hello.i) #14
  tail call void @rb_define_method(i64 %0, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_hello, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_Object#hello" to i64 (...)*), i32 -1) #14
  store i64* inttoptr (i64 64 to i64*), i64** %11, align 8, !tbaa !38
  %12 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_sorbet, i64 0, i64 0), i64 6) #14
  store i64 %12, i64* %callArgsAddr.i, align 8
  %13 = call i64 @rb_funcallv(i64 %0, i64 %rubyId_hello.i, i32 1, i64* nonnull %callArgsAddr.i) #14
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1)
  ret void
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #12

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #12

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_Object#hello.cold.1"(i64 %selfRaw) unnamed_addr #13 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw)
  unreachable
}

attributes #0 = { "addedToSilenceEmptyAttrsError" }
attributes #1 = { nounwind ssp uwtable }
attributes #2 = { norecurse nounwind readnone ssp uwtable }
attributes #3 = { noreturn }
attributes #4 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #5 = { noreturn nounwind ssp uwtable }
attributes #6 = { nofree norecurse nounwind ssp uwtable }
attributes #7 = { nounwind readnone }
attributes #8 = { nounwind readnone speculatable willreturn }
attributes #9 = { nounwind sspreq uwtable }
attributes #10 = { nounwind ssp }
attributes #11 = { nounwind sspreq }
attributes #12 = { argmemonly nounwind willreturn }
attributes #13 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #14 = { nounwind }
attributes #15 = { noreturn nounwind }
attributes #16 = { noinline }

!0 = !{!1, !1, i64 0}
!1 = !{!"int", !2, i64 0}
!2 = !{!"omnipotent char", !3, i64 0}
!3 = !{!"Simple C/C++ TBAA"}
!4 = !{!5, !6, i64 0}
!5 = !{!"RBasic", !6, i64 0, !6, i64 8}
!6 = !{!"long", !2, i64 0}
!7 = !{!2, !2, i64 0}
!8 = !{i32 1088}
!9 = !{!6, !6, i64 0}
!10 = !{!11, !1, i64 0}
!11 = !{!"iseq_insn_info_entry", !1, i64 0, !1, i64 4}
!12 = distinct !{!12, !13}
!13 = !{!"llvm.loop.unroll.disable"}
!14 = !{!15}
!15 = distinct !{!15, !16}
!16 = distinct !{!16, !"LVerDomain"}
!17 = !{!18}
!18 = distinct !{!18, !16}
!19 = distinct !{!19, !20}
!20 = !{!"llvm.loop.isvectorized", i32 1}
!21 = !{!22, !23, i64 16}
!22 = !{!"rb_iseq_struct", !6, i64 0, !6, i64 8, !23, i64 16, !2, i64 24}
!23 = !{!"any pointer", !2, i64 0}
!24 = !{!25, !23, i64 120}
!25 = !{!"rb_iseq_constant_body", !2, i64 0, !1, i64 4, !23, i64 8, !26, i64 16, !28, i64 64, !31, i64 120, !23, i64 152, !23, i64 160, !23, i64 168, !23, i64 176, !23, i64 184, !23, i64 192, !23, i64 200, !32, i64 208, !1, i64 240, !1, i64 244, !1, i64 248, !1, i64 252, !1, i64 256, !2, i64 260}
!26 = !{!"", !27, i64 0, !1, i64 4, !1, i64 8, !1, i64 12, !1, i64 16, !1, i64 20, !1, i64 24, !1, i64 28, !23, i64 32, !23, i64 40}
!27 = !{!"", !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0}
!28 = !{!"rb_iseq_location_struct", !6, i64 0, !6, i64 8, !6, i64 16, !6, i64 24, !1, i64 32, !29, i64 36}
!29 = !{!"rb_code_location_struct", !30, i64 0, !30, i64 8}
!30 = !{!"rb_code_position_struct", !1, i64 0, !1, i64 4}
!31 = !{!"iseq_insn_info", !23, i64 0, !23, i64 8, !1, i64 16, !23, i64 24}
!32 = !{!"", !6, i64 0, !6, i64 8, !6, i64 16, !23, i64 24}
!33 = !{!25, !23, i64 128}
!34 = !{!25, !1, i64 4}
!35 = !{!25, !1, i64 136}
!36 = !{!25, !23, i64 8}
!37 = distinct !{!37, !20}
!38 = !{!23, !23, i64 0}
!39 = !{!40, !23, i64 16}
!40 = !{!"rb_execution_context_struct", !23, i64 0, !6, i64 8, !23, i64 16, !23, i64 24, !23, i64 32, !1, i64 40, !1, i64 44, !23, i64 48, !23, i64 56, !23, i64 64, !6, i64 72, !6, i64 80, !23, i64 88, !6, i64 96, !23, i64 104, !23, i64 112, !6, i64 120, !6, i64 128, !2, i64 136, !2, i64 137, !6, i64 144, !41, i64 152}
!41 = !{!"", !23, i64 0, !23, i64 8, !6, i64 16, !2, i64 24}
!42 = !{!43, !23, i64 16}
!43 = !{!"rb_control_frame_struct", !23, i64 0, !23, i64 8, !23, i64 16, !6, i64 24, !23, i64 32, !23, i64 40, !23, i64 48}
!44 = !{!43, !23, i64 32}
!45 = !{!"branch_weights", i32 4000000, i32 4001}
!46 = !{!"misexpect", i64 1, i64 2000, i64 1}
!47 = !{!"branch_weights", i32 2000, i32 1}
!48 = !{!"misexpect", i64 0, i64 2000, i64 1}
!49 = !{!"branch_weights", i32 1073205, i32 2146410443}
!50 = !{!51}
!51 = distinct !{!51, !52, !"sorbet_int_rb_str_plus: argument 0"}
!52 = distinct !{!52, !"sorbet_int_rb_str_plus"}
!53 = !{!54}
!54 = distinct !{!54, !55, !"sorbet_rb_int_plus: argument 0"}
!55 = distinct !{!55, !"sorbet_rb_int_plus"}
