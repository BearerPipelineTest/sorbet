; ModuleID = 'payload'
source_filename = "compiler/IRHelpers/payload.c"
target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.1, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.1 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.RBasic = type { i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%union.anon.0 = type { i64 }

@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@rb_cObject = external local_unnamed_addr constant i64, align 8
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.3 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.6 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@.str.7 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@closureInfo = local_unnamed_addr constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.7, i32 0, i32 0), %struct.anon.1 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@rubyIdPrecomputed_hello = internal unnamed_addr global i64 0, align 8
@str_hello = private unnamed_addr constant [6 x i8] c"hello\00", align 1
@str_Object = private unnamed_addr constant [7 x i8] c"Object\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@"rubyIdPrecomputed_<" = internal unnamed_addr global i64 0, align 8
@"str_<" = private unnamed_addr constant [2 x i8] c"<\00", align 1
@"str_hello " = private unnamed_addr constant [7 x i8] c"hello \00", align 1
@"rubyIdPrecomputed_+" = internal unnamed_addr global i64 0, align 8
@"str_+" = private unnamed_addr constant [2 x i8] c"+\00", align 1
@rubyIdPrecomputed_puts = internal unnamed_addr global i64 0, align 8
@str_puts = private unnamed_addr constant [5 x i8] c"puts\00", align 1
@"rubyIdPrecomputed_<static-init>" = internal unnamed_addr global i64 0, align 8
@"str_<static-init>" = private unnamed_addr constant [14 x i8] c"<static-init>\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@llvm.global_ctors = appending global [6 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_hello, i8* bitcast (i64* @rubyIdPrecomputed_hello to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<", i8* bitcast (i64* @"rubyIdPrecomputed_<" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_+", i8* bitcast (i64* @"rubyIdPrecomputed_+" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_puts, i8* bitcast (i64* @rubyIdPrecomputed_puts to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<static-init>", i8* bitcast (i64* @"rubyIdPrecomputed_<static-init>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }]
@str_sorbet = private unnamed_addr constant [7 x i8] c"sorbet\00", align 1

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i8* @rb_id2name(i64 %0) #13
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #13
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !0
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #13
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !5
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #1

declare i64 @rb_str_new(i8*, i64) local_unnamed_addr #1

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #1

declare i64 @rb_id2sym(i64) local_unnamed_addr #1

declare i8* @rb_obj_classname(i64) local_unnamed_addr #1

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #2

declare void @rb_define_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #1

declare i64 @rb_funcallv(i64, i64, i32, i64*) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32 %0) unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.3, i64 0, i64 0), i32 %0, i32 1) #13
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !6
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #13
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #1

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64 %0) unnamed_addr #3 {
  %2 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  %3 = tail call i8* @rb_obj_classname(i64 %0) #13
  tail call void (i64, i8*, ...) @rb_raise(i64 %2, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0), i8* %3, i64 %0) #14
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_rb_error_arity(i32 %0) unnamed_addr #4 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #14
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8* %0) #0 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !7
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #13
  ret void
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #1

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly %0) #5 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !7
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #6

declare i64 @rb_int2big(i64) local_unnamed_addr #1

; Function Attrs: nounwind readnone speculatable willreturn
declare { i64, i1 } @llvm.sadd.with.overflow.i64(i64, i64) #7

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_Object#hello"(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #8 {
functionEntryInitializers:
  %callArgs = alloca [1 x i64], align 8
  %"rubyId_<" = load i64, i64* @"rubyIdPrecomputed_<", align 8
  %"rubyId_+" = load i64, i64* @"rubyIdPrecomputed_+", align 8
  %rubyId_puts = load i64, i64* @rubyIdPrecomputed_puts, align 8
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !9, !misexpect !10

BB2:                                              ; preds = %BB2.backedge, %BB2.preheader
  %i.sroa.0.0 = phi i64 [ 1, %BB2.preheader ], [ %i.sroa.0.0.be, %BB2.backedge ]
  %1 = and i64 %i.sroa.0.0, 1
  %2 = icmp ne i64 %1, 0
  store i64 21, i64* %callArgsAddr, align 8
  br i1 %2, label %sorbet_rb_int_lt.exit, label %"slowSymCallIntrinsic_<", !prof !11, !misexpect !12

BB3:                                              ; preds = %"afterSymCallIntrinsic_<"
  ret i64 8

BB5:                                              ; preds = %"afterSymCallIntrinsic_<"
  %3 = call i64 @rb_str_new(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @"str_hello ", i64 0, i64 0), i64 6) #13
  store i64 %rawArg_name, i64* %callArgsAddr, align 8
  %4 = call i64 @rb_funcallv(i64 %3, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #13
  store i64 %4, i64* %callArgsAddr, align 8
  %5 = call i64 @rb_funcallv(i64 %selfRaw, i64 %rubyId_puts, i32 1, i64* nonnull %callArgsAddr) #13
  store i64 3, i64* %callArgsAddr, align 8
  br i1 %2, label %"fastSymCallIntrinsic_+", label %"slowSymCallIntrinsic_+"

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_rb_error_arity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %rawArg_name = load i64, i64* %argArray, align 8
  %6 = load i64, i64* @rb_cObject, align 8
  %7 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %6) #6
  %8 = icmp eq i64 %7, 20
  br i1 %8, label %BB2.preheader, label %codeRepl, !prof !11, !misexpect !12

BB2.preheader:                                    ; preds = %fillRequiredArgs
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  br label %BB2

codeRepl:                                         ; preds = %fillRequiredArgs
  tail call fastcc void @"func_Object#hello.cold.1"(i64 %selfRaw) #15
  unreachable

"afterSymCallIntrinsic_<":                        ; preds = %"slowSymCallIntrinsic_<", %sorbet_rb_int_lt.exit
  %"symIntrinsicRawPhi_<" = phi i64 [ %13, %sorbet_rb_int_lt.exit ], [ %11, %"slowSymCallIntrinsic_<" ]
  %9 = and i64 %"symIntrinsicRawPhi_<", -9
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %BB3, label %BB5

"slowSymCallIntrinsic_<":                         ; preds = %BB2
  %11 = call i64 @rb_funcallv(i64 %i.sroa.0.0, i64 %"rubyId_<", i32 1, i64* nonnull %callArgsAddr) #13
  br label %"afterSymCallIntrinsic_<"

sorbet_rb_int_lt.exit:                            ; preds = %BB2
  %12 = icmp slt i64 %i.sroa.0.0, 20
  %13 = select i1 %12, i64 20, i64 0
  br label %"afterSymCallIntrinsic_<"

"slowSymCallIntrinsic_+":                         ; preds = %BB5
  %14 = call i64 @rb_funcallv(i64 %i.sroa.0.0, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #13
  br label %BB2.backedge

"fastSymCallIntrinsic_+":                         ; preds = %BB5
  %15 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %i.sroa.0.0, i64 2) #13
  %16 = extractvalue { i64, i1 } %15, 1
  %17 = extractvalue { i64, i1 } %15, 0
  br i1 %16, label %18, label %BB2.backedge

18:                                               ; preds = %"fastSymCallIntrinsic_+"
  %19 = ashr i64 %17, 1
  %20 = xor i64 %19, -9223372036854775808
  %21 = call i64 @rb_int2big(i64 %20) #13, !noalias !13
  br label %BB2.backedge

BB2.backedge:                                     ; preds = %18, %"fastSymCallIntrinsic_+", %"slowSymCallIntrinsic_+"
  %i.sroa.0.0.be = phi i64 [ %14, %"slowSymCallIntrinsic_+" ], [ %21, %18 ], [ %17, %"fastSymCallIntrinsic_+" ]
  br label %BB2
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_hello() #9 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_hello, i64 0, i64 0), i64 5) #13
  store i64 %0, i64* @rubyIdPrecomputed_hello, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<"() #9 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_<", i64 0, i64 0), i64 1) #13
  store i64 %0, i64* @"rubyIdPrecomputed_<", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_+"() #9 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_+", i64 0, i64 0), i64 1) #13
  store i64 %0, i64* @"rubyIdPrecomputed_+", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_puts() #9 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_puts, i64 0, i64 0), i64 4) #13
  store i64 %0, i64* @rubyIdPrecomputed_puts, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<static-init>"() #9 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_<static-init>", i64 0, i64 0), i64 13) #13
  store i64 %0, i64* @"rubyIdPrecomputed_<static-init>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #9 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #13
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_compiler_method() local_unnamed_addr #10 {
"func_<root>.<static-init>$111.exit":
  %callArgs.i = alloca [2 x i64], align 8
  %0 = load i64, i64* @rb_cObject, align 8
  %1 = bitcast [2 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1)
  %rubyId_hello.i = load i64, i64* @rubyIdPrecomputed_hello, align 8
  %callArgsAddr.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i, i64 0, i64 0
  %rawSym.i = tail call i64 @rb_id2sym(i64 %rubyId_hello.i) #13
  tail call void @rb_define_method(i64 %0, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_hello, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_Object#hello" to i64 (...)*), i32 -1) #13
  %2 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_sorbet, i64 0, i64 0), i64 6) #13
  store i64 %2, i64* %callArgsAddr.i, align 8
  %3 = call i64 @rb_funcallv(i64 %0, i64 %rubyId_hello.i, i32 1, i64* nonnull %callArgsAddr.i) #13
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1)
  ret void
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #11

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #11

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_Object#hello.cold.1"(i64 %selfRaw) unnamed_addr #12 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw)
  unreachable
}

attributes #0 = { nounwind ssp uwtable }
attributes #1 = { "addedToSilenceEmptyAttrsError" }
attributes #2 = { noreturn }
attributes #3 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #4 = { noreturn nounwind ssp uwtable }
attributes #5 = { norecurse nounwind readnone ssp uwtable }
attributes #6 = { nounwind readnone }
attributes #7 = { nounwind readnone speculatable willreturn }
attributes #8 = { nounwind sspreq uwtable }
attributes #9 = { nounwind ssp }
attributes #10 = { nounwind sspreq }
attributes #11 = { argmemonly nounwind willreturn }
attributes #12 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #13 = { nounwind }
attributes #14 = { noreturn nounwind }
attributes #15 = { noinline }

!0 = !{!1, !2, i64 0}
!1 = !{!"RBasic", !2, i64 0, !2, i64 8}
!2 = !{!"long", !3, i64 0}
!3 = !{!"omnipotent char", !4, i64 0}
!4 = !{!"Simple C/C++ TBAA"}
!5 = !{!3, !3, i64 0}
!6 = !{!2, !2, i64 0}
!7 = !{!8, !8, i64 0}
!8 = !{!"int", !3, i64 0}
!9 = !{!"branch_weights", i32 4000000, i32 4001}
!10 = !{!"misexpect", i64 1, i64 2000, i64 1}
!11 = !{!"branch_weights", i32 2000, i32 1}
!12 = !{!"misexpect", i64 0, i64 2000, i64 1}
!13 = !{!14}
!14 = distinct !{!14, !15, !"sorbet_rb_int_plus: argument 0"}
!15 = distinct !{!15, !"sorbet_rb_int_plus"}
