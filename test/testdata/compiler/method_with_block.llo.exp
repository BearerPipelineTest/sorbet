; ModuleID = 'payload'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.20, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.20 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.rb_vm_struct = type { i64, %struct.rb_global_vm_lock_struct, %struct.rb_thread_struct*, %struct.rb_thread_struct*, i8*, i64, %union.pthread_mutex_t, %union.anon.12, %union.anon.12, %union.anon.12, %union.anon.12, i64, i32, i8, i32, i64, [5 x i64], i64, i64, i64, i64, i64, i64, i64, %struct.st_table*, %struct.st_table*, %struct.anon.18, %struct.rb_hook_list_struct, %struct.st_table*, %struct.rb_postponed_job_struct*, i32, i32, %union.anon.12, %union.pthread_mutex_t, i64, i64, i64, i64, i64, i32, i64, %struct.rb_objspace*, %struct.rb_at_exit_list*, i64*, %struct.st_table*, %struct.anon.19, [28 x i16] }
%struct.rb_global_vm_lock_struct = type { %struct.rb_thread_struct*, %union.pthread_mutex_t, %union.anon.12, %struct.rb_thread_struct*, i32, %union.pthread_cond_t, %union.pthread_cond_t, i32, i32 }
%union.pthread_cond_t = type { %struct.anon.14 }
%struct.anon.14 = type { i32, i32, i64, i64, i64, i8*, i32, i32 }
%struct.rb_thread_struct = type { %struct.list_node, i64, %struct.rb_vm_struct*, %struct.rb_execution_context_struct*, i64, %struct.rb_calling_info*, i64, i64, i64, i8, i8, i32, %struct.native_thread_data_struct, i8*, i64, i64, i64, i64, %union.pthread_mutex_t, %struct.rb_unblock_callback, i64, %struct.rb_mutex_struct*, %struct.rb_thread_list_struct*, %union.anon.15, i32, i64, %struct.rb_fiber_struct*, [1 x %struct.__jmp_buf_tag], i64 }
%struct.list_node = type { %struct.list_node*, %struct.list_node* }
%struct.rb_execution_context_struct = type { i64*, i64, %struct.rb_control_frame_struct*, %struct.rb_vm_tag*, %struct.rb_vm_protect_tag*, i32, i32, %struct.rb_fiber_struct*, %struct.rb_thread_struct*, %struct.st_table*, i64, i64, i64*, i64, %struct.rb_ensure_list*, %struct.rb_trace_arg_struct*, i64, i64, i8, i8, i64, %struct.anon.11 }
%struct.rb_control_frame_struct = type { i64*, i64*, %struct.rb_iseq_struct*, i64, i64*, i8*, i64* }
%struct.rb_iseq_struct = type { i64, i64, %struct.rb_iseq_constant_body*, %union.anon.8 }
%struct.rb_iseq_constant_body = type { i32, i32, i64*, %struct.anon.1, %struct.rb_iseq_location_struct, %struct.iseq_insn_info, i64*, %struct.iseq_catch_table*, %struct.rb_iseq_struct*, %struct.rb_iseq_struct*, %union.iseq_inline_storage_entry*, %struct.rb_call_info*, %struct.rb_call_cache*, %struct.anon.7, i32, i32, i32, i32, i32, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*)*, i64, %struct.rb_mjit_unit*, i8 }
%struct.anon.1 = type { %struct.anon.2, i32, i32, i32, i32, i32, i32, i32, i64*, %struct.rb_iseq_param_keyword* }
%struct.anon.2 = type { i8, [3 x i8] }
%struct.rb_iseq_param_keyword = type { i32, i32, i32, i32, i64*, i64* }
%struct.rb_iseq_location_struct = type { i64, i64, i64, i64, i32, %struct.rb_code_location_struct }
%struct.rb_code_location_struct = type { %struct.rb_code_position_struct, %struct.rb_code_position_struct }
%struct.rb_code_position_struct = type { i32, i32 }
%struct.iseq_insn_info = type { %struct.rb_code_position_struct*, i32*, i32, %struct.succ_index_table* }
%struct.succ_index_table = type opaque
%struct.iseq_catch_table = type opaque
%union.iseq_inline_storage_entry = type { %struct.iseq_inline_cache_entry }
%struct.iseq_inline_cache_entry = type { i64, %struct.rb_cref_struct*, %union.anon.0 }
%struct.rb_cref_struct = type { i64, i64, i64, %struct.rb_cref_struct*, %struct.anon.2 }
%union.anon.0 = type { i64 }
%struct.rb_call_info = type { i64, i32, i32 }
%struct.rb_call_cache = type { i64, i64, %struct.rb_callable_method_entry_struct*, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, %struct.rb_calling_info*, %struct.rb_call_info*, %struct.rb_call_cache*)*, %union.anon.6 }
%struct.rb_callable_method_entry_struct = type { i64, i64, %struct.rb_method_definition_struct*, i64, i64 }
%struct.rb_method_definition_struct = type { i64, %union.anon.5, i64 }
%union.anon.5 = type { %struct.rb_method_cfunc_struct }
%struct.rb_method_cfunc_struct = type { i64 (...)*, i64 (i64 (...)*, i64, i32, i64*)*, i32 }
%union.anon.6 = type { i32 }
%struct.anon.7 = type { i64, i64, i64, i64* }
%struct.rb_mjit_unit = type opaque
%union.anon.8 = type { %struct.anon.9 }
%struct.anon.9 = type { i64, i32 }
%struct.rb_vm_tag = type { i64, i64, [1 x %struct.__jmp_buf_tag], %struct.rb_vm_tag*, i32 }
%struct.rb_vm_protect_tag = type { %struct.rb_vm_protect_tag* }
%struct.rb_ensure_list = type { %struct.rb_ensure_list*, %struct.rb_ensure_entry }
%struct.rb_ensure_entry = type { i64, i64 (...)*, i64 }
%struct.rb_trace_arg_struct = type { i32, %struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, i64, i64, i64, i64, i64, i32, i32, i64 }
%struct.anon.11 = type { i64*, i64*, i64, [1 x %struct.__jmp_buf_tag] }
%struct.rb_calling_info = type { i64, i64, i32 }
%struct.native_thread_data_struct = type { %union.anon.12, %union.anon.13 }
%union.anon.13 = type { %union.pthread_cond_t }
%struct.rb_unblock_callback = type { void (i8*)*, i8* }
%struct.rb_mutex_struct = type opaque
%struct.rb_thread_list_struct = type { %struct.rb_thread_list_struct*, %struct.rb_thread_struct* }
%union.anon.15 = type { %struct.RBasic }
%struct.RBasic = type { i64, i64 }
%struct.rb_fiber_struct = type opaque
%struct.__jmp_buf_tag = type { [8 x i64], i32, %struct.__sigset_t }
%struct.__sigset_t = type { [16 x i64] }
%struct.anon.18 = type { [65 x i64], [65 x i8] }
%struct.rb_hook_list_struct = type { %struct.rb_event_hook_struct*, i32, i32, i32 }
%struct.rb_event_hook_struct = type opaque
%struct.rb_postponed_job_struct = type opaque
%union.anon.12 = type { %struct.list_node }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%struct.rb_objspace = type opaque
%struct.rb_at_exit_list = type { void (%struct.rb_vm_struct*)*, %struct.rb_at_exit_list* }
%struct.st_table = type { i8, i8, i8, i32, %struct.st_hash_type*, i64, i64*, i64, i64, %struct.st_table_entry* }
%struct.st_hash_type = type { i32 (...)*, i64 (...)* }
%struct.st_table_entry = type opaque
%struct.anon.19 = type { i64, i64, i64, i64 }
%struct.FunctionInlineCache = type { %struct.rb_callable_method_entry_struct*, i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%struct.OnigEncodingTypeST = type { i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i8*, i32, i32, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8**, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i32 (i32, i32*, i32, i8*)*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, i8*, %struct.OnigCaseFoldCodeItem*, %struct.OnigEncodingTypeST*)*, i32 (%struct.OnigEncodingTypeST*, i8*, i8*)*, i32 (i32, i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i32*, i32**, %struct.OnigEncodingTypeST*)*, i8* (i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32*, i8**, i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32, i32 }
%struct.OnigCaseFoldCodeItem = type { i32, i32, [3 x i32] }
%struct.rb_ast_body_struct = type { %struct.RNode*, i64, i32 }
%struct.RNode = type { i64, %union.anon.21, %union.anon.21, %union.anon.21, %struct.rb_code_location_struct, i32 }
%union.anon.21 = type { %struct.RNode* }
%struct.RClass = type { %struct.RBasic, i64, %struct.rb_classext_struct*, %struct.rb_id_table* }
%struct.rb_classext_struct = type { %struct.st_table*, %struct.st_table*, %struct.rb_id_table*, %struct.rb_id_table*, %struct.rb_subclass_entry*, %struct.rb_subclass_entry**, %struct.rb_subclass_entry**, i64, i64, i64, i64 (i64)* }
%struct.rb_subclass_entry = type { i64, %struct.rb_subclass_entry* }
%struct.rb_id_table = type opaque
%struct.RTypedData = type { %struct.RBasic, %struct.rb_data_type_struct*, i64, i8* }
%struct.sorbet_Closure = type { i32, [0 x i64] }

@closureInfo = constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.10, i32 0, i32 0), %struct.anon.20 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@.str.10 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@ruby_current_vm_ptr = external local_unnamed_addr global %struct.rb_vm_struct*, align 8
@rb_cFalseClass = external local_unnamed_addr constant i64, align 8
@rb_cInteger = external local_unnamed_addr constant i64, align 8
@rb_cFloat = external local_unnamed_addr constant i64, align 8
@rb_cTrueClass = external local_unnamed_addr constant i64, align 8
@rb_cSymbol = external local_unnamed_addr constant i64, align 8
@rb_cNilClass = external local_unnamed_addr constant i64, align 8
@rb_cObject = external local_unnamed_addr constant i64, align 8
@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@.str.1 = private unnamed_addr constant [29 x i8] c"wrong constant name %li\0B%li\0B\00", align 1
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.2 = private unnamed_addr constant [36 x i8] c"%li\0B does not refer to class/module\00", align 1
@sorbet_getConstantAt.rb_intern_id_cache = internal unnamed_addr global i64 0, align 8
@.str.3 = private unnamed_addr constant [14 x i8] c"const_missing\00", align 1
@ruby_current_execution_context_ptr = external local_unnamed_addr global %struct.rb_execution_context_struct*, align 8
@.str.5 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.8 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@rb_cData = external local_unnamed_addr constant i64, align 8
@ruby_vm_global_constant_state = external local_unnamed_addr global i64, align 8
@ruby_vm_global_method_state = external local_unnamed_addr global i64, align 8
@.str.13 = private unnamed_addr constant [40 x i8] c"unimplmented call with a missing method\00", align 1
@"stackFramePrecomputed_func_<root>.<static-init>$111" = internal unnamed_addr global i8* null, align 8
@"rubyIdPrecomputed_<top (required)>" = internal unnamed_addr global i64 0, align 8
@"str_<top (required)>" = private unnamed_addr constant [17 x i8] c"<top (required)>\00", align 1
@"rubyStrFrozen_<top (required)>" = internal unnamed_addr global i64 0, align 8
@str_Object = private unnamed_addr constant [7 x i8] c"Object\00", align 1
@"rubyStrFrozen_test/testdata/compiler/method_with_block.rb" = internal unnamed_addr global i64 0, align 8
@"str_test/testdata/compiler/method_with_block.rb" = private unnamed_addr constant [44 x i8] c"test/testdata/compiler/method_with_block.rb\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@"str_T.class_of(<root>)" = private unnamed_addr constant [19 x i8] c"T.class_of(<root>)\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@rubyIdPrecomputed_foo = internal unnamed_addr global i64 0, align 8
@str_foo = private unnamed_addr constant [4 x i8] c"foo\00", align 1
@"str_Sorbet::Private::Static" = private unnamed_addr constant [24 x i8] c"Sorbet::Private::Static\00", align 1
@rubyIdPrecomputed_keep_method_def = internal unnamed_addr global i64 0, align 8
@str_keep_method_def = private unnamed_addr constant [16 x i8] c"keep_method_def\00", align 1
@ic_call_via_vm_keep_method_def = internal global %struct.FunctionInlineCache zeroinitializer
@rubyIdPrecomputed_boo = internal unnamed_addr global i64 0, align 8
@str_boo = private unnamed_addr constant [4 x i8] c"boo\00", align 1
@ic_call_via_vm_keep_method_def.2 = internal global %struct.FunctionInlineCache zeroinitializer
@rubyIdPrecomputed_bar = internal unnamed_addr global i64 0, align 8
@str_bar = private unnamed_addr constant [4 x i8] c"bar\00", align 1
@ic_call_via_vm_keep_method_def.4 = internal global %struct.FunctionInlineCache zeroinitializer
@rubyIdPrecomputed_baz = internal unnamed_addr global i64 0, align 8
@str_baz = private unnamed_addr constant [4 x i8] c"baz\00", align 1
@ic_call_via_vm_keep_method_def.6 = internal global %struct.FunctionInlineCache zeroinitializer
@rubyStrFrozen_heey = internal unnamed_addr global i64 0, align 8
@str_heey = private unnamed_addr constant [5 x i8] c"heey\00", align 1
@rubyIdPrecomputed_puts = internal unnamed_addr global i64 0, align 8
@str_puts = private unnamed_addr constant [5 x i8] c"puts\00", align 1
@ic_call_via_vm_puts = internal global %struct.FunctionInlineCache zeroinitializer
@rubyStrFrozen_boohey = internal unnamed_addr global i64 0, align 8
@str_boohey = private unnamed_addr constant [7 x i8] c"boohey\00", align 1
@ic_call_via_vm_puts.7 = internal global %struct.FunctionInlineCache zeroinitializer
@rubyStrFrozen_bar = internal unnamed_addr global i64 0, align 8
@ic_call_via_vm_puts.8 = internal global %struct.FunctionInlineCache zeroinitializer
@"stackFramePrecomputed_func_Object#foo" = internal unnamed_addr global i8* null, align 8
@rubyStrFrozen_foo = internal unnamed_addr global i64 0, align 8
@rubyIdPrecomputed_call = internal unnamed_addr global i64 0, align 8
@str_call = private unnamed_addr constant [5 x i8] c"call\00", align 1
@ic_call_via_vm_call = internal global %struct.FunctionInlineCache zeroinitializer
@"stackFramePrecomputed_func_Object#boo" = internal unnamed_addr global i8* null, align 8
@rubyStrFrozen_boo = internal unnamed_addr global i64 0, align 8
@ic_call_via_vm_call.9 = internal global %struct.FunctionInlineCache zeroinitializer
@"stackFramePrecomputed_func_Object#bar" = internal unnamed_addr global i8* null, align 8
@rubyIdPrecomputed_to_proc = internal unnamed_addr global i64 0, align 8
@str_to_proc = private unnamed_addr constant [8 x i8] c"to_proc\00", align 1
@ic_call_via_vm_to_proc = internal global %struct.FunctionInlineCache zeroinitializer
@"stackFramePrecomputed_func_Object#baz" = internal unnamed_addr global i8* null, align 8
@rubyStrFrozen_baz = internal unnamed_addr global i64 0, align 8
@llvm.global_ctors = appending global [23 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<top (required)>", i8* bitcast (i64* @"rubyIdPrecomputed_<top (required)>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyStrFrozen_<top (required)>", i8* bitcast (i64* @"rubyStrFrozen_<top (required)>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyStrFrozen_test/testdata/compiler/method_with_block.rb", i8* bitcast (i64* @"rubyStrFrozen_test/testdata/compiler/method_with_block.rb" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_<root>.<static-init>$111", i8* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_foo, i8* bitcast (i64* @rubyIdPrecomputed_foo to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_keep_method_def, i8* bitcast (i64* @rubyIdPrecomputed_keep_method_def to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_boo, i8* bitcast (i64* @rubyIdPrecomputed_boo to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_bar, i8* bitcast (i64* @rubyIdPrecomputed_bar to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_baz, i8* bitcast (i64* @rubyIdPrecomputed_baz to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyStrFrozen_heey, i8* bitcast (i64* @rubyStrFrozen_heey to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_puts, i8* bitcast (i64* @rubyIdPrecomputed_puts to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyStrFrozen_boohey, i8* bitcast (i64* @rubyStrFrozen_boohey to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyStrFrozen_bar, i8* bitcast (i64* @rubyStrFrozen_bar to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyStrFrozen_foo, i8* bitcast (i64* @rubyStrFrozen_foo to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_Object#foo", i8* bitcast (i8** @"stackFramePrecomputed_func_Object#foo" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_call, i8* bitcast (i64* @rubyIdPrecomputed_call to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyStrFrozen_boo, i8* bitcast (i64* @rubyStrFrozen_boo to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_Object#boo", i8* bitcast (i8** @"stackFramePrecomputed_func_Object#boo" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_Object#bar", i8* bitcast (i8** @"stackFramePrecomputed_func_Object#bar" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_to_proc, i8* bitcast (i64* @rubyIdPrecomputed_to_proc to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyStrFrozen_baz, i8* bitcast (i64* @rubyStrFrozen_baz to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_Object#baz", i8* bitcast (i8** @"stackFramePrecomputed_func_Object#baz" to i8*) }]
@ic_call_via_vm_call.10 = internal global %struct.FunctionInlineCache zeroinitializer
@"guard_epoch_Sorbet::Private::Static" = linkonce local_unnamed_addr global i64 0
@"guarded_const_Sorbet::Private::Static" = linkonce local_unnamed_addr global i64 0

declare i64 @rb_str_intern(i64) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8*) #1 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !0
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #18
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly) #2 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !0
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64) local_unnamed_addr #1 {
  %2 = tail call i8* @rb_id2name(i64 %0) #18
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64) local_unnamed_addr #1 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #18
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !4
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #18
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !7
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define void @stopInDebugger() local_unnamed_addr #1 {
  tail call void asm sideeffect "int $$3", "~{dirflag},~{fpsr},~{flags}"() #18, !srcloc !8
  ret void
}

declare i64 @rb_fstring_new(i8*, i64) local_unnamed_addr #0

declare void @rb_gc_register_mark_object(i64) local_unnamed_addr #0

declare void @rb_ary_detransient(i64) local_unnamed_addr #0

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #0

declare i64 @rb_id2sym(i64) local_unnamed_addr #0

declare i8* @rb_obj_classname(i64) local_unnamed_addr #0

declare i32 @rb_block_given_p() local_unnamed_addr #0

declare i64 @rb_block_proc() local_unnamed_addr #0

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstantAt(i64, i64) unnamed_addr #3 {
  %3 = tail call i64 @rb_id2str(i64 %1) #18
  %4 = tail call %struct.OnigEncodingTypeST* @rb_enc_get(i64 %3) #18
  %5 = tail call i8* @rb_id2name(i64 %1) #18
  %6 = tail call i64 @strlen(i8* %5) #19
  %7 = getelementptr inbounds i8, i8* %5, i64 %6
  %8 = icmp sgt i64 %6, 0
  br i1 %8, label %9, label %.loopexit11

9:                                                ; preds = %2
  %10 = ptrtoint i8* %5 to i64
  br label %13

.loopexit10:                                      ; preds = %91, %44, %41, %28, %107
  %11 = phi i64 [ %108, %107 ], [ %3, %28 ], [ %3, %44 ], [ %3, %41 ], [ %66, %91 ]
  %12 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !9
  tail call void (i64, i8*, ...) @rb_raise(i64 %12, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.1, i64 0, i64 0), i64 %14, i64 %11) #20
  unreachable

13:                                               ; preds = %115, %9
  %14 = phi i64 [ %0, %9 ], [ %116, %115 ]
  %15 = phi i8* [ %5, %9 ], [ %50, %115 ]
  %16 = phi i8* [ %5, %9 ], [ %49, %115 ]
  %17 = icmp ult i8* %16, %7
  br i1 %17, label %18, label %28

18:                                               ; preds = %13
  %19 = load i8, i8* %16, align 1, !tbaa !7
  %20 = icmp eq i8 %19, 58
  br i1 %20, label %28, label %.preheader

21:                                               ; preds = %.preheader
  %22 = load i8, i8* %25, align 1, !tbaa !7
  %23 = icmp eq i8 %22, 58
  br i1 %23, label %.loopexit, label %.preheader

.preheader:                                       ; preds = %18, %21
  %24 = phi i8* [ %25, %21 ], [ %16, %18 ]
  %25 = getelementptr inbounds i8, i8* %24, i64 1
  %26 = icmp eq i8* %25, %7
  br i1 %26, label %.loopexit, label %21

.loopexit:                                        ; preds = %21, %.preheader
  %.lcssa = phi i8* [ %25, %21 ], [ %7, %.preheader ]
  %27 = icmp ult i8* %.lcssa, %7
  br label %28

28:                                               ; preds = %.loopexit, %18, %13
  %29 = phi i8* [ %16, %13 ], [ %16, %18 ], [ %.lcssa, %.loopexit ]
  %30 = phi i1 [ false, %13 ], [ true, %18 ], [ %27, %.loopexit ]
  %31 = icmp eq i8* %15, %29
  br i1 %31, label %.loopexit10, label %32

32:                                               ; preds = %28
  %33 = ptrtoint i8* %29 to i64
  %34 = ptrtoint i8* %15 to i64
  %35 = sub i64 %33, %34
  %36 = tail call i64 @rb_check_id_cstr(i8* %15, i64 %35, %struct.OnigEncodingTypeST* %4) #18
  %37 = sub i64 %34, %10
  br i1 %30, label %38, label %48

38:                                               ; preds = %32
  %39 = load i8, i8* %29, align 1, !tbaa !7
  %40 = icmp eq i8 %39, 58
  br i1 %40, label %41, label %48

41:                                               ; preds = %38
  %42 = getelementptr inbounds i8, i8* %29, i64 2
  %43 = icmp ult i8* %42, %7
  br i1 %43, label %44, label %.loopexit10

44:                                               ; preds = %41
  %45 = getelementptr inbounds i8, i8* %29, i64 1
  %46 = load i8, i8* %45, align 1, !tbaa !7
  %47 = icmp eq i8 %46, 58
  br i1 %47, label %48, label %.loopexit10

48:                                               ; preds = %44, %38, %32
  %49 = phi i8* [ %29, %38 ], [ %29, %32 ], [ %42, %44 ]
  %50 = phi i8* [ %15, %38 ], [ %15, %32 ], [ %42, %44 ]
  %51 = and i64 %14, 7
  %52 = icmp ne i64 %51, 0
  %53 = and i64 %14, -9
  %54 = icmp eq i64 %53, 0
  %55 = or i1 %52, %54
  br i1 %55, label %61, label %56

56:                                               ; preds = %48
  %57 = inttoptr i64 %14 to %struct.RBasic*
  %58 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 0
  %59 = load i64, i64* %58, align 8, !tbaa !4
  %60 = and i64 %59, 30
  %switch = icmp eq i64 %60, 2
  br i1 %switch, label %63, label %61

61:                                               ; preds = %56, %48
  %62 = load i64, i64* @rb_eTypeError, align 8, !tbaa !9
  tail call void (i64, i8*, ...) @rb_raise(i64 %62, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.2, i64 0, i64 0), i64 %3) #20
  unreachable

63:                                               ; preds = %56
  %64 = icmp eq i64 %36, 0
  br i1 %64, label %65, label %104

65:                                               ; preds = %63
  %66 = tail call i64 @rb_str_subseq(i64 %3, i64 %37, i64 %35) #18
  %67 = and i64 %66, 7
  %68 = icmp ne i64 %67, 0
  %69 = and i64 %66, -9
  %70 = icmp eq i64 %69, 0
  %71 = or i1 %68, %70
  br i1 %71, label %rb_obj_freeze_inline.exit, label %72

72:                                               ; preds = %65
  %73 = inttoptr i64 %66 to %struct.RBasic*
  %74 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 0
  %75 = load i64, i64* %74, align 8, !tbaa !4
  %76 = and i64 %75, 31
  %77 = icmp eq i64 %76, 27
  br i1 %77, label %rb_obj_freeze_inline.exit, label %78

78:                                               ; preds = %72
  %79 = or i64 %75, 2048
  store i64 %79, i64* %74, align 8, !tbaa !4
  %80 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 1
  %81 = load i64, i64* %80, align 8, !tbaa !10
  %82 = icmp ne i64 %81, 0
  %83 = and i64 %75, 4096
  %84 = icmp eq i64 %83, 0
  %85 = and i1 %84, %82
  br i1 %85, label %86, label %rb_obj_freeze_inline.exit

86:                                               ; preds = %78
  tail call void @rb_freeze_singleton_class(i64 %66) #18
  br label %rb_obj_freeze_inline.exit

rb_obj_freeze_inline.exit:                        ; preds = %65, %72, %78, %86
  %87 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !9
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %89, label %91

89:                                               ; preds = %rb_obj_freeze_inline.exit
  %90 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.3, i64 0, i64 0), i64 13) #18
  store i64 %90, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !9
  br label %91

91:                                               ; preds = %89, %rb_obj_freeze_inline.exit
  %92 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !9
  %93 = tail call i32 @rb_is_const_name(i64 %66) #18
  %94 = icmp eq i32 %93, 0
  br i1 %94, label %.loopexit10, label %rb_class_of.exit

rb_class_of.exit:                                 ; preds = %91
  %95 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 1
  %96 = load i64, i64* %95, align 8, !tbaa !9
  %97 = tail call i32 @rb_method_basic_definition_p(i64 %96, i64 %92) #18
  %98 = icmp eq i32 %97, 0
  br i1 %98, label %99, label %102

99:                                               ; preds = %rb_class_of.exit
  %100 = tail call i64 @rb_str_intern(i64 %66) #18
  %101 = tail call i64 @rb_const_missing(i64 %14, i64 %100) #18
  br label %115

102:                                              ; preds = %rb_class_of.exit
  %103 = tail call i64 @rb_mod_const_missing(i64 %14, i64 %66) #20
  unreachable

104:                                              ; preds = %63
  %105 = tail call i32 @rb_is_const_id(i64 %36) #6
  %106 = icmp eq i32 %105, 0
  br i1 %106, label %107, label %109

107:                                              ; preds = %104
  %108 = tail call i64 @rb_id2sym(i64 %36) #18
  br label %.loopexit10

109:                                              ; preds = %104
  %110 = icmp eq i64 %37, 0
  br i1 %110, label %111, label %113

111:                                              ; preds = %109
  %112 = tail call i64 @rb_const_get(i64 %14, i64 %36) #18
  br label %115

113:                                              ; preds = %109
  %114 = tail call i64 @rb_const_get_from(i64 %14, i64 %36) #18
  br label %115

115:                                              ; preds = %113, %111, %99
  %116 = phi i64 [ %101, %99 ], [ %112, %111 ], [ %114, %113 ]
  %117 = icmp ult i8* %49, %7
  br i1 %117, label %13, label %.loopexit11

.loopexit11:                                      ; preds = %115, %2
  %118 = phi i64 [ %0, %2 ], [ %116, %115 ]
  ret i64 %118
}

declare i64 @rb_id2str(i64) local_unnamed_addr #0

declare %struct.OnigEncodingTypeST* @rb_enc_get(i64) local_unnamed_addr #0

; Function Attrs: argmemonly nofree nounwind readonly
declare i64 @strlen(i8* nocapture) local_unnamed_addr #4

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #5

declare i64 @rb_check_id_cstr(i8*, i64, %struct.OnigEncodingTypeST*) local_unnamed_addr #0

declare i64 @rb_str_subseq(i64, i64, i64) local_unnamed_addr #0

declare i32 @rb_is_const_name(i64) local_unnamed_addr #0

declare i32 @rb_method_basic_definition_p(i64, i64) local_unnamed_addr #0

declare i64 @rb_const_missing(i64, i64) local_unnamed_addr #0

; Function Attrs: noreturn
declare i64 @rb_mod_const_missing(i64, i64) local_unnamed_addr #5

; Function Attrs: nounwind readnone
declare i32 @rb_is_const_id(i64) local_unnamed_addr #6

declare i64 @rb_const_get(i64, i64) local_unnamed_addr #0

declare i64 @rb_const_get_from(i64, i64) local_unnamed_addr #0

declare void @rb_freeze_singleton_class(i64) local_unnamed_addr #0

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstant(i8*, i64) unnamed_addr #3 {
  %3 = load i64, i64* @rb_cObject, align 8, !tbaa !9
  %4 = tail call i64 @rb_intern2(i8* %0, i64 %1) #18
  %5 = tail call fastcc i64 @sorbet_getConstantAt(i64 %3, i64 %4)
  ret i64 %5
}

declare void @rb_define_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #0

declare %struct.rb_callable_method_entry_struct* @rb_callable_method_entry(i64, i64) local_unnamed_addr #0

declare i64 @rb_vm_call(%struct.rb_execution_context_struct*, i64, i64, i32, i64*, %struct.rb_callable_method_entry_struct*) local_unnamed_addr #0

declare i64 @rb_funcall_with_block(i64, i64, i32, i64*, i64) local_unnamed_addr #0

declare i64 @rb_block_call(i64, i64, i32, i64*, i64 (...)*, i64) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32) unnamed_addr #1 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.5, i64 0, i64 0), i32 %0, i32 0) #18
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !9
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #18
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #0

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64, i8*) unnamed_addr #7 {
  %3 = load i64, i64* @rb_eTypeError, align 8, !tbaa !9
  %4 = tail call i8* @rb_obj_classname(i64 %0) #18
  tail call void (i64, i8*, ...) @rb_raise(i64 %3, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.8, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* %1, i8* %4, i64 %0) #20
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_raiseArity(i32) unnamed_addr #8 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #20
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #5

declare i8* @ruby_xmalloc(i64) local_unnamed_addr #0

declare i64 @rb_data_typed_object_wrap(i64, i8*, %struct.rb_data_type_struct*) local_unnamed_addr #0

declare %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct*, i64, i64, i64, %struct.rb_iseq_struct*, i32) local_unnamed_addr #0

declare i8* @ruby_xmalloc2(i64, i64) local_unnamed_addr #0

declare void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct*) local_unnamed_addr #0

; Function Attrs: nofree norecurse nounwind ssp uwtable
define i64** @sorbet_setRubyStackFrame(i8*) local_unnamed_addr #9 {
  %2 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %3 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %2, i64 0, i32 2
  %4 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %3, align 8, !tbaa !13
  %5 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 2
  %6 = bitcast %struct.rb_iseq_struct** %5 to i8**
  store i8* %0, i8** %6, align 8, !tbaa !16
  %7 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 4
  %8 = load i64*, i64** %7, align 8, !tbaa !18
  %9 = load i64, i64* %8, align 8, !tbaa !9
  %10 = and i64 %9, -129
  store i64 %10, i64* %8, align 8, !tbaa !9
  %11 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 0
  ret i64** %11
}

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @sorbet_inlineCacheInvalidated(i64, %struct.FunctionInlineCache* nocapture, i64) unnamed_addr #1 {
  %4 = and i64 %0, 7
  %5 = icmp eq i64 %4, 0
  br i1 %5, label %18, label %6

6:                                                ; preds = %3
  %7 = trunc i64 %0 to i32
  %8 = and i32 %7, 1
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %10, label %rb_class_of.exit

10:                                               ; preds = %6
  %11 = and i32 %7, 3
  %12 = icmp eq i32 %11, 2
  br i1 %12, label %rb_class_of.exit, label %13

13:                                               ; preds = %10
  %14 = icmp eq i64 %0, 20
  br i1 %14, label %rb_class_of.exit, label %15

15:                                               ; preds = %13
  %16 = and i64 %0, 255
  %17 = icmp eq i64 %16, 12
  br i1 %17, label %rb_class_of.exit, label %23

18:                                               ; preds = %3
  %19 = and i64 %0, -9
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %21, label %23

21:                                               ; preds = %18
  switch i64 %0, label %23 [
    i64 8, label %rb_class_of.exit
    i64 0, label %22
  ]

22:                                               ; preds = %21
  br label %rb_class_of.exit

23:                                               ; preds = %21, %18, %15
  %24 = inttoptr i64 %0 to %struct.RBasic*
  %25 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %24, i64 0, i32 1
  br label %rb_class_of.exit

rb_class_of.exit:                                 ; preds = %6, %10, %13, %15, %21, %22, %23
  %26 = phi i64* [ %25, %23 ], [ @rb_cFalseClass, %22 ], [ @rb_cInteger, %6 ], [ @rb_cFloat, %10 ], [ @rb_cTrueClass, %13 ], [ @rb_cSymbol, %15 ], [ @rb_cNilClass, %21 ]
  %27 = load i64, i64* %26, align 8, !tbaa !9
  %28 = tail call %struct.rb_callable_method_entry_struct* @rb_callable_method_entry(i64 %27, i64 %2) #18
  %29 = icmp eq %struct.rb_callable_method_entry_struct* %28, null
  br i1 %29, label %30, label %32

30:                                               ; preds = %rb_class_of.exit
  %31 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !9
  tail call void (i64, i8*, ...) @rb_raise(i64 %31, i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.13, i64 0, i64 0)) #20
  unreachable

32:                                               ; preds = %rb_class_of.exit
  %33 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %1, i64 0, i32 0
  store %struct.rb_callable_method_entry_struct* %28, %struct.rb_callable_method_entry_struct** %33, align 8, !tbaa !19
  %34 = load i64, i64* @ruby_vm_global_method_state, align 8, !tbaa !22
  %35 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %1, i64 0, i32 1
  store i64 %34, i64* %35, align 8, !tbaa !23
  br i1 %5, label %48, label %36

36:                                               ; preds = %32
  %37 = trunc i64 %0 to i32
  %38 = and i32 %37, 1
  %39 = icmp eq i32 %38, 0
  br i1 %39, label %40, label %sorbet_getClassSerial.exit

40:                                               ; preds = %36
  %41 = and i32 %37, 3
  %42 = icmp eq i32 %41, 2
  br i1 %42, label %sorbet_getClassSerial.exit, label %43

43:                                               ; preds = %40
  %44 = icmp eq i64 %0, 20
  br i1 %44, label %sorbet_getClassSerial.exit, label %45

45:                                               ; preds = %43
  %46 = and i64 %0, 255
  %47 = icmp eq i64 %46, 12
  br i1 %47, label %sorbet_getClassSerial.exit, label %53

48:                                               ; preds = %32
  %49 = and i64 %0, -9
  %50 = icmp eq i64 %49, 0
  br i1 %50, label %51, label %53

51:                                               ; preds = %48
  switch i64 %0, label %53 [
    i64 8, label %sorbet_getClassSerial.exit
    i64 0, label %52
  ]

52:                                               ; preds = %51
  br label %sorbet_getClassSerial.exit

53:                                               ; preds = %51, %48, %45
  %54 = inttoptr i64 %0 to %struct.RBasic*
  %55 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %54, i64 0, i32 1
  %phitmp.i = bitcast i64* %55 to %struct.RClass**
  br label %sorbet_getClassSerial.exit

sorbet_getClassSerial.exit:                       ; preds = %36, %40, %43, %45, %51, %52, %53
  %56 = phi %struct.RClass** [ %phitmp.i, %53 ], [ bitcast (i64* @rb_cFalseClass to %struct.RClass**), %52 ], [ bitcast (i64* @rb_cInteger to %struct.RClass**), %36 ], [ bitcast (i64* @rb_cFloat to %struct.RClass**), %40 ], [ bitcast (i64* @rb_cTrueClass to %struct.RClass**), %43 ], [ bitcast (i64* @rb_cSymbol to %struct.RClass**), %45 ], [ bitcast (i64* @rb_cNilClass to %struct.RClass**), %51 ]
  %57 = load %struct.RClass*, %struct.RClass** %56, align 8, !tbaa !9
  %58 = getelementptr inbounds %struct.RClass, %struct.RClass* %57, i64 0, i32 2
  %59 = load %struct.rb_classext_struct*, %struct.rb_classext_struct** %58, align 8, !tbaa !24
  %60 = getelementptr inbounds %struct.rb_classext_struct, %struct.rb_classext_struct* %59, i64 0, i32 7
  %61 = load i64, i64* %60, align 8, !tbaa !26
  %62 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %1, i64 0, i32 2
  store i64 %61, i64* %62, align 8, !tbaa !28
  ret void
}

; Function Attrs: ssp
define internal i64 @"func_<root>.<static-init>$111$block_1"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readonly %argArray, i64 %blockArg) #10 {
functionEntryInitializers:
  %callArgs = alloca [2 x i64], align 8
  %"stackFrame_func_<root>.<static-init>$1117" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i64*), align 8
  %rubyStr_heey = load i64, i64* @rubyStrFrozen_heey, align 8
  %arrayExpansionSizeGuard = icmp eq i32 %argc, 1
  br i1 %arrayExpansionSizeGuard, label %argArrayExpandArrayTest, label %fillRequiredArgs

argArrayExpandArrayTest:                          ; preds = %functionEntryInitializers
  %arg1_maybeExpandToFullArgs = load i64, i64* %argArray, align 8
  %0 = and i64 %arg1_maybeExpandToFullArgs, 7
  %1 = icmp ne i64 %0, 0
  %2 = and i64 %arg1_maybeExpandToFullArgs, -9
  %3 = icmp eq i64 %2, 0
  %4 = or i1 %1, %3
  br i1 %4, label %fillRequiredArgs, label %sorbet_isa_Array.exit

sorbet_isa_Array.exit:                            ; preds = %argArrayExpandArrayTest
  %5 = inttoptr i64 %arg1_maybeExpandToFullArgs to %struct.RBasic*
  %6 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %5, i64 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !4
  %8 = and i64 %7, 33554463
  %9 = icmp eq i64 %8, 33554439
  br i1 %9, label %10, label %fillRequiredArgs

10:                                               ; preds = %sorbet_isa_Array.exit
  tail call void @rb_ary_detransient(i64 %arg1_maybeExpandToFullArgs) #18
  br label %fillRequiredArgs

fillRequiredArgs:                                 ; preds = %sorbet_isa_Array.exit, %argArrayExpandArrayTest, %10, %functionEntryInitializers
  %11 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %12 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %11, i64 0, i32 2
  %13 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %12, align 8, !tbaa !13
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 2
  %15 = bitcast %struct.rb_iseq_struct** %14 to i64*
  store i64 %"stackFrame_func_<root>.<static-init>$1117", i64* %15, align 8, !tbaa !16
  %16 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8, !tbaa !18
  %18 = load i64, i64* %17, align 8, !tbaa !9
  %19 = and i64 %18, -129
  store i64 %19, i64* %17, align 8, !tbaa !9
  %20 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 0
  store i64* inttoptr (i64 144 to i64*), i64** %20, align 8, !tbaa !11
  %callArgsAddr = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 0
  store i64 %rubyStr_heey, i64* %callArgsAddr, align 8
  %21 = inttoptr i64 %captures to %struct.RTypedData*
  %22 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %21, i64 0, i32 3
  %23 = bitcast i8** %22 to %struct.sorbet_Closure**
  %24 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %23, align 8, !tbaa !29
  %25 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %24, i64 0, i32 1, i64 0
  %26 = load i64, i64* %25, align 8
  %rawSendResult = call i64 @call_via_vm_puts(i32 1, i64* nonnull %callArgsAddr, i64 %26, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_puts)
  store i64* inttoptr (i64 136 to i64*), i64** %20, align 8, !tbaa !11
  ret i64 %rawSendResult
}

; Function Attrs: ssp
define internal i64 @"func_<root>.<static-init>$111$block_2"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readonly %argArray, i64 %blockArg) #10 {
functionEntryInitializers:
  %callArgs = alloca [2 x i64], align 8
  %"stackFrame_func_<root>.<static-init>$1117" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i64*), align 8
  %rubyStr_boohey = load i64, i64* @rubyStrFrozen_boohey, align 8
  %arrayExpansionSizeGuard = icmp eq i32 %argc, 1
  br i1 %arrayExpansionSizeGuard, label %argArrayExpandArrayTest, label %fillRequiredArgs

argArrayExpandArrayTest:                          ; preds = %functionEntryInitializers
  %arg1_maybeExpandToFullArgs = load i64, i64* %argArray, align 8
  %0 = and i64 %arg1_maybeExpandToFullArgs, 7
  %1 = icmp ne i64 %0, 0
  %2 = and i64 %arg1_maybeExpandToFullArgs, -9
  %3 = icmp eq i64 %2, 0
  %4 = or i1 %1, %3
  br i1 %4, label %fillRequiredArgs, label %sorbet_isa_Array.exit

sorbet_isa_Array.exit:                            ; preds = %argArrayExpandArrayTest
  %5 = inttoptr i64 %arg1_maybeExpandToFullArgs to %struct.RBasic*
  %6 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %5, i64 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !4
  %8 = and i64 %7, 33554463
  %9 = icmp eq i64 %8, 33554439
  br i1 %9, label %10, label %fillRequiredArgs

10:                                               ; preds = %sorbet_isa_Array.exit
  tail call void @rb_ary_detransient(i64 %arg1_maybeExpandToFullArgs) #18
  br label %fillRequiredArgs

fillRequiredArgs:                                 ; preds = %sorbet_isa_Array.exit, %argArrayExpandArrayTest, %10, %functionEntryInitializers
  %11 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %12 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %11, i64 0, i32 2
  %13 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %12, align 8, !tbaa !13
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 2
  %15 = bitcast %struct.rb_iseq_struct** %14 to i64*
  store i64 %"stackFrame_func_<root>.<static-init>$1117", i64* %15, align 8, !tbaa !16
  %16 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8, !tbaa !18
  %18 = load i64, i64* %17, align 8, !tbaa !9
  %19 = and i64 %18, -129
  store i64 %19, i64* %17, align 8, !tbaa !9
  %20 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 0
  store i64* inttoptr (i64 176 to i64*), i64** %20, align 8, !tbaa !11
  %callArgsAddr = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 0
  store i64 %rubyStr_boohey, i64* %callArgsAddr, align 8
  %21 = inttoptr i64 %captures to %struct.RTypedData*
  %22 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %21, i64 0, i32 3
  %23 = bitcast i8** %22 to %struct.sorbet_Closure**
  %24 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %23, align 8, !tbaa !29
  %25 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %24, i64 0, i32 1, i64 0
  %26 = load i64, i64* %25, align 8
  %rawSendResult = call i64 @call_via_vm_puts(i32 1, i64* nonnull %callArgsAddr, i64 %26, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_puts.7)
  store i64* inttoptr (i64 168 to i64*), i64** %20, align 8, !tbaa !11
  ret i64 %rawSendResult
}

; Function Attrs: ssp
define internal i64 @"func_<root>.<static-init>$111$block_3"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readonly %argArray, i64 %blockArg) #10 {
functionEntryInitializers:
  %callArgs = alloca [2 x i64], align 8
  %"stackFrame_func_<root>.<static-init>$1117" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i64*), align 8
  %rubyStr_bar = load i64, i64* @rubyStrFrozen_bar, align 8
  %arrayExpansionSizeGuard = icmp eq i32 %argc, 1
  br i1 %arrayExpansionSizeGuard, label %argArrayExpandArrayTest, label %fillRequiredArgs

argArrayExpandArrayTest:                          ; preds = %functionEntryInitializers
  %arg1_maybeExpandToFullArgs = load i64, i64* %argArray, align 8
  %0 = and i64 %arg1_maybeExpandToFullArgs, 7
  %1 = icmp ne i64 %0, 0
  %2 = and i64 %arg1_maybeExpandToFullArgs, -9
  %3 = icmp eq i64 %2, 0
  %4 = or i1 %1, %3
  br i1 %4, label %fillRequiredArgs, label %sorbet_isa_Array.exit

sorbet_isa_Array.exit:                            ; preds = %argArrayExpandArrayTest
  %5 = inttoptr i64 %arg1_maybeExpandToFullArgs to %struct.RBasic*
  %6 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %5, i64 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !4
  %8 = and i64 %7, 33554463
  %9 = icmp eq i64 %8, 33554439
  br i1 %9, label %10, label %fillRequiredArgs

10:                                               ; preds = %sorbet_isa_Array.exit
  tail call void @rb_ary_detransient(i64 %arg1_maybeExpandToFullArgs) #18
  br label %fillRequiredArgs

fillRequiredArgs:                                 ; preds = %sorbet_isa_Array.exit, %argArrayExpandArrayTest, %10, %functionEntryInitializers
  %11 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %12 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %11, i64 0, i32 2
  %13 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %12, align 8, !tbaa !13
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 2
  %15 = bitcast %struct.rb_iseq_struct** %14 to i64*
  store i64 %"stackFrame_func_<root>.<static-init>$1117", i64* %15, align 8, !tbaa !16
  %16 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8, !tbaa !18
  %18 = load i64, i64* %17, align 8, !tbaa !9
  %19 = and i64 %18, -129
  store i64 %19, i64* %17, align 8, !tbaa !9
  %20 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 0
  store i64* inttoptr (i64 208 to i64*), i64** %20, align 8, !tbaa !11
  %callArgsAddr = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 0
  store i64 %rubyStr_bar, i64* %callArgsAddr, align 8
  %21 = inttoptr i64 %captures to %struct.RTypedData*
  %22 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %21, i64 0, i32 3
  %23 = bitcast i8** %22 to %struct.sorbet_Closure**
  %24 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %23, align 8, !tbaa !29
  %25 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %24, i64 0, i32 1, i64 0
  %26 = load i64, i64* %25, align 8
  %rawSendResult = call i64 @call_via_vm_puts(i32 1, i64* nonnull %callArgsAddr, i64 %26, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_puts.8)
  store i64* inttoptr (i64 200 to i64*), i64** %20, align 8, !tbaa !11
  ret i64 %rawSendResult
}

; Function Attrs: nounwind ssp
define internal i64 @"func_<root>.<static-init>$111$block_4"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readonly %argArray, i64 %blockArg) #11 {
functionEntryInitializers:
  %"stackFrame_func_<root>.<static-init>$1113" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i64*), align 8
  %arrayExpansionSizeGuard = icmp eq i32 %argc, 1
  br i1 %arrayExpansionSizeGuard, label %argArrayExpandArrayTest, label %fillRequiredArgs

argArrayExpandArrayTest:                          ; preds = %functionEntryInitializers
  %arg1_maybeExpandToFullArgs = load i64, i64* %argArray, align 8
  %0 = and i64 %arg1_maybeExpandToFullArgs, 7
  %1 = icmp ne i64 %0, 0
  %2 = and i64 %arg1_maybeExpandToFullArgs, -9
  %3 = icmp eq i64 %2, 0
  %4 = or i1 %1, %3
  br i1 %4, label %fillRequiredArgs, label %sorbet_isa_Array.exit

sorbet_isa_Array.exit:                            ; preds = %argArrayExpandArrayTest
  %5 = inttoptr i64 %arg1_maybeExpandToFullArgs to %struct.RBasic*
  %6 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %5, i64 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !4
  %8 = and i64 %7, 33554463
  %9 = icmp eq i64 %8, 33554439
  br i1 %9, label %10, label %fillRequiredArgs

10:                                               ; preds = %sorbet_isa_Array.exit
  tail call void @rb_ary_detransient(i64 %arg1_maybeExpandToFullArgs) #18
  br label %fillRequiredArgs

fillRequiredArgs:                                 ; preds = %sorbet_isa_Array.exit, %argArrayExpandArrayTest, %10, %functionEntryInitializers
  %11 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %12 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %11, i64 0, i32 2
  %13 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %12, align 8, !tbaa !13
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 2
  %15 = bitcast %struct.rb_iseq_struct** %14 to i64*
  store i64 %"stackFrame_func_<root>.<static-init>$1113", i64* %15, align 8, !tbaa !16
  %16 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8, !tbaa !18
  %18 = load i64, i64* %17, align 8, !tbaa !9
  %19 = and i64 %18, -129
  store i64 %19, i64* %17, align 8, !tbaa !9
  %20 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %13, i64 0, i32 0
  store i64* inttoptr (i64 232 to i64*), i64** %20, align 8, !tbaa !11
  ret i64 8
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_<root>.<static-init>$111"() #11 {
entryInitializers:
  %"rubyStr_<top (required)>" = load i64, i64* @"rubyStrFrozen_<top (required)>", align 8
  %"rubyStr_test/testdata/compiler/method_with_block.rb" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/method_with_block.rb", align 8
  %0 = tail call %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct* null, i64 %"rubyStr_<top (required)>", i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", %struct.rb_iseq_struct* null, i32 1) #18
  %1 = ptrtoint %struct.rb_iseq_struct* %0 to i64
  tail call void @rb_gc_register_mark_object(i64 %1) #18
  %2 = tail call i8* @ruby_xmalloc2(i64 30, i64 8) #18
  %3 = bitcast i8* %2 to %struct.rb_code_position_struct*
  %4 = tail call i8* @ruby_xmalloc2(i64 30, i64 4) #18
  %5 = bitcast i8* %4 to i32*
  %scevgep = getelementptr i8, i8* %4, i64 120
  %scevgep2 = getelementptr i8, i8* %2, i64 236
  %bound0 = icmp ult i8* %4, %scevgep2
  %bound1 = icmp ult i8* %2, %scevgep
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %scalar.ph.prol.preheader, label %vector.body

vector.body:                                      ; preds = %entryInitializers
  %6 = bitcast i8* %4 to <8 x i32>*
  store <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, <8 x i32>* %6, align 4, !tbaa !0, !alias.scope !31, !noalias !34
  %7 = bitcast i8* %2 to i32*
  %8 = getelementptr inbounds i8, i8* %2, i64 8
  %9 = bitcast i8* %8 to i32*
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to i32*
  %12 = getelementptr inbounds i8, i8* %2, i64 24
  %13 = bitcast i8* %12 to i32*
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = getelementptr inbounds i8, i8* %2, i64 40
  %17 = bitcast i8* %16 to i32*
  %18 = getelementptr inbounds i8, i8* %2, i64 48
  %19 = bitcast i8* %18 to i32*
  %20 = getelementptr inbounds i8, i8* %2, i64 56
  %21 = bitcast i8* %20 to i32*
  store i32 5, i32* %7, align 4, !tbaa !36, !alias.scope !34
  store i32 6, i32* %9, align 4, !tbaa !36, !alias.scope !34
  store i32 7, i32* %11, align 4, !tbaa !36, !alias.scope !34
  store i32 8, i32* %13, align 4, !tbaa !36, !alias.scope !34
  store i32 9, i32* %15, align 4, !tbaa !36, !alias.scope !34
  store i32 10, i32* %17, align 4, !tbaa !36, !alias.scope !34
  store i32 11, i32* %19, align 4, !tbaa !36, !alias.scope !34
  store i32 12, i32* %21, align 4, !tbaa !36, !alias.scope !34
  %22 = getelementptr inbounds i8, i8* %4, i64 32
  %23 = bitcast i8* %22 to <8 x i32>*
  store <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>, <8 x i32>* %23, align 4, !tbaa !0, !alias.scope !31, !noalias !34
  %24 = getelementptr inbounds i8, i8* %2, i64 64
  %25 = bitcast i8* %24 to i32*
  %26 = getelementptr inbounds i8, i8* %2, i64 72
  %27 = bitcast i8* %26 to i32*
  %28 = getelementptr inbounds i8, i8* %2, i64 80
  %29 = bitcast i8* %28 to i32*
  %30 = getelementptr inbounds i8, i8* %2, i64 88
  %31 = bitcast i8* %30 to i32*
  %32 = getelementptr inbounds i8, i8* %2, i64 96
  %33 = bitcast i8* %32 to i32*
  %34 = getelementptr inbounds i8, i8* %2, i64 104
  %35 = bitcast i8* %34 to i32*
  %36 = getelementptr inbounds i8, i8* %2, i64 112
  %37 = bitcast i8* %36 to i32*
  %38 = getelementptr inbounds i8, i8* %2, i64 120
  %39 = bitcast i8* %38 to i32*
  store i32 13, i32* %25, align 4, !tbaa !36, !alias.scope !34
  store i32 14, i32* %27, align 4, !tbaa !36, !alias.scope !34
  store i32 15, i32* %29, align 4, !tbaa !36, !alias.scope !34
  store i32 16, i32* %31, align 4, !tbaa !36, !alias.scope !34
  store i32 17, i32* %33, align 4, !tbaa !36, !alias.scope !34
  store i32 18, i32* %35, align 4, !tbaa !36, !alias.scope !34
  store i32 19, i32* %37, align 4, !tbaa !36, !alias.scope !34
  store i32 20, i32* %39, align 4, !tbaa !36, !alias.scope !34
  %40 = getelementptr inbounds i8, i8* %4, i64 64
  %41 = bitcast i8* %40 to <8 x i32>*
  store <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>, <8 x i32>* %41, align 4, !tbaa !0, !alias.scope !31, !noalias !34
  %42 = getelementptr inbounds i8, i8* %2, i64 128
  %43 = bitcast i8* %42 to i32*
  %44 = getelementptr inbounds i8, i8* %2, i64 136
  %45 = bitcast i8* %44 to i32*
  %46 = getelementptr inbounds i8, i8* %2, i64 144
  %47 = bitcast i8* %46 to i32*
  %48 = getelementptr inbounds i8, i8* %2, i64 152
  %49 = bitcast i8* %48 to i32*
  %50 = getelementptr inbounds i8, i8* %2, i64 160
  %51 = bitcast i8* %50 to i32*
  %52 = getelementptr inbounds i8, i8* %2, i64 168
  %53 = bitcast i8* %52 to i32*
  %54 = getelementptr inbounds i8, i8* %2, i64 176
  %55 = bitcast i8* %54 to i32*
  %56 = getelementptr inbounds i8, i8* %2, i64 184
  %57 = bitcast i8* %56 to i32*
  store i32 21, i32* %43, align 4, !tbaa !36, !alias.scope !34
  store i32 22, i32* %45, align 4, !tbaa !36, !alias.scope !34
  store i32 23, i32* %47, align 4, !tbaa !36, !alias.scope !34
  store i32 24, i32* %49, align 4, !tbaa !36, !alias.scope !34
  store i32 25, i32* %51, align 4, !tbaa !36, !alias.scope !34
  store i32 26, i32* %53, align 4, !tbaa !36, !alias.scope !34
  store i32 27, i32* %55, align 4, !tbaa !36, !alias.scope !34
  store i32 28, i32* %57, align 4, !tbaa !36, !alias.scope !34
  br label %scalar.ph.prol.preheader

scalar.ph.prol.preheader:                         ; preds = %entryInitializers, %vector.body
  %phiofops = phi i1 [ false, %entryInitializers ], [ true, %vector.body ]
  %.ph = phi i64 [ 0, %entryInitializers ], [ 24, %vector.body ]
  br label %scalar.ph.prol

scalar.ph.prol:                                   ; preds = %scalar.ph.prol, %scalar.ph.prol.preheader
  %58 = phi i64 [ %63, %scalar.ph.prol ], [ %.ph, %scalar.ph.prol.preheader ]
  %prol.iter = phi i64 [ %prol.iter.sub, %scalar.ph.prol ], [ 6, %scalar.ph.prol.preheader ]
  %59 = trunc i64 %58 to i32
  %60 = add nsw i32 %59, 5
  %61 = getelementptr inbounds i32, i32* %5, i64 %58
  store i32 %59, i32* %61, align 4, !tbaa !0
  %62 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %58, i32 0
  store i32 %60, i32* %62, align 4, !tbaa !36
  %63 = add nuw nsw i64 %58, 1
  %prol.iter.sub = add nsw i64 %prol.iter, -1
  %prol.iter.cmp = icmp eq i64 %prol.iter.sub, 0
  br i1 %prol.iter.cmp, label %scalar.ph.prol.loopexit, label %scalar.ph.prol, !llvm.loop !38

scalar.ph.prol.loopexit:                          ; preds = %scalar.ph.prol
  br i1 %phiofops, label %sorbet_allocateRubyStackFrames.exit, label %scalar.ph

scalar.ph:                                        ; preds = %scalar.ph.prol.loopexit, %scalar.ph
  %64 = phi i64 [ %104, %scalar.ph ], [ %63, %scalar.ph.prol.loopexit ]
  %65 = trunc i64 %64 to i32
  %66 = add nsw i32 %65, 5
  %67 = getelementptr inbounds i32, i32* %5, i64 %64
  store i32 %65, i32* %67, align 4, !tbaa !0
  %68 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %64, i32 0
  store i32 %66, i32* %68, align 4, !tbaa !36
  %69 = add nuw nsw i64 %64, 1
  %70 = trunc i64 %69 to i32
  %71 = add nsw i32 %70, 5
  %72 = getelementptr inbounds i32, i32* %5, i64 %69
  store i32 %70, i32* %72, align 4, !tbaa !0
  %73 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %69, i32 0
  store i32 %71, i32* %73, align 4, !tbaa !36
  %74 = add nuw nsw i64 %64, 2
  %75 = trunc i64 %74 to i32
  %76 = add nsw i32 %75, 5
  %77 = getelementptr inbounds i32, i32* %5, i64 %74
  store i32 %75, i32* %77, align 4, !tbaa !0
  %78 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %74, i32 0
  store i32 %76, i32* %78, align 4, !tbaa !36
  %79 = add nuw nsw i64 %64, 3
  %80 = trunc i64 %79 to i32
  %81 = add nsw i32 %80, 5
  %82 = getelementptr inbounds i32, i32* %5, i64 %79
  store i32 %80, i32* %82, align 4, !tbaa !0
  %83 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %79, i32 0
  store i32 %81, i32* %83, align 4, !tbaa !36
  %84 = add nuw nsw i64 %64, 4
  %85 = trunc i64 %84 to i32
  %86 = add nsw i32 %85, 5
  %87 = getelementptr inbounds i32, i32* %5, i64 %84
  store i32 %85, i32* %87, align 4, !tbaa !0
  %88 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %84, i32 0
  store i32 %86, i32* %88, align 4, !tbaa !36
  %89 = add nuw nsw i64 %64, 5
  %90 = trunc i64 %89 to i32
  %91 = add nsw i32 %90, 5
  %92 = getelementptr inbounds i32, i32* %5, i64 %89
  store i32 %90, i32* %92, align 4, !tbaa !0
  %93 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %89, i32 0
  store i32 %91, i32* %93, align 4, !tbaa !36
  %94 = add nuw nsw i64 %64, 6
  %95 = trunc i64 %94 to i32
  %96 = add nsw i32 %95, 5
  %97 = getelementptr inbounds i32, i32* %5, i64 %94
  store i32 %95, i32* %97, align 4, !tbaa !0
  %98 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %94, i32 0
  store i32 %96, i32* %98, align 4, !tbaa !36
  %99 = add nuw nsw i64 %64, 7
  %100 = trunc i64 %99 to i32
  %101 = add nsw i32 %100, 5
  %102 = getelementptr inbounds i32, i32* %5, i64 %99
  store i32 %100, i32* %102, align 4, !tbaa !0
  %103 = getelementptr inbounds %struct.rb_code_position_struct, %struct.rb_code_position_struct* %3, i64 %99, i32 0
  store i32 %101, i32* %103, align 4, !tbaa !36
  %104 = add nuw nsw i64 %64, 8
  %105 = icmp eq i64 %104, 30
  br i1 %105, label %sorbet_allocateRubyStackFrames.exit, label %scalar.ph, !llvm.loop !40

sorbet_allocateRubyStackFrames.exit:              ; preds = %scalar.ph, %scalar.ph.prol.loopexit
  %106 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %0, i64 0, i32 2
  %107 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %106, align 8, !tbaa !42
  %108 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %107, i64 0, i32 5, i32 0
  %109 = bitcast %struct.rb_code_position_struct** %108 to i8**
  store i8* %2, i8** %109, align 8, !tbaa !44
  %110 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %107, i64 0, i32 5, i32 1
  %111 = bitcast i32** %110 to i8**
  store i8* %4, i8** %111, align 8, !tbaa !53
  %112 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %107, i64 0, i32 1
  store i32 30, i32* %112, align 4, !tbaa !54
  %113 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %107, i64 0, i32 5, i32 2
  store i32 30, i32* %113, align 8, !tbaa !55
  tail call void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct* %0) #18
  %114 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %106, align 8, !tbaa !42
  %115 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %114, i64 0, i32 2
  store i64* null, i64** %115, align 8, !tbaa !56
  store %struct.rb_iseq_struct* %0, %struct.rb_iseq_struct** bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to %struct.rb_iseq_struct**), align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<top (required)>"() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #18
  store i64 %0, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyStrFrozen_<top (required)>"() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @"rubyStrFrozen_<top (required)>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyStrFrozen_test/testdata/compiler/method_with_block.rb"() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([44 x i8], [44 x i8]* @"str_test/testdata/compiler/method_with_block.rb", i64 0, i64 0), i64 43) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @"rubyStrFrozen_test/testdata/compiler/method_with_block.rb", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #18
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_foo() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 3) #18
  store i64 %0, i64* @rubyIdPrecomputed_foo, align 8
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_Object#foo"(i32 %argc, i64* nocapture readnone %argArray, i64 %selfRaw) #12 {
functionEntryInitializers:
  %callArgs = alloca [0 x i64], align 8
  %tooManyArgs = icmp eq i32 %argc, 0
  br i1 %tooManyArgs, label %fillRequiredArgs, label %argCountFailBlock, !prof !57

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %"stackFrame_func_Object#foo12" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_Object#foo" to i64*), align 8
  %0 = tail call i32 @rb_block_given_p() #18
  %1 = icmp eq i32 %0, 0
  br i1 %1, label %sorbet_getMethodBlockAsProc.exit, label %2

2:                                                ; preds = %fillRequiredArgs
  %3 = tail call i64 @rb_block_proc() #18
  br label %sorbet_getMethodBlockAsProc.exit

sorbet_getMethodBlockAsProc.exit:                 ; preds = %fillRequiredArgs, %2
  %4 = phi i64 [ %3, %2 ], [ 8, %fillRequiredArgs ]
  %5 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %6 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %5, i64 0, i32 2
  %7 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %6, align 8, !tbaa !13
  %8 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 2
  %9 = bitcast %struct.rb_iseq_struct** %8 to i64*
  store i64 %"stackFrame_func_Object#foo12", i64* %9, align 8, !tbaa !16
  %10 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 4
  %11 = load i64*, i64** %10, align 8, !tbaa !18
  %12 = load i64, i64* %11, align 8, !tbaa !9
  %13 = and i64 %12, -129
  store i64 %13, i64* %11, align 8, !tbaa !9
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 0
  store i64* inttoptr (i64 8 to i64*), i64** %14, align 8, !tbaa !11
  %15 = load i64, i64* @rb_cObject, align 8
  %16 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %15) #6
  %17 = icmp eq i64 %16, 20
  br i1 %17, label %typeTestSuccess, label %codeRepl, !prof !57

typeTestSuccess:                                  ; preds = %sorbet_getMethodBlockAsProc.exit
  store i64* inttoptr (i64 16 to i64*), i64** %14, align 8, !tbaa !11
  %18 = getelementptr inbounds [0 x i64], [0 x i64]* %callArgs, i64 0, i64 0
  %rawSendResult = call i64 @call_via_vm_call(i32 0, i64* nonnull %18, i64 %4, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_call) #18
  ret i64 %rawSendResult

codeRepl:                                         ; preds = %sorbet_getMethodBlockAsProc.exit
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0)) #18
  unreachable
}

; Function Attrs: noinline ssp
define linkonce i64 @call_via_vm_keep_method_def(i32, i64*, i64, %struct.FunctionInlineCache*) local_unnamed_addr #13 {
functionEntryInitializers:
  %rubyId_keep_method_def = load i64, i64* @rubyIdPrecomputed_keep_method_def, align 8
  %4 = load i64, i64* @ruby_vm_global_method_state, align 8, !tbaa !22
  %5 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 1
  %6 = load i64, i64* %5, align 8, !tbaa !23
  %7 = icmp eq i64 %4, %6
  br i1 %7, label %8, label %updateIC, !prof !58

8:                                                ; preds = %functionEntryInitializers
  %9 = and i64 %2, 7
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %23, label %11

11:                                               ; preds = %8
  %12 = trunc i64 %2 to i32
  %13 = and i32 %12, 1
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %15, label %sorbet_isInlineCacheValid.exit

15:                                               ; preds = %11
  %16 = and i32 %12, 3
  %17 = icmp eq i32 %16, 2
  br i1 %17, label %sorbet_isInlineCacheValid.exit, label %18

18:                                               ; preds = %15
  %19 = icmp eq i64 %2, 20
  br i1 %19, label %sorbet_isInlineCacheValid.exit, label %20

20:                                               ; preds = %18
  %21 = and i64 %2, 255
  %22 = icmp eq i64 %21, 12
  br i1 %22, label %sorbet_isInlineCacheValid.exit, label %28

23:                                               ; preds = %8
  %24 = and i64 %2, -9
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %26, label %28

26:                                               ; preds = %23
  switch i64 %2, label %28 [
    i64 8, label %sorbet_isInlineCacheValid.exit
    i64 0, label %27
  ]

27:                                               ; preds = %26
  br label %sorbet_isInlineCacheValid.exit

28:                                               ; preds = %26, %23, %20
  %29 = inttoptr i64 %2 to %struct.RBasic*
  %30 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %29, i64 0, i32 1
  %phitmp.i.i = bitcast i64* %30 to %struct.RClass**
  br label %sorbet_isInlineCacheValid.exit

sorbet_isInlineCacheValid.exit:                   ; preds = %11, %15, %18, %20, %26, %27, %28
  %31 = phi %struct.RClass** [ %phitmp.i.i, %28 ], [ bitcast (i64* @rb_cFalseClass to %struct.RClass**), %27 ], [ bitcast (i64* @rb_cInteger to %struct.RClass**), %11 ], [ bitcast (i64* @rb_cFloat to %struct.RClass**), %15 ], [ bitcast (i64* @rb_cTrueClass to %struct.RClass**), %18 ], [ bitcast (i64* @rb_cSymbol to %struct.RClass**), %20 ], [ bitcast (i64* @rb_cNilClass to %struct.RClass**), %26 ]
  %32 = load %struct.RClass*, %struct.RClass** %31, align 8, !tbaa !9
  %33 = getelementptr inbounds %struct.RClass, %struct.RClass* %32, i64 0, i32 2
  %34 = load %struct.rb_classext_struct*, %struct.rb_classext_struct** %33, align 8, !tbaa !24
  %35 = getelementptr inbounds %struct.rb_classext_struct, %struct.rb_classext_struct* %34, i64 0, i32 7
  %36 = load i64, i64* %35, align 8, !tbaa !26
  %37 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 2
  %38 = load i64, i64* %37, align 8, !tbaa !28
  %39 = icmp eq i64 %36, %38
  br i1 %39, label %call, label %updateIC, !prof !57

updateIC:                                         ; preds = %functionEntryInitializers, %sorbet_isInlineCacheValid.exit
  tail call fastcc void @sorbet_inlineCacheInvalidated(i64 %2, %struct.FunctionInlineCache* nonnull %3, i64 %rubyId_keep_method_def)
  br label %call

call:                                             ; preds = %updateIC, %sorbet_isInlineCacheValid.exit
  %40 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11, !noalias !59
  %41 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 0
  %42 = load %struct.rb_callable_method_entry_struct*, %struct.rb_callable_method_entry_struct** %41, align 8, !tbaa !19, !noalias !59
  %43 = tail call i64 @rb_vm_call(%struct.rb_execution_context_struct* %40, i64 %2, i64 %rubyId_keep_method_def, i32 %0, i64* %1, %struct.rb_callable_method_entry_struct* %42) #18
  ret i64 %43
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_keep_method_def() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([16 x i8], [16 x i8]* @str_keep_method_def, i64 0, i64 0), i64 15) #18
  store i64 %0, i64* @rubyIdPrecomputed_keep_method_def, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_boo() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_boo, i64 0, i64 0), i64 3) #18
  store i64 %0, i64* @rubyIdPrecomputed_boo, align 8
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_Object#boo"(i32 %argc, i64* nocapture readnone %argArray, i64 %selfRaw) #12 {
functionEntryInitializers:
  %callArgs = alloca [0 x i64], align 8
  %tooManyArgs = icmp eq i32 %argc, 0
  br i1 %tooManyArgs, label %fillRequiredArgs, label %argCountFailBlock, !prof !57

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %"stackFrame_func_Object#boo12" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_Object#boo" to i64*), align 8
  %0 = tail call i32 @rb_block_given_p() #18
  %1 = icmp eq i32 %0, 0
  br i1 %1, label %sorbet_getMethodBlockAsProc.exit, label %2

2:                                                ; preds = %fillRequiredArgs
  %3 = tail call i64 @rb_block_proc() #18
  br label %sorbet_getMethodBlockAsProc.exit

sorbet_getMethodBlockAsProc.exit:                 ; preds = %fillRequiredArgs, %2
  %4 = phi i64 [ %3, %2 ], [ 8, %fillRequiredArgs ]
  %5 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %6 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %5, i64 0, i32 2
  %7 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %6, align 8, !tbaa !13
  %8 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 2
  %9 = bitcast %struct.rb_iseq_struct** %8 to i64*
  store i64 %"stackFrame_func_Object#boo12", i64* %9, align 8, !tbaa !16
  %10 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 4
  %11 = load i64*, i64** %10, align 8, !tbaa !18
  %12 = load i64, i64* %11, align 8, !tbaa !9
  %13 = and i64 %12, -129
  store i64 %13, i64* %11, align 8, !tbaa !9
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 0
  store i64* inttoptr (i64 8 to i64*), i64** %14, align 8, !tbaa !11
  %15 = load i64, i64* @rb_cObject, align 8
  %16 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %15) #6
  %17 = icmp eq i64 %16, 20
  br i1 %17, label %typeTestSuccess, label %codeRepl, !prof !57

typeTestSuccess:                                  ; preds = %sorbet_getMethodBlockAsProc.exit
  store i64* inttoptr (i64 16 to i64*), i64** %14, align 8, !tbaa !11
  %18 = getelementptr inbounds [0 x i64], [0 x i64]* %callArgs, i64 0, i64 0
  %rawSendResult = call i64 @call_via_vm_call(i32 0, i64* nonnull %18, i64 %4, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_call.9) #18
  ret i64 %rawSendResult

codeRepl:                                         ; preds = %sorbet_getMethodBlockAsProc.exit
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0)) #18
  unreachable
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_bar() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_bar, i64 0, i64 0), i64 3) #18
  store i64 %0, i64* @rubyIdPrecomputed_bar, align 8
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_Object#bar"(i32 %argc, i64* nocapture readnone %argArray, i64 %selfRaw) #12 {
functionEntryInitializers:
  %callArgs = alloca [3 x i64], align 8
  %rubyId_foo = load i64, i64* @rubyIdPrecomputed_foo, align 8
  %tooManyArgs = icmp eq i32 %argc, 0
  br i1 %tooManyArgs, label %fillRequiredArgs, label %argCountFailBlock, !prof !57

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %"stackFrame_func_Object#bar18" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_Object#bar" to i64*), align 8
  %0 = tail call i32 @rb_block_given_p() #18
  %1 = icmp eq i32 %0, 0
  br i1 %1, label %sorbet_getMethodBlockAsProc.exit, label %2

2:                                                ; preds = %fillRequiredArgs
  %3 = tail call i64 @rb_block_proc() #18
  br label %sorbet_getMethodBlockAsProc.exit

sorbet_getMethodBlockAsProc.exit:                 ; preds = %fillRequiredArgs, %2
  %4 = phi i64 [ %3, %2 ], [ 8, %fillRequiredArgs ]
  %5 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %6 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %5, i64 0, i32 2
  %7 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %6, align 8, !tbaa !13
  %8 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 2
  %9 = bitcast %struct.rb_iseq_struct** %8 to i64*
  store i64 %"stackFrame_func_Object#bar18", i64* %9, align 8, !tbaa !16
  %10 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 4
  %11 = load i64*, i64** %10, align 8, !tbaa !18
  %12 = load i64, i64* %11, align 8, !tbaa !9
  %13 = and i64 %12, -129
  store i64 %13, i64* %11, align 8, !tbaa !9
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 0
  store i64* inttoptr (i64 8 to i64*), i64** %14, align 8, !tbaa !11
  %15 = load i64, i64* @rb_cObject, align 8
  %16 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %15) #6
  %17 = icmp eq i64 %16, 20
  br i1 %17, label %typeTestSuccess, label %codeRepl, !prof !57

typeTestSuccess:                                  ; preds = %sorbet_getMethodBlockAsProc.exit
  store i64* inttoptr (i64 16 to i64*), i64** %14, align 8, !tbaa !11
  %rawSym = tail call i64 @rb_id2sym(i64 %rubyId_foo) #18
  %rawSendResult = tail call i64 @call_via_vm_to_proc(i32 0, i64* null, i64 %4, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_to_proc) #18
  %18 = getelementptr inbounds [3 x i64], [3 x i64]* %callArgs, i64 0, i64 0
  %19 = call i64 @rb_funcall_with_block(i64 %selfRaw, i64 %rubyId_foo, i32 0, i64* nonnull %18, i64 %rawSendResult) #18
  ret i64 %19

codeRepl:                                         ; preds = %sorbet_getMethodBlockAsProc.exit
  tail call fastcc void @"func_Object#bar.cold.1"(i64 %selfRaw) #21
  unreachable
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_baz() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_baz, i64 0, i64 0), i64 3) #18
  store i64 %0, i64* @rubyIdPrecomputed_baz, align 8
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @"func_Object#baz"(i32 %argc, i64* nocapture readnone %argArray, i64 %selfRaw) #12 {
functionEntryInitializers:
  %callArgs = alloca [1 x i64], align 8
  %rubyStr_baz = load i64, i64* @rubyStrFrozen_baz, align 8
  %tooManyArgs = icmp eq i32 %argc, 0
  br i1 %tooManyArgs, label %fillRequiredArgs, label %argCountFailBlock, !prof !57

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %"stackFrame_func_Object#baz14" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_Object#baz" to i64*), align 8
  %0 = tail call i32 @rb_block_given_p() #18
  %1 = icmp eq i32 %0, 0
  br i1 %1, label %sorbet_getMethodBlockAsProc.exit, label %2

2:                                                ; preds = %fillRequiredArgs
  %3 = tail call i64 @rb_block_proc() #18
  br label %sorbet_getMethodBlockAsProc.exit

sorbet_getMethodBlockAsProc.exit:                 ; preds = %fillRequiredArgs, %2
  %4 = phi i64 [ %3, %2 ], [ 8, %fillRequiredArgs ]
  %5 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %6 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %5, i64 0, i32 2
  %7 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %6, align 8, !tbaa !13
  %8 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 2
  %9 = bitcast %struct.rb_iseq_struct** %8 to i64*
  store i64 %"stackFrame_func_Object#baz14", i64* %9, align 8, !tbaa !16
  %10 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 4
  %11 = load i64*, i64** %10, align 8, !tbaa !18
  %12 = load i64, i64* %11, align 8, !tbaa !9
  %13 = and i64 %12, -129
  store i64 %13, i64* %11, align 8, !tbaa !9
  %14 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %7, i64 0, i32 0
  store i64* inttoptr (i64 8 to i64*), i64** %14, align 8, !tbaa !11
  %15 = load i64, i64* @rb_cObject, align 8
  %16 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %15) #6
  %17 = icmp eq i64 %16, 20
  br i1 %17, label %typeTestSuccess, label %codeRepl, !prof !57

typeTestSuccess:                                  ; preds = %sorbet_getMethodBlockAsProc.exit
  store i64* inttoptr (i64 16 to i64*), i64** %14, align 8, !tbaa !11
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  store i64 %rubyStr_baz, i64* %callArgsAddr, align 8
  %rawSendResult = call i64 @call_via_vm_call(i32 1, i64* nonnull %callArgsAddr, i64 %4, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_call.10) #18
  ret i64 %rawSendResult

codeRepl:                                         ; preds = %sorbet_getMethodBlockAsProc.exit
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0)) #18
  unreachable
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyStrFrozen_heey() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_heey, i64 0, i64 0), i64 4) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @rubyStrFrozen_heey, align 8
  ret void
}

; Function Attrs: noinline ssp
define linkonce i64 @call_via_vm_puts(i32, i64*, i64, %struct.FunctionInlineCache*) local_unnamed_addr #13 {
functionEntryInitializers:
  %rubyId_puts = load i64, i64* @rubyIdPrecomputed_puts, align 8
  %4 = load i64, i64* @ruby_vm_global_method_state, align 8, !tbaa !22
  %5 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 1
  %6 = load i64, i64* %5, align 8, !tbaa !23
  %7 = icmp eq i64 %4, %6
  br i1 %7, label %8, label %updateIC, !prof !58

8:                                                ; preds = %functionEntryInitializers
  %9 = and i64 %2, 7
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %23, label %11

11:                                               ; preds = %8
  %12 = trunc i64 %2 to i32
  %13 = and i32 %12, 1
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %15, label %sorbet_isInlineCacheValid.exit

15:                                               ; preds = %11
  %16 = and i32 %12, 3
  %17 = icmp eq i32 %16, 2
  br i1 %17, label %sorbet_isInlineCacheValid.exit, label %18

18:                                               ; preds = %15
  %19 = icmp eq i64 %2, 20
  br i1 %19, label %sorbet_isInlineCacheValid.exit, label %20

20:                                               ; preds = %18
  %21 = and i64 %2, 255
  %22 = icmp eq i64 %21, 12
  br i1 %22, label %sorbet_isInlineCacheValid.exit, label %28

23:                                               ; preds = %8
  %24 = and i64 %2, -9
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %26, label %28

26:                                               ; preds = %23
  switch i64 %2, label %28 [
    i64 8, label %sorbet_isInlineCacheValid.exit
    i64 0, label %27
  ]

27:                                               ; preds = %26
  br label %sorbet_isInlineCacheValid.exit

28:                                               ; preds = %26, %23, %20
  %29 = inttoptr i64 %2 to %struct.RBasic*
  %30 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %29, i64 0, i32 1
  %phitmp.i.i = bitcast i64* %30 to %struct.RClass**
  br label %sorbet_isInlineCacheValid.exit

sorbet_isInlineCacheValid.exit:                   ; preds = %11, %15, %18, %20, %26, %27, %28
  %31 = phi %struct.RClass** [ %phitmp.i.i, %28 ], [ bitcast (i64* @rb_cFalseClass to %struct.RClass**), %27 ], [ bitcast (i64* @rb_cInteger to %struct.RClass**), %11 ], [ bitcast (i64* @rb_cFloat to %struct.RClass**), %15 ], [ bitcast (i64* @rb_cTrueClass to %struct.RClass**), %18 ], [ bitcast (i64* @rb_cSymbol to %struct.RClass**), %20 ], [ bitcast (i64* @rb_cNilClass to %struct.RClass**), %26 ]
  %32 = load %struct.RClass*, %struct.RClass** %31, align 8, !tbaa !9
  %33 = getelementptr inbounds %struct.RClass, %struct.RClass* %32, i64 0, i32 2
  %34 = load %struct.rb_classext_struct*, %struct.rb_classext_struct** %33, align 8, !tbaa !24
  %35 = getelementptr inbounds %struct.rb_classext_struct, %struct.rb_classext_struct* %34, i64 0, i32 7
  %36 = load i64, i64* %35, align 8, !tbaa !26
  %37 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 2
  %38 = load i64, i64* %37, align 8, !tbaa !28
  %39 = icmp eq i64 %36, %38
  br i1 %39, label %call, label %updateIC, !prof !57

updateIC:                                         ; preds = %functionEntryInitializers, %sorbet_isInlineCacheValid.exit
  tail call fastcc void @sorbet_inlineCacheInvalidated(i64 %2, %struct.FunctionInlineCache* nonnull %3, i64 %rubyId_puts)
  br label %call

call:                                             ; preds = %updateIC, %sorbet_isInlineCacheValid.exit
  %40 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11, !noalias !62
  %41 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 0
  %42 = load %struct.rb_callable_method_entry_struct*, %struct.rb_callable_method_entry_struct** %41, align 8, !tbaa !19, !noalias !62
  %43 = tail call i64 @rb_vm_call(%struct.rb_execution_context_struct* %40, i64 %2, i64 %rubyId_puts, i32 %0, i64* %1, %struct.rb_callable_method_entry_struct* %42) #18
  ret i64 %43
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_puts() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_puts, i64 0, i64 0), i64 4) #18
  store i64 %0, i64* @rubyIdPrecomputed_puts, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyStrFrozen_boohey() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_boohey, i64 0, i64 0), i64 6) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @rubyStrFrozen_boohey, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyStrFrozen_bar() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_bar, i64 0, i64 0), i64 3) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @rubyStrFrozen_bar, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_compiler_method_with_block() local_unnamed_addr #14 {
entry:
  %callArgs.i = alloca [2 x i64], align 8
  %0 = load %struct.rb_vm_struct*, %struct.rb_vm_struct** @ruby_current_vm_ptr, align 8, !tbaa !11
  %1 = getelementptr inbounds %struct.rb_vm_struct, %struct.rb_vm_struct* %0, i64 0, i32 17
  %2 = load i64, i64* %1, align 8, !tbaa !65
  %3 = bitcast [2 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %3)
  %4 = tail call i8* @ruby_xmalloc(i64 16) #18
  %5 = bitcast i8* %4 to i32*
  store i32 1, i32* %5, align 8, !tbaa !0
  %6 = load i64, i64* @rb_cData, align 8, !tbaa !9
  %7 = tail call i64 @rb_data_typed_object_wrap(i64 %6, i8* %4, %struct.rb_data_type_struct* nonnull @closureInfo) #18
  %8 = inttoptr i64 %7 to %struct.RTypedData*
  %9 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %8, i64 0, i32 3
  %10 = bitcast i8** %9 to %struct.sorbet_Closure**
  %11 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %12 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %11, i64 0, i32 1, i64 0
  store i64 8, i64* %12, align 8
  %rubyId_foo.i = load i64, i64* @rubyIdPrecomputed_foo, align 8
  %rubyId_boo.i = load i64, i64* @rubyIdPrecomputed_boo, align 8
  %rubyId_bar.i = load i64, i64* @rubyIdPrecomputed_bar, align 8
  %rubyId_baz.i = load i64, i64* @rubyIdPrecomputed_baz, align 8
  %"stackFrame_func_<root>.<static-init>$1111.i" = load i64, i64* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$111" to i64*), align 8
  %13 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %14 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %13, i64 0, i32 1, i64 0
  store i64 %2, i64* %14, align 8
  %15 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11
  %16 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %15, i64 0, i32 2
  %17 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %16, align 8, !tbaa !13
  %18 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %17, i64 0, i32 2
  %19 = bitcast %struct.rb_iseq_struct** %18 to i64*
  store i64 %"stackFrame_func_<root>.<static-init>$1111.i", i64* %19, align 8, !tbaa !16
  %20 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %17, i64 0, i32 4
  %21 = load i64*, i64** %20, align 8, !tbaa !18
  %22 = load i64, i64* %21, align 8, !tbaa !9
  %23 = and i64 %22, -129
  store i64 %23, i64* %21, align 8, !tbaa !9
  %24 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %17, i64 0, i32 0
  store i64* inttoptr (i64 8 to i64*), i64** %24, align 8, !tbaa !11
  %25 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %26 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %25, i64 0, i32 1, i64 0
  %27 = load i64, i64* %26, align 8
  %28 = load %struct.rb_vm_struct*, %struct.rb_vm_struct** @ruby_current_vm_ptr, align 8, !tbaa !11
  %29 = getelementptr inbounds %struct.rb_vm_struct, %struct.rb_vm_struct* %28, i64 0, i32 17
  %30 = load i64, i64* %29, align 8, !tbaa !65
  %31 = icmp eq i64 %30, %27
  br i1 %31, label %"func_<root>.<static-init>$111.exit", label %codeRepl, !prof !57

codeRepl:                                         ; preds = %entry
  tail call fastcc void @Init_test_testdata_compiler_method_with_block.cold.1(i64 %27) #21
  unreachable

"func_<root>.<static-init>$111.exit":             ; preds = %entry
  %32 = load i64, i64* @rb_cObject, align 8
  %callArgsAddr.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i, i64 0, i64 0
  %rawSym.i = tail call i64 @rb_id2sym(i64 %rubyId_foo.i) #18
  tail call void @rb_define_method(i64 %32, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_Object#foo" to i64 (...)*), i32 -1) #18
  %rawSym94.i = tail call i64 @rb_id2sym(i64 %rubyId_foo.i) #18
  %33 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %34 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %33, i64 0, i32 1, i64 0
  %35 = load i64, i64* %34, align 8
  store i64 %35, i64* %callArgsAddr.i, align 8
  %callArgsAddr98.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i, i64 0, i64 1
  store i64 %rawSym94.i, i64* %callArgsAddr98.i, align 8
  %36 = load i64, i64* @"guard_epoch_Sorbet::Private::Static", align 8
  %37 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !22
  %needTakeSlowPath = icmp eq i64 %36, %37
  br i1 %needTakeSlowPath, label %39, label %38, !prof !73

38:                                               ; preds = %"func_<root>.<static-init>$111.exit"
  tail call void @"const_recompute_Sorbet::Private::Static"() #18
  br label %39

39:                                               ; preds = %"func_<root>.<static-init>$111.exit", %38
  %40 = load i64, i64* @"guarded_const_Sorbet::Private::Static", align 8
  %41 = load i64, i64* @"guard_epoch_Sorbet::Private::Static", align 8
  %42 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !22
  %guardUpdated = icmp eq i64 %41, %42
  tail call void @llvm.assume(i1 %guardUpdated)
  %rawSendResult99.i = call i64 @call_via_vm_keep_method_def(i32 2, i64* nonnull %callArgsAddr.i, i64 %40, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_keep_method_def) #18
  store i64* inttoptr (i64 40 to i64*), i64** %24, align 8, !tbaa !11
  store i64 %32, i64* %callArgsAddr.i, align 8
  %rawSym108.i = call i64 @rb_id2sym(i64 %rubyId_boo.i) #18
  call void @rb_define_method(i64 %32, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_boo, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_Object#boo" to i64 (...)*), i32 -1) #18
  %rawSym113.i = call i64 @rb_id2sym(i64 %rubyId_boo.i) #18
  %43 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %44 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %43, i64 0, i32 1, i64 0
  %45 = load i64, i64* %44, align 8
  store i64 %45, i64* %callArgsAddr.i, align 8
  store i64 %rawSym113.i, i64* %callArgsAddr98.i, align 8
  %rawSendResult119.i = call i64 @call_via_vm_keep_method_def(i32 2, i64* nonnull %callArgsAddr.i, i64 %40, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_keep_method_def.2) #18
  store i64* inttoptr (i64 72 to i64*), i64** %24, align 8, !tbaa !11
  store i64 %32, i64* %callArgsAddr.i, align 8
  %rawSym128.i = call i64 @rb_id2sym(i64 %rubyId_bar.i) #18
  call void @rb_define_method(i64 %32, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_bar, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_Object#bar" to i64 (...)*), i32 -1) #18
  %rawSym133.i = call i64 @rb_id2sym(i64 %rubyId_bar.i) #18
  %46 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %47 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %46, i64 0, i32 1, i64 0
  %48 = load i64, i64* %47, align 8
  store i64 %48, i64* %callArgsAddr.i, align 8
  store i64 %rawSym133.i, i64* %callArgsAddr98.i, align 8
  %rawSendResult139.i = call i64 @call_via_vm_keep_method_def(i32 2, i64* nonnull %callArgsAddr.i, i64 %40, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_keep_method_def.4) #18
  store i64* inttoptr (i64 104 to i64*), i64** %24, align 8, !tbaa !11
  store i64 %32, i64* %callArgsAddr.i, align 8
  %rawSym148.i = call i64 @rb_id2sym(i64 %rubyId_baz.i) #18
  call void @rb_define_method(i64 %32, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_baz, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @"func_Object#baz" to i64 (...)*), i32 -1) #18
  %rawSym153.i = call i64 @rb_id2sym(i64 %rubyId_baz.i) #18
  %49 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %50 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %49, i64 0, i32 1, i64 0
  %51 = load i64, i64* %50, align 8
  store i64 %51, i64* %callArgsAddr.i, align 8
  store i64 %rawSym153.i, i64* %callArgsAddr98.i, align 8
  %rawSendResult159.i = call i64 @call_via_vm_keep_method_def(i32 2, i64* nonnull %callArgsAddr.i, i64 %40, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_keep_method_def.6) #18
  store i64* inttoptr (i64 136 to i64*), i64** %24, align 8, !tbaa !11
  %52 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %53 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %52, i64 0, i32 1, i64 0
  %54 = load i64, i64* %53, align 8
  %55 = call i64 @rb_block_call(i64 %54, i64 %rubyId_foo.i, i32 0, i64* nonnull %callArgsAddr.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_<root>.<static-init>$111$block_1" to i64 (...)*), i64 %7) #18
  %56 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %57 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %56, i64 0, i32 1, i64 0
  %58 = load i64, i64* %57, align 8
  store i64* inttoptr (i64 136 to i64*), i64** %24, align 8, !tbaa !11
  %59 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %60 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %59, i64 0, i32 1, i64 0
  store i64 %58, i64* %60, align 8
  store i64* inttoptr (i64 168 to i64*), i64** %24, align 8, !tbaa !11
  %61 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %62 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %61, i64 0, i32 1, i64 0
  %63 = load i64, i64* %62, align 8
  %64 = call i64 @rb_block_call(i64 %63, i64 %rubyId_boo.i, i32 0, i64* nonnull %callArgsAddr.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_<root>.<static-init>$111$block_2" to i64 (...)*), i64 %7) #18
  %65 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %66 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %65, i64 0, i32 1, i64 0
  %67 = load i64, i64* %66, align 8
  store i64* inttoptr (i64 168 to i64*), i64** %24, align 8, !tbaa !11
  %68 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %69 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %68, i64 0, i32 1, i64 0
  store i64 %67, i64* %69, align 8
  store i64* inttoptr (i64 200 to i64*), i64** %24, align 8, !tbaa !11
  %70 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %71 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %70, i64 0, i32 1, i64 0
  %72 = load i64, i64* %71, align 8
  %73 = call i64 @rb_block_call(i64 %72, i64 %rubyId_bar.i, i32 0, i64* nonnull %callArgsAddr.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_<root>.<static-init>$111$block_3" to i64 (...)*), i64 %7) #18
  %74 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %75 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %74, i64 0, i32 1, i64 0
  %76 = load i64, i64* %75, align 8
  store i64* inttoptr (i64 200 to i64*), i64** %24, align 8, !tbaa !11
  %77 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %78 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %77, i64 0, i32 1, i64 0
  store i64 %76, i64* %78, align 8
  store i64* inttoptr (i64 232 to i64*), i64** %24, align 8, !tbaa !11
  %79 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %10, align 8, !tbaa !29
  %80 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %79, i64 0, i32 1, i64 0
  %81 = load i64, i64* %80, align 8
  %82 = call i64 @rb_block_call(i64 %81, i64 %rubyId_baz.i, i32 0, i64* nonnull %callArgsAddr.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_<root>.<static-init>$111$block_4" to i64 (...)*), i64 %7) #18
  store i64* inttoptr (i64 232 to i64*), i64** %24, align 8, !tbaa !11
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %3)
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_Object#foo"() #11 {
sorbet_allocateRubyStackFrames.exit:
  %rubyStr_foo = load i64, i64* @rubyStrFrozen_foo, align 8
  %"rubyStr_test/testdata/compiler/method_with_block.rb" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/method_with_block.rb", align 8
  %0 = tail call %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct* null, i64 %rubyStr_foo, i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", %struct.rb_iseq_struct* null, i32 1) #18
  %1 = ptrtoint %struct.rb_iseq_struct* %0 to i64
  tail call void @rb_gc_register_mark_object(i64 %1) #18
  %2 = tail call i8* @ruby_xmalloc2(i64 3, i64 8) #18
  %3 = tail call i8* @ruby_xmalloc2(i64 3, i64 4) #18
  %4 = bitcast i8* %3 to i32*
  store i32 0, i32* %4, align 4, !tbaa !0
  %5 = bitcast i8* %2 to i32*
  store i32 5, i32* %5, align 4, !tbaa !36
  %6 = getelementptr inbounds i8, i8* %3, i64 4
  %7 = bitcast i8* %6 to i32*
  store i32 1, i32* %7, align 4, !tbaa !0
  %8 = getelementptr inbounds i8, i8* %2, i64 8
  %9 = bitcast i8* %8 to i32*
  store i32 6, i32* %9, align 4, !tbaa !36
  %10 = getelementptr inbounds i8, i8* %3, i64 8
  %11 = bitcast i8* %10 to i32*
  store i32 2, i32* %11, align 4, !tbaa !0
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to i32*
  store i32 7, i32* %13, align 4, !tbaa !36
  %14 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %0, i64 0, i32 2
  %15 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %16 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 0
  %17 = bitcast %struct.rb_code_position_struct** %16 to i8**
  store i8* %2, i8** %17, align 8, !tbaa !44
  %18 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 1
  %19 = bitcast i32** %18 to i8**
  store i8* %3, i8** %19, align 8, !tbaa !53
  %20 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 1
  store i32 3, i32* %20, align 4, !tbaa !54
  %21 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 2
  store i32 3, i32* %21, align 8, !tbaa !55
  tail call void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct* %0) #18
  %22 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %23 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %22, i64 0, i32 2
  store i64* null, i64** %23, align 8, !tbaa !56
  store %struct.rb_iseq_struct* %0, %struct.rb_iseq_struct** bitcast (i8** @"stackFramePrecomputed_func_Object#foo" to %struct.rb_iseq_struct**), align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyStrFrozen_foo() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_foo, i64 0, i64 0), i64 3) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @rubyStrFrozen_foo, align 8
  ret void
}

; Function Attrs: noinline ssp
define linkonce i64 @call_via_vm_call(i32, i64*, i64, %struct.FunctionInlineCache*) local_unnamed_addr #13 {
functionEntryInitializers:
  %rubyId_call = load i64, i64* @rubyIdPrecomputed_call, align 8
  %4 = load i64, i64* @ruby_vm_global_method_state, align 8, !tbaa !22
  %5 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 1
  %6 = load i64, i64* %5, align 8, !tbaa !23
  %7 = icmp eq i64 %4, %6
  br i1 %7, label %8, label %updateIC, !prof !58

8:                                                ; preds = %functionEntryInitializers
  %9 = and i64 %2, 7
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %23, label %11

11:                                               ; preds = %8
  %12 = trunc i64 %2 to i32
  %13 = and i32 %12, 1
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %15, label %sorbet_isInlineCacheValid.exit

15:                                               ; preds = %11
  %16 = and i32 %12, 3
  %17 = icmp eq i32 %16, 2
  br i1 %17, label %sorbet_isInlineCacheValid.exit, label %18

18:                                               ; preds = %15
  %19 = icmp eq i64 %2, 20
  br i1 %19, label %sorbet_isInlineCacheValid.exit, label %20

20:                                               ; preds = %18
  %21 = and i64 %2, 255
  %22 = icmp eq i64 %21, 12
  br i1 %22, label %sorbet_isInlineCacheValid.exit, label %28

23:                                               ; preds = %8
  %24 = and i64 %2, -9
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %26, label %28

26:                                               ; preds = %23
  switch i64 %2, label %28 [
    i64 8, label %sorbet_isInlineCacheValid.exit
    i64 0, label %27
  ]

27:                                               ; preds = %26
  br label %sorbet_isInlineCacheValid.exit

28:                                               ; preds = %26, %23, %20
  %29 = inttoptr i64 %2 to %struct.RBasic*
  %30 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %29, i64 0, i32 1
  %phitmp.i.i = bitcast i64* %30 to %struct.RClass**
  br label %sorbet_isInlineCacheValid.exit

sorbet_isInlineCacheValid.exit:                   ; preds = %11, %15, %18, %20, %26, %27, %28
  %31 = phi %struct.RClass** [ %phitmp.i.i, %28 ], [ bitcast (i64* @rb_cFalseClass to %struct.RClass**), %27 ], [ bitcast (i64* @rb_cInteger to %struct.RClass**), %11 ], [ bitcast (i64* @rb_cFloat to %struct.RClass**), %15 ], [ bitcast (i64* @rb_cTrueClass to %struct.RClass**), %18 ], [ bitcast (i64* @rb_cSymbol to %struct.RClass**), %20 ], [ bitcast (i64* @rb_cNilClass to %struct.RClass**), %26 ]
  %32 = load %struct.RClass*, %struct.RClass** %31, align 8, !tbaa !9
  %33 = getelementptr inbounds %struct.RClass, %struct.RClass* %32, i64 0, i32 2
  %34 = load %struct.rb_classext_struct*, %struct.rb_classext_struct** %33, align 8, !tbaa !24
  %35 = getelementptr inbounds %struct.rb_classext_struct, %struct.rb_classext_struct* %34, i64 0, i32 7
  %36 = load i64, i64* %35, align 8, !tbaa !26
  %37 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 2
  %38 = load i64, i64* %37, align 8, !tbaa !28
  %39 = icmp eq i64 %36, %38
  br i1 %39, label %call, label %updateIC, !prof !57

updateIC:                                         ; preds = %functionEntryInitializers, %sorbet_isInlineCacheValid.exit
  tail call fastcc void @sorbet_inlineCacheInvalidated(i64 %2, %struct.FunctionInlineCache* nonnull %3, i64 %rubyId_call)
  br label %call

call:                                             ; preds = %updateIC, %sorbet_isInlineCacheValid.exit
  %40 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11, !noalias !74
  %41 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 0
  %42 = load %struct.rb_callable_method_entry_struct*, %struct.rb_callable_method_entry_struct** %41, align 8, !tbaa !19, !noalias !74
  %43 = tail call i64 @rb_vm_call(%struct.rb_execution_context_struct* %40, i64 %2, i64 %rubyId_call, i32 %0, i64* %1, %struct.rb_callable_method_entry_struct* %42) #18
  ret i64 %43
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_call() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_call, i64 0, i64 0), i64 4) #18
  store i64 %0, i64* @rubyIdPrecomputed_call, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_Object#boo"() #11 {
sorbet_allocateRubyStackFrames.exit:
  %rubyStr_boo = load i64, i64* @rubyStrFrozen_boo, align 8
  %"rubyStr_test/testdata/compiler/method_with_block.rb" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/method_with_block.rb", align 8
  %0 = tail call %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct* null, i64 %rubyStr_boo, i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", %struct.rb_iseq_struct* null, i32 1) #18
  %1 = ptrtoint %struct.rb_iseq_struct* %0 to i64
  tail call void @rb_gc_register_mark_object(i64 %1) #18
  %2 = tail call i8* @ruby_xmalloc2(i64 3, i64 8) #18
  %3 = tail call i8* @ruby_xmalloc2(i64 3, i64 4) #18
  %4 = bitcast i8* %3 to i32*
  store i32 0, i32* %4, align 4, !tbaa !0
  %5 = bitcast i8* %2 to i32*
  store i32 9, i32* %5, align 4, !tbaa !36
  %6 = getelementptr inbounds i8, i8* %3, i64 4
  %7 = bitcast i8* %6 to i32*
  store i32 1, i32* %7, align 4, !tbaa !0
  %8 = getelementptr inbounds i8, i8* %2, i64 8
  %9 = bitcast i8* %8 to i32*
  store i32 10, i32* %9, align 4, !tbaa !36
  %10 = getelementptr inbounds i8, i8* %3, i64 8
  %11 = bitcast i8* %10 to i32*
  store i32 2, i32* %11, align 4, !tbaa !0
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to i32*
  store i32 11, i32* %13, align 4, !tbaa !36
  %14 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %0, i64 0, i32 2
  %15 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %16 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 0
  %17 = bitcast %struct.rb_code_position_struct** %16 to i8**
  store i8* %2, i8** %17, align 8, !tbaa !44
  %18 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 1
  %19 = bitcast i32** %18 to i8**
  store i8* %3, i8** %19, align 8, !tbaa !53
  %20 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 1
  store i32 3, i32* %20, align 4, !tbaa !54
  %21 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 2
  store i32 3, i32* %21, align 8, !tbaa !55
  tail call void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct* %0) #18
  %22 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %23 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %22, i64 0, i32 2
  store i64* null, i64** %23, align 8, !tbaa !56
  store %struct.rb_iseq_struct* %0, %struct.rb_iseq_struct** bitcast (i8** @"stackFramePrecomputed_func_Object#boo" to %struct.rb_iseq_struct**), align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyStrFrozen_boo() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_boo, i64 0, i64 0), i64 3) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @rubyStrFrozen_boo, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_Object#bar"() #11 {
sorbet_allocateRubyStackFrames.exit:
  %rubyStr_bar = load i64, i64* @rubyStrFrozen_bar, align 8
  %"rubyStr_test/testdata/compiler/method_with_block.rb" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/method_with_block.rb", align 8
  %0 = tail call %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct* null, i64 %rubyStr_bar, i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", %struct.rb_iseq_struct* null, i32 1) #18
  %1 = ptrtoint %struct.rb_iseq_struct* %0 to i64
  tail call void @rb_gc_register_mark_object(i64 %1) #18
  %2 = tail call i8* @ruby_xmalloc2(i64 3, i64 8) #18
  %3 = tail call i8* @ruby_xmalloc2(i64 3, i64 4) #18
  %4 = bitcast i8* %3 to i32*
  store i32 0, i32* %4, align 4, !tbaa !0
  %5 = bitcast i8* %2 to i32*
  store i32 13, i32* %5, align 4, !tbaa !36
  %6 = getelementptr inbounds i8, i8* %3, i64 4
  %7 = bitcast i8* %6 to i32*
  store i32 1, i32* %7, align 4, !tbaa !0
  %8 = getelementptr inbounds i8, i8* %2, i64 8
  %9 = bitcast i8* %8 to i32*
  store i32 14, i32* %9, align 4, !tbaa !36
  %10 = getelementptr inbounds i8, i8* %3, i64 8
  %11 = bitcast i8* %10 to i32*
  store i32 2, i32* %11, align 4, !tbaa !0
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to i32*
  store i32 15, i32* %13, align 4, !tbaa !36
  %14 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %0, i64 0, i32 2
  %15 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %16 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 0
  %17 = bitcast %struct.rb_code_position_struct** %16 to i8**
  store i8* %2, i8** %17, align 8, !tbaa !44
  %18 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 1
  %19 = bitcast i32** %18 to i8**
  store i8* %3, i8** %19, align 8, !tbaa !53
  %20 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 1
  store i32 3, i32* %20, align 4, !tbaa !54
  %21 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 2
  store i32 3, i32* %21, align 8, !tbaa !55
  tail call void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct* %0) #18
  %22 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %23 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %22, i64 0, i32 2
  store i64* null, i64** %23, align 8, !tbaa !56
  store %struct.rb_iseq_struct* %0, %struct.rb_iseq_struct** bitcast (i8** @"stackFramePrecomputed_func_Object#bar" to %struct.rb_iseq_struct**), align 8
  ret void
}

; Function Attrs: noinline ssp
define linkonce i64 @call_via_vm_to_proc(i32, i64*, i64, %struct.FunctionInlineCache*) local_unnamed_addr #13 {
functionEntryInitializers:
  %rubyId_to_proc = load i64, i64* @rubyIdPrecomputed_to_proc, align 8
  %4 = load i64, i64* @ruby_vm_global_method_state, align 8, !tbaa !22
  %5 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 1
  %6 = load i64, i64* %5, align 8, !tbaa !23
  %7 = icmp eq i64 %4, %6
  br i1 %7, label %8, label %updateIC, !prof !58

8:                                                ; preds = %functionEntryInitializers
  %9 = and i64 %2, 7
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %23, label %11

11:                                               ; preds = %8
  %12 = trunc i64 %2 to i32
  %13 = and i32 %12, 1
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %15, label %sorbet_isInlineCacheValid.exit

15:                                               ; preds = %11
  %16 = and i32 %12, 3
  %17 = icmp eq i32 %16, 2
  br i1 %17, label %sorbet_isInlineCacheValid.exit, label %18

18:                                               ; preds = %15
  %19 = icmp eq i64 %2, 20
  br i1 %19, label %sorbet_isInlineCacheValid.exit, label %20

20:                                               ; preds = %18
  %21 = and i64 %2, 255
  %22 = icmp eq i64 %21, 12
  br i1 %22, label %sorbet_isInlineCacheValid.exit, label %28

23:                                               ; preds = %8
  %24 = and i64 %2, -9
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %26, label %28

26:                                               ; preds = %23
  switch i64 %2, label %28 [
    i64 8, label %sorbet_isInlineCacheValid.exit
    i64 0, label %27
  ]

27:                                               ; preds = %26
  br label %sorbet_isInlineCacheValid.exit

28:                                               ; preds = %26, %23, %20
  %29 = inttoptr i64 %2 to %struct.RBasic*
  %30 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %29, i64 0, i32 1
  %phitmp.i.i = bitcast i64* %30 to %struct.RClass**
  br label %sorbet_isInlineCacheValid.exit

sorbet_isInlineCacheValid.exit:                   ; preds = %11, %15, %18, %20, %26, %27, %28
  %31 = phi %struct.RClass** [ %phitmp.i.i, %28 ], [ bitcast (i64* @rb_cFalseClass to %struct.RClass**), %27 ], [ bitcast (i64* @rb_cInteger to %struct.RClass**), %11 ], [ bitcast (i64* @rb_cFloat to %struct.RClass**), %15 ], [ bitcast (i64* @rb_cTrueClass to %struct.RClass**), %18 ], [ bitcast (i64* @rb_cSymbol to %struct.RClass**), %20 ], [ bitcast (i64* @rb_cNilClass to %struct.RClass**), %26 ]
  %32 = load %struct.RClass*, %struct.RClass** %31, align 8, !tbaa !9
  %33 = getelementptr inbounds %struct.RClass, %struct.RClass* %32, i64 0, i32 2
  %34 = load %struct.rb_classext_struct*, %struct.rb_classext_struct** %33, align 8, !tbaa !24
  %35 = getelementptr inbounds %struct.rb_classext_struct, %struct.rb_classext_struct* %34, i64 0, i32 7
  %36 = load i64, i64* %35, align 8, !tbaa !26
  %37 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 2
  %38 = load i64, i64* %37, align 8, !tbaa !28
  %39 = icmp eq i64 %36, %38
  br i1 %39, label %call, label %updateIC, !prof !57

updateIC:                                         ; preds = %functionEntryInitializers, %sorbet_isInlineCacheValid.exit
  tail call fastcc void @sorbet_inlineCacheInvalidated(i64 %2, %struct.FunctionInlineCache* nonnull %3, i64 %rubyId_to_proc)
  br label %call

call:                                             ; preds = %updateIC, %sorbet_isInlineCacheValid.exit
  %40 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !11, !noalias !77
  %41 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 0
  %42 = load %struct.rb_callable_method_entry_struct*, %struct.rb_callable_method_entry_struct** %41, align 8, !tbaa !19, !noalias !77
  %43 = tail call i64 @rb_vm_call(%struct.rb_execution_context_struct* %40, i64 %2, i64 %rubyId_to_proc, i32 %0, i64* %1, %struct.rb_callable_method_entry_struct* %42) #18
  ret i64 %43
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_to_proc() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_to_proc, i64 0, i64 0), i64 7) #18
  store i64 %0, i64* @rubyIdPrecomputed_to_proc, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_Object#baz"() #11 {
sorbet_allocateRubyStackFrames.exit:
  %rubyStr_baz = load i64, i64* @rubyStrFrozen_baz, align 8
  %"rubyStr_test/testdata/compiler/method_with_block.rb" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/method_with_block.rb", align 8
  %0 = tail call %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct* null, i64 %rubyStr_baz, i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", i64 %"rubyStr_test/testdata/compiler/method_with_block.rb", %struct.rb_iseq_struct* null, i32 1) #18
  %1 = ptrtoint %struct.rb_iseq_struct* %0 to i64
  tail call void @rb_gc_register_mark_object(i64 %1) #18
  %2 = tail call i8* @ruby_xmalloc2(i64 3, i64 8) #18
  %3 = tail call i8* @ruby_xmalloc2(i64 3, i64 4) #18
  %4 = bitcast i8* %3 to i32*
  store i32 0, i32* %4, align 4, !tbaa !0
  %5 = bitcast i8* %2 to i32*
  store i32 17, i32* %5, align 4, !tbaa !36
  %6 = getelementptr inbounds i8, i8* %3, i64 4
  %7 = bitcast i8* %6 to i32*
  store i32 1, i32* %7, align 4, !tbaa !0
  %8 = getelementptr inbounds i8, i8* %2, i64 8
  %9 = bitcast i8* %8 to i32*
  store i32 18, i32* %9, align 4, !tbaa !36
  %10 = getelementptr inbounds i8, i8* %3, i64 8
  %11 = bitcast i8* %10 to i32*
  store i32 2, i32* %11, align 4, !tbaa !0
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to i32*
  store i32 19, i32* %13, align 4, !tbaa !36
  %14 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %0, i64 0, i32 2
  %15 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %16 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 0
  %17 = bitcast %struct.rb_code_position_struct** %16 to i8**
  store i8* %2, i8** %17, align 8, !tbaa !44
  %18 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 1
  %19 = bitcast i32** %18 to i8**
  store i8* %3, i8** %19, align 8, !tbaa !53
  %20 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 1
  store i32 3, i32* %20, align 4, !tbaa !54
  %21 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %15, i64 0, i32 5, i32 2
  store i32 3, i32* %21, align 8, !tbaa !55
  tail call void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct* %0) #18
  %22 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %14, align 8, !tbaa !42
  %23 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %22, i64 0, i32 2
  store i64* null, i64** %23, align 8, !tbaa !56
  store %struct.rb_iseq_struct* %0, %struct.rb_iseq_struct** bitcast (i8** @"stackFramePrecomputed_func_Object#baz" to %struct.rb_iseq_struct**), align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyStrFrozen_baz() #11 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_baz, i64 0, i64 0), i64 3) #18
  tail call void @rb_gc_register_mark_object(i64 %0) #18
  store i64 %0, i64* @rubyStrFrozen_baz, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #15

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #15

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @"func_Object#bar.cold.1"(i64 %selfRaw) unnamed_addr #16 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq
define internal fastcc void @Init_test_testdata_compiler_method_with_block.cold.1(i64) unnamed_addr #17 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %0, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(<root>)", i64 0, i64 0)) #18
  unreachable
}

; Function Attrs: nounwind
declare void @llvm.assume(i1) #18

; Function Attrs: ssp
define linkonce void @"const_recompute_Sorbet::Private::Static"() local_unnamed_addr #10 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @"str_Sorbet::Private::Static", i64 0, i64 0), i64 23)
  store i64 %1, i64* @"guarded_const_Sorbet::Private::Static", align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !22
  store i64 %2, i64* @"guard_epoch_Sorbet::Private::Static", align 8
  ret void
}

attributes #0 = { "addedToSilenceEmptyAttrsError" }
attributes #1 = { nounwind ssp uwtable }
attributes #2 = { norecurse nounwind readnone ssp uwtable }
attributes #3 = { noinline nounwind ssp uwtable }
attributes #4 = { argmemonly nofree nounwind readonly }
attributes #5 = { noreturn }
attributes #6 = { nounwind readnone }
attributes #7 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #8 = { noreturn nounwind ssp uwtable }
attributes #9 = { nofree norecurse nounwind ssp uwtable }
attributes #10 = { ssp }
attributes #11 = { nounwind ssp }
attributes #12 = { nounwind sspreq uwtable }
attributes #13 = { noinline ssp }
attributes #14 = { nounwind sspreq }
attributes #15 = { argmemonly nounwind }
attributes #16 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #17 = { cold minsize noreturn nounwind sspreq }
attributes #18 = { nounwind }
attributes #19 = { nounwind readonly }
attributes #20 = { noreturn nounwind }
attributes #21 = { noinline }

!0 = !{!1, !1, i64 0}
!1 = !{!"int", !2, i64 0}
!2 = !{!"omnipotent char", !3, i64 0}
!3 = !{!"Simple C/C++ TBAA"}
!4 = !{!5, !6, i64 0}
!5 = !{!"RBasic", !6, i64 0, !6, i64 8}
!6 = !{!"long", !2, i64 0}
!7 = !{!2, !2, i64 0}
!8 = !{i32 1216}
!9 = !{!6, !6, i64 0}
!10 = !{!5, !6, i64 8}
!11 = !{!12, !12, i64 0}
!12 = !{!"any pointer", !2, i64 0}
!13 = !{!14, !12, i64 16}
!14 = !{!"rb_execution_context_struct", !12, i64 0, !6, i64 8, !12, i64 16, !12, i64 24, !12, i64 32, !1, i64 40, !1, i64 44, !12, i64 48, !12, i64 56, !12, i64 64, !6, i64 72, !6, i64 80, !12, i64 88, !6, i64 96, !12, i64 104, !12, i64 112, !6, i64 120, !6, i64 128, !2, i64 136, !2, i64 137, !6, i64 144, !15, i64 152}
!15 = !{!"", !12, i64 0, !12, i64 8, !6, i64 16, !2, i64 24}
!16 = !{!17, !12, i64 16}
!17 = !{!"rb_control_frame_struct", !12, i64 0, !12, i64 8, !12, i64 16, !6, i64 24, !12, i64 32, !12, i64 40, !12, i64 48}
!18 = !{!17, !12, i64 32}
!19 = !{!20, !12, i64 0}
!20 = !{!"FunctionInlineCache", !12, i64 0, !21, i64 8, !21, i64 16}
!21 = !{!"long long", !2, i64 0}
!22 = !{!21, !21, i64 0}
!23 = !{!20, !21, i64 8}
!24 = !{!25, !12, i64 24}
!25 = !{!"RClass", !5, i64 0, !6, i64 16, !12, i64 24, !12, i64 32}
!26 = !{!27, !21, i64 56}
!27 = !{!"rb_classext_struct", !12, i64 0, !12, i64 8, !12, i64 16, !12, i64 24, !12, i64 32, !12, i64 40, !12, i64 48, !21, i64 56, !6, i64 64, !6, i64 72, !12, i64 80}
!28 = !{!20, !21, i64 16}
!29 = !{!30, !12, i64 32}
!30 = !{!"RTypedData", !5, i64 0, !12, i64 16, !6, i64 24, !12, i64 32}
!31 = !{!32}
!32 = distinct !{!32, !33}
!33 = distinct !{!33, !"LVerDomain"}
!34 = !{!35}
!35 = distinct !{!35, !33}
!36 = !{!37, !1, i64 0}
!37 = !{!"iseq_insn_info_entry", !1, i64 0, !1, i64 4}
!38 = distinct !{!38, !39}
!39 = !{!"llvm.loop.unroll.disable"}
!40 = distinct !{!40, !41}
!41 = !{!"llvm.loop.isvectorized", i32 1}
!42 = !{!43, !12, i64 16}
!43 = !{!"rb_iseq_struct", !6, i64 0, !6, i64 8, !12, i64 16, !2, i64 24}
!44 = !{!45, !12, i64 120}
!45 = !{!"rb_iseq_constant_body", !2, i64 0, !1, i64 4, !12, i64 8, !46, i64 16, !48, i64 64, !51, i64 120, !12, i64 152, !12, i64 160, !12, i64 168, !12, i64 176, !12, i64 184, !12, i64 192, !12, i64 200, !52, i64 208, !1, i64 240, !1, i64 244, !1, i64 248, !1, i64 252, !1, i64 256, !12, i64 264, !6, i64 272, !12, i64 280, !2, i64 288}
!46 = !{!"", !47, i64 0, !1, i64 4, !1, i64 8, !1, i64 12, !1, i64 16, !1, i64 20, !1, i64 24, !1, i64 28, !12, i64 32, !12, i64 40}
!47 = !{!"", !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0}
!48 = !{!"rb_iseq_location_struct", !6, i64 0, !6, i64 8, !6, i64 16, !6, i64 24, !1, i64 32, !49, i64 36}
!49 = !{!"rb_code_location_struct", !50, i64 0, !50, i64 8}
!50 = !{!"rb_code_position_struct", !1, i64 0, !1, i64 4}
!51 = !{!"iseq_insn_info", !12, i64 0, !12, i64 8, !1, i64 16, !12, i64 24}
!52 = !{!"", !6, i64 0, !6, i64 8, !6, i64 16, !12, i64 24}
!53 = !{!45, !12, i64 128}
!54 = !{!45, !1, i64 4}
!55 = !{!45, !1, i64 136}
!56 = !{!45, !12, i64 8}
!57 = !{!"branch_weights", i32 2000, i32 1}
!58 = !{!"branch_weights", i32 2146410443, i32 1073205}
!59 = !{!60}
!60 = distinct !{!60, !61, !"sorbet_callFunc: argument 0"}
!61 = distinct !{!61, !"sorbet_callFunc"}
!62 = !{!63}
!63 = distinct !{!63, !64, !"sorbet_callFunc: argument 0"}
!64 = distinct !{!64, !"sorbet_callFunc"}
!65 = !{!66, !6, i64 400}
!66 = !{!"rb_vm_struct", !6, i64 0, !67, i64 8, !12, i64 192, !12, i64 200, !12, i64 208, !21, i64 216, !2, i64 224, !68, i64 264, !68, i64 280, !68, i64 296, !68, i64 312, !6, i64 328, !1, i64 336, !1, i64 340, !1, i64 340, !1, i64 340, !1, i64 340, !1, i64 344, !6, i64 352, !2, i64 360, !6, i64 400, !6, i64 408, !6, i64 416, !6, i64 424, !6, i64 432, !6, i64 440, !6, i64 448, !12, i64 456, !12, i64 464, !70, i64 472, !71, i64 1064, !12, i64 1088, !12, i64 1096, !1, i64 1104, !1, i64 1108, !68, i64 1112, !2, i64 1128, !6, i64 1168, !6, i64 1176, !6, i64 1184, !6, i64 1192, !6, i64 1200, !1, i64 1208, !6, i64 1216, !12, i64 1224, !12, i64 1232, !12, i64 1240, !12, i64 1248, !72, i64 1256, !2, i64 1288}
!67 = !{!"rb_global_vm_lock_struct", !12, i64 0, !2, i64 8, !68, i64 48, !12, i64 64, !1, i64 72, !2, i64 80, !2, i64 128, !1, i64 176, !1, i64 180}
!68 = !{!"list_head", !69, i64 0}
!69 = !{!"list_node", !12, i64 0, !12, i64 8}
!70 = !{!"", !2, i64 0, !2, i64 520}
!71 = !{!"rb_hook_list_struct", !12, i64 0, !1, i64 8, !1, i64 12, !1, i64 16}
!72 = !{!"", !6, i64 0, !6, i64 8, !6, i64 16, !6, i64 24}
!73 = !{!"branch_weights", i32 10000, i32 1}
!74 = !{!75}
!75 = distinct !{!75, !76, !"sorbet_callFunc: argument 0"}
!76 = distinct !{!76, !"sorbet_callFunc"}
!77 = !{!78}
!78 = distinct !{!78, !79, !"sorbet_callFunc: argument 0"}
!79 = distinct !{!79, !"sorbet_callFunc"}
