; ModuleID = 'payload'
source_filename = "llvm-link"
target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.19, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.19 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.rb_vm_struct = type { i64, %struct.rb_global_vm_lock_struct, %struct.rb_thread_struct*, %struct.rb_thread_struct*, i8*, i64, %struct._opaque_pthread_mutex_t, %union.anon.12, %union.anon.12, %union.anon.12, %union.anon.12, i64, i32, i8, i32, i64, [5 x i64], i64, i64, i64, i64, i64, i64, i64, %struct.st_table*, %struct.st_table*, %struct.anon.17, %struct.rb_hook_list_struct, %struct.st_table*, %struct.rb_postponed_job_struct*, i32, i32, %union.anon.12, %struct._opaque_pthread_mutex_t, i64, i64, i64, i64, i64, i32, i64, %struct.rb_objspace*, %struct.rb_at_exit_list*, i64*, %struct.st_table*, %struct.anon.18, [28 x i16] }
%struct.rb_global_vm_lock_struct = type { %struct.rb_thread_struct*, %struct._opaque_pthread_mutex_t, %union.anon.12, %struct.rb_thread_struct*, i32, %struct._opaque_pthread_cond_t, %struct._opaque_pthread_cond_t, i32, i32 }
%struct._opaque_pthread_cond_t = type { i64, [40 x i8] }
%struct.rb_thread_struct = type { %struct.list_node, i64, %struct.rb_vm_struct*, %struct.rb_execution_context_struct*, i64, %struct.rb_calling_info*, i64, i64, %struct._opaque_pthread_t*, i8, i8, i32, %struct.native_thread_data_struct, i8*, i64, i64, i64, i64, %struct._opaque_pthread_mutex_t, %struct.rb_unblock_callback, i64, %struct.rb_mutex_struct*, %struct.rb_thread_list_struct*, %union.anon.14, i32, i64, %struct.rb_fiber_struct*, [38 x i32], i64 }
%struct.list_node = type { %struct.list_node*, %struct.list_node* }
%struct.rb_execution_context_struct = type { i64*, i64, %struct.rb_control_frame_struct*, %struct.rb_vm_tag*, %struct.rb_vm_protect_tag*, i32, i32, %struct.rb_fiber_struct*, %struct.rb_thread_struct*, %struct.st_table*, i64, i64, i64*, i64, %struct.rb_ensure_list*, %struct.rb_trace_arg_struct*, i64, i64, i8, i8, i64, %struct.anon.11 }
%struct.rb_control_frame_struct = type { i64*, i64*, %struct.rb_iseq_struct*, i64, i64*, i8*, i64* }
%struct.rb_iseq_struct = type { i64, i64, %struct.rb_iseq_constant_body*, %union.anon.8 }
%struct.rb_iseq_constant_body = type { i32, i32, i64*, %struct.anon.1, %struct.rb_iseq_location_struct, %struct.iseq_insn_info, i64*, %struct.iseq_catch_table*, %struct.rb_iseq_struct*, %struct.rb_iseq_struct*, %union.iseq_inline_storage_entry*, %struct.rb_call_info*, %struct.rb_call_cache*, %struct.anon.7, i32, i32, i32, i32, i32, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*)*, i64, %struct.rb_mjit_unit*, i8 }
%struct.anon.1 = type { %struct.anon.2, i32, i32, i32, i32, i32, i32, i32, i64*, %struct.rb_iseq_param_keyword* }
%struct.anon.2 = type { i8, [3 x i8] }
%struct.rb_iseq_param_keyword = type { i32, i32, i32, i32, i64*, i64* }
%struct.rb_iseq_location_struct = type { i64, i64, i64, i64, i32, %struct.rb_code_location_struct }
%struct.rb_code_location_struct = type { %struct.rb_code_position_struct, %struct.rb_code_position_struct }
%struct.rb_code_position_struct = type { i32, i32 }
%struct.iseq_insn_info = type { %struct.rb_code_position_struct*, i32*, i32, %struct.succ_index_table* }
%struct.succ_index_table = type opaque
%struct.iseq_catch_table = type opaque
%union.iseq_inline_storage_entry = type { %struct.iseq_inline_cache_entry }
%struct.iseq_inline_cache_entry = type { i64, %struct.rb_cref_struct*, %union.anon.0 }
%struct.rb_cref_struct = type { i64, i64, i64, %struct.rb_cref_struct*, %struct.anon.2 }
%union.anon.0 = type { i64 }
%struct.rb_call_info = type { i64, i32, i32 }
%struct.rb_call_cache = type { i64, i64, %struct.rb_callable_method_entry_struct*, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, %struct.rb_calling_info*, %struct.rb_call_info*, %struct.rb_call_cache*)*, %union.anon.6 }
%struct.rb_callable_method_entry_struct = type { i64, i64, %struct.rb_method_definition_struct*, i64, i64 }
%struct.rb_method_definition_struct = type { i64, %union.anon.5, i64 }
%union.anon.5 = type { %struct.rb_method_cfunc_struct }
%struct.rb_method_cfunc_struct = type { i64 (...)*, i64 (i64 (...)*, i64, i32, i64*)*, i32 }
%union.anon.6 = type { i32 }
%struct.anon.7 = type { i64, i64, i64, i64* }
%struct.rb_mjit_unit = type opaque
%union.anon.8 = type { %struct.anon.9 }
%struct.anon.9 = type { i64, i32 }
%struct.rb_vm_tag = type { i64, i64, [38 x i32], %struct.rb_vm_tag*, i32 }
%struct.rb_vm_protect_tag = type { %struct.rb_vm_protect_tag* }
%struct.rb_ensure_list = type { %struct.rb_ensure_list*, %struct.rb_ensure_entry }
%struct.rb_ensure_entry = type { i64, i64 (...)*, i64 }
%struct.rb_trace_arg_struct = type { i32, %struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, i64, i64, i64, i64, i64, i32, i32, i64 }
%struct.anon.11 = type { i64*, i64*, i64, [37 x i32] }
%struct.rb_calling_info = type { i64, i64, i32 }
%struct._opaque_pthread_t = type { i64, %struct.__darwin_pthread_handler_rec*, [8176 x i8] }
%struct.__darwin_pthread_handler_rec = type { void (i8*)*, i8*, %struct.__darwin_pthread_handler_rec* }
%struct.native_thread_data_struct = type { %union.anon.12, %struct.anon.13 }
%struct.anon.13 = type { %struct._opaque_pthread_cond_t, %struct._opaque_pthread_cond_t }
%struct.rb_unblock_callback = type { void (i8*)*, i8* }
%struct.rb_mutex_struct = type opaque
%struct.rb_thread_list_struct = type { %struct.rb_thread_list_struct*, %struct.rb_thread_struct* }
%union.anon.14 = type { %struct.RBasic }
%struct.RBasic = type { i64, i64 }
%struct.rb_fiber_struct = type opaque
%struct.anon.17 = type { [32 x i64], [32 x i8] }
%struct.rb_hook_list_struct = type { %struct.rb_event_hook_struct*, i32, i32, i32 }
%struct.rb_event_hook_struct = type opaque
%struct.rb_postponed_job_struct = type opaque
%union.anon.12 = type { %struct.list_node }
%struct._opaque_pthread_mutex_t = type { i64, [56 x i8] }
%struct.rb_objspace = type opaque
%struct.rb_at_exit_list = type { void (%struct.rb_vm_struct*)*, %struct.rb_at_exit_list* }
%struct.st_table = type { i8, i8, i8, i32, %struct.st_hash_type*, i64, i64*, i64, i64, %struct.st_table_entry* }
%struct.st_hash_type = type { i32 (...)*, i64 (...)* }
%struct.st_table_entry = type opaque
%struct.anon.18 = type { i64, i64, i64, i64 }
%struct.FunctionInlineCache = type { %struct.rb_callable_method_entry_struct*, i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%struct.rb_ast_body_struct = type { %struct.RNode*, i64, i32 }
%struct.RNode = type { i64, %union.anon.20, %union.anon.20, %union.anon.20, %struct.rb_code_location_struct, i32 }
%union.anon.20 = type { %struct.RNode* }
%struct.RArray = type { %struct.RBasic, %union.anon.26 }
%union.anon.26 = type { %struct.anon.27 }
%struct.anon.27 = type { i64, %union.anon.0, i64* }
%struct.RClass = type { %struct.RBasic, i64, %struct.rb_classext_struct*, %struct.rb_id_table* }
%struct.rb_classext_struct = type { %struct.st_table*, %struct.st_table*, %struct.rb_id_table*, %struct.rb_id_table*, %struct.rb_subclass_entry*, %struct.rb_subclass_entry**, %struct.rb_subclass_entry**, i64, i64, i64, i64 (i64)* }
%struct.rb_subclass_entry = type { i64, %struct.rb_subclass_entry* }
%struct.rb_id_table = type opaque

@closureInfo = local_unnamed_addr constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.10, i32 0, i32 0), %struct.anon.19 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@.str.10 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@ruby_current_vm_ptr = external local_unnamed_addr global %struct.rb_vm_struct*, align 8
@rb_cFalseClass = external local_unnamed_addr constant i64, align 8
@rb_cInteger = external local_unnamed_addr constant i64, align 8
@rb_cFloat = external local_unnamed_addr constant i64, align 8
@rb_cTrueClass = external local_unnamed_addr constant i64, align 8
@rb_cSymbol = external local_unnamed_addr constant i64, align 8
@rb_cNilClass = external local_unnamed_addr constant i64, align 8
@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@ruby_current_execution_context_ptr = external local_unnamed_addr global %struct.rb_execution_context_struct*, align 8
@.str.8 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@ruby_vm_global_method_state = external local_unnamed_addr global i64, align 8
@.str.13 = private unnamed_addr constant [40 x i8] c"unimplmented call with a missing method\00", align 1
@"stackFramePrecomputed_func_<root>.<static-init>$114" = internal unnamed_addr global i8* null, align 8
@"rubyIdPrecomputed_<top (required)>" = internal unnamed_addr global i64 0, align 8
@"str_<top (required)>" = private unnamed_addr constant [17 x i8] c"<top (required)>\00", align 1
@"rubyStrFrozen_<top (required)>" = internal unnamed_addr global i64 0, align 8
@"rubyStrFrozen_test/testdata/compiler/splat.rb" = internal unnamed_addr global i64 0, align 8
@"str_test/testdata/compiler/splat.rb" = private unnamed_addr constant [32 x i8] c"test/testdata/compiler/splat.rb\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@"str_T.class_of(<root>)" = private unnamed_addr constant [19 x i8] c"T.class_of(<root>)\00", align 1
@"rubyIdPrecomputed_<build-array>" = internal unnamed_addr global i64 0, align 8
@"str_<build-array>" = private unnamed_addr constant [14 x i8] c"<build-array>\00", align 1
@"rubyIdPrecomputed_<expand-splat>" = internal unnamed_addr global i64 0, align 8
@"str_<expand-splat>" = private unnamed_addr constant [15 x i8] c"<expand-splat>\00", align 1
@"rubyIdPrecomputed_[]" = internal unnamed_addr global i64 0, align 8
@"str_[]" = private unnamed_addr constant [3 x i8] c"[]\00", align 1
@"ic_call_via_vm_[]" = internal global %struct.FunctionInlineCache zeroinitializer
@"ic_call_via_vm_[].1" = internal global %struct.FunctionInlineCache zeroinitializer
@"ic_call_via_vm_[].2" = internal global %struct.FunctionInlineCache zeroinitializer
@ic_call_via_vm_puts = internal global %struct.FunctionInlineCache zeroinitializer
@rubyIdPrecomputed_puts = internal unnamed_addr global i64 0, align 8
@str_puts = private unnamed_addr constant [5 x i8] c"puts\00", align 1
@llvm.global_ctors = appending global [8 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<top (required)>", i8* bitcast (i64* @"rubyIdPrecomputed_<top (required)>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyStrFrozen_<top (required)>", i8* bitcast (i64* @"rubyStrFrozen_<top (required)>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyStrFrozen_test/testdata/compiler/splat.rb", i8* bitcast (i64* @"rubyStrFrozen_test/testdata/compiler/splat.rb" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_stackFramePrecomputed_func_<root>.<static-init>$114", i8* bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$114" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<build-array>", i8* bitcast (i64* @"rubyIdPrecomputed_<build-array>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<expand-splat>", i8* bitcast (i64* @"rubyIdPrecomputed_<expand-splat>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_[]", i8* bitcast (i64* @"rubyIdPrecomputed_[]" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_puts, i8* bitcast (i64* @rubyIdPrecomputed_puts to i8*) }]
@"ic_call_via_vm_[].3" = internal global %struct.FunctionInlineCache zeroinitializer
@"ic_call_via_vm_[].4" = internal global %struct.FunctionInlineCache zeroinitializer
@"ic_call_via_vm_[].5" = internal global %struct.FunctionInlineCache zeroinitializer
@ic_call_via_vm_puts.6 = internal global %struct.FunctionInlineCache zeroinitializer
@"ic_call_via_vm_[].7" = internal global %struct.FunctionInlineCache zeroinitializer
@"ic_call_via_vm_[].8" = internal global %struct.FunctionInlineCache zeroinitializer
@"ic_call_via_vm_[].9" = internal global %struct.FunctionInlineCache zeroinitializer
@ic_call_via_vm_puts.10 = internal global %struct.FunctionInlineCache zeroinitializer

declare i64 @rb_ary_push(i64, i64) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8*) #1 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !0
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #10
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly) #2 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !0
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64) local_unnamed_addr #1 {
  %2 = tail call i8* @rb_id2name(i64 %0) #10
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64) local_unnamed_addr #1 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #10
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !4
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #10
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !7
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #0

; Function Attrs: nounwind ssp uwtable
define void @stopInDebugger() local_unnamed_addr #1 {
  tail call void asm sideeffect "int $$3", "~{dirflag},~{fpsr},~{flags}"() #10, !srcloc !8
  ret void
}

declare i64 @rb_fstring_new(i8*, i64) local_unnamed_addr #0

declare void @rb_gc_register_mark_object(i64) local_unnamed_addr #0

declare i64 @rb_ary_new_from_values(i64, i64*) local_unnamed_addr #0

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #0

declare i8* @rb_obj_classname(i64) local_unnamed_addr #0

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #3

declare %struct.rb_callable_method_entry_struct* @rb_callable_method_entry(i64, i64) local_unnamed_addr #0

declare i64 @rb_vm_call(%struct.rb_execution_context_struct*, i64, i64, i32, i64*, %struct.rb_callable_method_entry_struct*) local_unnamed_addr #0

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64) unnamed_addr #4 {
  %2 = load i64, i64* @rb_eTypeError, align 8, !tbaa !9
  %3 = tail call i8* @rb_obj_classname(i64 %0) #10
  tail call void (i64, i8*, ...) @rb_raise(i64 %2, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.8, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(<root>)", i64 0, i64 0), i8* %3, i64 %0) #11
  unreachable
}

declare %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct*, i64, i64, i64, %struct.rb_iseq_struct*, i32) local_unnamed_addr #0

declare i8** @rb_vm_get_insns_address_table() local_unnamed_addr #0

declare i8* @ruby_xmalloc2(i64, i64) local_unnamed_addr #0

declare void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct*) local_unnamed_addr #0

; Function Attrs: nofree norecurse nounwind ssp uwtable
define i64** @sorbet_setRubyStackFrame(i8*) local_unnamed_addr #5 {
  %2 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !10
  %3 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %2, i64 0, i32 2
  %4 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %3, align 8, !tbaa !12
  %5 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 2
  %6 = bitcast %struct.rb_iseq_struct** %5 to i8**
  store i8* %0, i8** %6, align 8, !tbaa !15
  %7 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 4
  %8 = load i64*, i64** %7, align 8, !tbaa !17
  %9 = load i64, i64* %8, align 8, !tbaa !9
  %10 = and i64 %9, -129
  store i64 %10, i64* %8, align 8, !tbaa !9
  %11 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %4, i64 0, i32 0
  ret i64** %11
}

declare i64 @rb_ary_new() local_unnamed_addr #0

declare i64 @rb_ary_dup(i64) local_unnamed_addr #0

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #6

declare i64 @rb_ary_entry(i64, i64) local_unnamed_addr #0

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #6

; Function Attrs: norecurse nounwind readonly ssp uwtable
define i64 @enumerator_size_func_array_length(i64, i64, i64) local_unnamed_addr #7 {
  %4 = inttoptr i64 %0 to %struct.RBasic*
  %5 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %4, i64 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !4
  %7 = and i64 %6, 8192
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %12, label %9

9:                                                ; preds = %3
  %10 = lshr i64 %6, 15
  %11 = and i64 %10, 3
  br label %rb_array_len.exit

12:                                               ; preds = %3
  %13 = inttoptr i64 %0 to %struct.RArray*
  %14 = getelementptr inbounds %struct.RArray, %struct.RArray* %13, i64 0, i32 1, i32 0, i32 0
  %15 = load i64, i64* %14, align 8, !tbaa !7
  br label %rb_array_len.exit

rb_array_len.exit:                                ; preds = %9, %12
  %16 = phi i64 [ %11, %9 ], [ %15, %12 ]
  ret i64 %16
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_callFunc(i64, i64, i64* noalias nocapture, %struct.FunctionInlineCache* nocapture) unnamed_addr #1 {
  %5 = load i64, i64* @ruby_vm_global_method_state, align 8, !tbaa !18
  %6 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 1
  %7 = load i64, i64* %6, align 8, !tbaa !20
  %8 = icmp eq i64 %5, %7
  br i1 %8, label %9, label %41, !prof !22

9:                                                ; preds = %4
  %10 = and i64 %0, 7
  %11 = icmp eq i64 %10, 0
  br i1 %11, label %24, label %12

12:                                               ; preds = %9
  %13 = trunc i64 %0 to i32
  %14 = and i32 %13, 1
  %15 = icmp eq i32 %14, 0
  br i1 %15, label %16, label %sorbet_getClassSerial.exit

16:                                               ; preds = %12
  %17 = and i32 %13, 3
  %18 = icmp eq i32 %17, 2
  br i1 %18, label %sorbet_getClassSerial.exit, label %19

19:                                               ; preds = %16
  %20 = icmp eq i64 %0, 20
  br i1 %20, label %sorbet_getClassSerial.exit, label %21

21:                                               ; preds = %19
  %22 = and i64 %0, 255
  %23 = icmp eq i64 %22, 12
  br i1 %23, label %sorbet_getClassSerial.exit, label %29

24:                                               ; preds = %9
  %25 = and i64 %0, -9
  %26 = icmp eq i64 %25, 0
  br i1 %26, label %27, label %29

27:                                               ; preds = %24
  switch i64 %0, label %29 [
    i64 8, label %sorbet_getClassSerial.exit
    i64 0, label %28
  ]

28:                                               ; preds = %27
  br label %sorbet_getClassSerial.exit

29:                                               ; preds = %27, %24, %21
  %30 = inttoptr i64 %0 to %struct.RBasic*
  %31 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %30, i64 0, i32 1
  %phitmp.i = bitcast i64* %31 to %struct.RClass**
  br label %sorbet_getClassSerial.exit

sorbet_getClassSerial.exit:                       ; preds = %12, %16, %19, %21, %27, %28, %29
  %32 = phi %struct.RClass** [ %phitmp.i, %29 ], [ bitcast (i64* @rb_cFalseClass to %struct.RClass**), %28 ], [ bitcast (i64* @rb_cInteger to %struct.RClass**), %12 ], [ bitcast (i64* @rb_cFloat to %struct.RClass**), %16 ], [ bitcast (i64* @rb_cTrueClass to %struct.RClass**), %19 ], [ bitcast (i64* @rb_cSymbol to %struct.RClass**), %21 ], [ bitcast (i64* @rb_cNilClass to %struct.RClass**), %27 ]
  %33 = load %struct.RClass*, %struct.RClass** %32, align 8, !tbaa !9
  %34 = getelementptr inbounds %struct.RClass, %struct.RClass* %33, i64 0, i32 2
  %35 = load %struct.rb_classext_struct*, %struct.rb_classext_struct** %34, align 8, !tbaa !23
  %36 = getelementptr inbounds %struct.rb_classext_struct, %struct.rb_classext_struct* %35, i64 0, i32 7
  %37 = load i64, i64* %36, align 8, !tbaa !25
  %38 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 2
  %39 = load i64, i64* %38, align 8, !tbaa !27
  %40 = icmp eq i64 %37, %39
  br i1 %40, label %100, label %41, !prof !22

41:                                               ; preds = %sorbet_getClassSerial.exit, %4
  %42 = and i64 %0, 7
  %43 = icmp eq i64 %42, 0
  br i1 %43, label %56, label %44

44:                                               ; preds = %41
  %45 = trunc i64 %0 to i32
  %46 = and i32 %45, 1
  %47 = icmp eq i32 %46, 0
  br i1 %47, label %48, label %rb_class_of.exit.i

48:                                               ; preds = %44
  %49 = and i32 %45, 3
  %50 = icmp eq i32 %49, 2
  br i1 %50, label %rb_class_of.exit.i, label %51

51:                                               ; preds = %48
  %52 = icmp eq i64 %0, 20
  br i1 %52, label %rb_class_of.exit.i, label %53

53:                                               ; preds = %51
  %54 = and i64 %0, 255
  %55 = icmp eq i64 %54, 12
  br i1 %55, label %rb_class_of.exit.i, label %61

56:                                               ; preds = %41
  %57 = and i64 %0, -9
  %58 = icmp eq i64 %57, 0
  br i1 %58, label %59, label %61

59:                                               ; preds = %56
  switch i64 %0, label %61 [
    i64 8, label %rb_class_of.exit.i
    i64 0, label %60
  ]

60:                                               ; preds = %59
  br label %rb_class_of.exit.i

61:                                               ; preds = %59, %56, %53
  %62 = inttoptr i64 %0 to %struct.RBasic*
  %63 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %62, i64 0, i32 1
  br label %rb_class_of.exit.i

rb_class_of.exit.i:                               ; preds = %61, %60, %59, %53, %51, %48, %44
  %64 = phi i64* [ %63, %61 ], [ @rb_cFalseClass, %60 ], [ @rb_cInteger, %44 ], [ @rb_cFloat, %48 ], [ @rb_cTrueClass, %51 ], [ @rb_cSymbol, %53 ], [ @rb_cNilClass, %59 ]
  %65 = load i64, i64* %64, align 8, !tbaa !9
  %66 = tail call %struct.rb_callable_method_entry_struct* @rb_callable_method_entry(i64 %65, i64 %1) #10
  %67 = icmp eq %struct.rb_callable_method_entry_struct* %66, null
  br i1 %67, label %68, label %70

68:                                               ; preds = %rb_class_of.exit.i
  %69 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !9
  tail call void (i64, i8*, ...) @rb_raise(i64 %69, i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.13, i64 0, i64 0)) #11
  unreachable

70:                                               ; preds = %rb_class_of.exit.i
  %71 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 0
  store %struct.rb_callable_method_entry_struct* %66, %struct.rb_callable_method_entry_struct** %71, align 8, !tbaa !28
  %72 = load i64, i64* @ruby_vm_global_method_state, align 8, !tbaa !18
  store i64 %72, i64* %6, align 8, !tbaa !20
  br i1 %43, label %85, label %73

73:                                               ; preds = %70
  %74 = trunc i64 %0 to i32
  %75 = and i32 %74, 1
  %76 = icmp eq i32 %75, 0
  br i1 %76, label %77, label %sorbet_inlineCacheInvalidated.exit

77:                                               ; preds = %73
  %78 = and i32 %74, 3
  %79 = icmp eq i32 %78, 2
  br i1 %79, label %sorbet_inlineCacheInvalidated.exit, label %80

80:                                               ; preds = %77
  %81 = icmp eq i64 %0, 20
  br i1 %81, label %sorbet_inlineCacheInvalidated.exit, label %82

82:                                               ; preds = %80
  %83 = and i64 %0, 255
  %84 = icmp eq i64 %83, 12
  br i1 %84, label %sorbet_inlineCacheInvalidated.exit, label %90

85:                                               ; preds = %70
  %86 = and i64 %0, -9
  %87 = icmp eq i64 %86, 0
  br i1 %87, label %88, label %90

88:                                               ; preds = %85
  switch i64 %0, label %90 [
    i64 8, label %sorbet_inlineCacheInvalidated.exit
    i64 0, label %89
  ]

89:                                               ; preds = %88
  br label %sorbet_inlineCacheInvalidated.exit

90:                                               ; preds = %88, %85, %82
  %91 = inttoptr i64 %0 to %struct.RBasic*
  %92 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %91, i64 0, i32 1
  %phitmp.i.i = bitcast i64* %92 to %struct.RClass**
  br label %sorbet_inlineCacheInvalidated.exit

sorbet_inlineCacheInvalidated.exit:               ; preds = %73, %77, %80, %82, %88, %89, %90
  %93 = phi %struct.RClass** [ %phitmp.i.i, %90 ], [ bitcast (i64* @rb_cFalseClass to %struct.RClass**), %89 ], [ bitcast (i64* @rb_cInteger to %struct.RClass**), %73 ], [ bitcast (i64* @rb_cFloat to %struct.RClass**), %77 ], [ bitcast (i64* @rb_cTrueClass to %struct.RClass**), %80 ], [ bitcast (i64* @rb_cSymbol to %struct.RClass**), %82 ], [ bitcast (i64* @rb_cNilClass to %struct.RClass**), %88 ]
  %94 = load %struct.RClass*, %struct.RClass** %93, align 8, !tbaa !9
  %95 = getelementptr inbounds %struct.RClass, %struct.RClass* %94, i64 0, i32 2
  %96 = load %struct.rb_classext_struct*, %struct.rb_classext_struct** %95, align 8, !tbaa !23
  %97 = getelementptr inbounds %struct.rb_classext_struct, %struct.rb_classext_struct* %96, i64 0, i32 7
  %98 = load i64, i64* %97, align 8, !tbaa !25
  %99 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 2
  store i64 %98, i64* %99, align 8, !tbaa !27
  br label %100

100:                                              ; preds = %sorbet_inlineCacheInvalidated.exit, %sorbet_getClassSerial.exit
  %101 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !10
  %102 = getelementptr inbounds %struct.FunctionInlineCache, %struct.FunctionInlineCache* %3, i64 0, i32 0
  %103 = load %struct.rb_callable_method_entry_struct*, %struct.rb_callable_method_entry_struct** %102, align 8, !tbaa !28
  %104 = tail call i64 @rb_vm_call(%struct.rb_execution_context_struct* %101, i64 %0, i64 %1, i32 1, i64* %2, %struct.rb_callable_method_entry_struct* %103) #10
  ret i64 %104
}

; Function Attrs: nounwind ssp
define internal void @"Constr_stackFramePrecomputed_func_<root>.<static-init>$114"() #8 {
entryInitializers:
  %"rubyStr_<top (required)>" = load i64, i64* @"rubyStrFrozen_<top (required)>", align 8
  %"rubyStr_test/testdata/compiler/splat.rb" = load i64, i64* @"rubyStrFrozen_test/testdata/compiler/splat.rb", align 8
  %0 = tail call %struct.rb_iseq_struct* @rb_iseq_new(%struct.rb_ast_body_struct* null, i64 %"rubyStr_<top (required)>", i64 %"rubyStr_test/testdata/compiler/splat.rb", i64 %"rubyStr_test/testdata/compiler/splat.rb", %struct.rb_iseq_struct* null, i32 1) #10
  %1 = ptrtoint %struct.rb_iseq_struct* %0 to i64
  tail call void @rb_gc_register_mark_object(i64 %1) #10
  %2 = tail call i8** @rb_vm_get_insns_address_table() #10
  %3 = bitcast i8** %2 to i64*
  %4 = load i64, i64* %3, align 8, !tbaa !10
  %5 = tail call i8* @ruby_xmalloc2(i64 8, i64 8) #10
  %6 = tail call i8* @ruby_xmalloc2(i64 8, i64 4) #10
  %7 = tail call i8* @ruby_xmalloc2(i64 8, i64 8) #10
  %8 = bitcast i8* %6 to i32*
  store i32 0, i32* %8, align 4, !tbaa !0
  %9 = bitcast i8* %5 to i32*
  store i32 5, i32* %9, align 4, !tbaa !29
  %10 = getelementptr inbounds i8, i8* %6, i64 4
  %11 = bitcast i8* %10 to i32*
  store i32 1, i32* %11, align 4, !tbaa !0
  %12 = getelementptr inbounds i8, i8* %5, i64 8
  %13 = bitcast i8* %12 to i32*
  store i32 6, i32* %13, align 4, !tbaa !29
  %14 = getelementptr inbounds i8, i8* %6, i64 8
  %15 = bitcast i8* %14 to i32*
  store i32 2, i32* %15, align 4, !tbaa !0
  %16 = getelementptr inbounds i8, i8* %5, i64 16
  %17 = bitcast i8* %16 to i32*
  store i32 7, i32* %17, align 4, !tbaa !29
  %18 = getelementptr inbounds i8, i8* %6, i64 12
  %19 = bitcast i8* %18 to i32*
  store i32 3, i32* %19, align 4, !tbaa !0
  %20 = getelementptr inbounds i8, i8* %5, i64 24
  %21 = bitcast i8* %20 to i32*
  store i32 8, i32* %21, align 4, !tbaa !29
  %22 = insertelement <4 x i64> undef, i64 %4, i32 0
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <4 x i32> zeroinitializer
  %24 = bitcast i8* %7 to <4 x i64>*
  store <4 x i64> %23, <4 x i64>* %24, align 8, !tbaa !9
  %25 = getelementptr inbounds i8, i8* %6, i64 16
  %26 = bitcast i8* %25 to i32*
  store i32 4, i32* %26, align 4, !tbaa !0
  %27 = getelementptr inbounds i8, i8* %5, i64 32
  %28 = bitcast i8* %27 to i32*
  store i32 9, i32* %28, align 4, !tbaa !29
  %29 = getelementptr inbounds i8, i8* %7, i64 32
  %30 = getelementptr inbounds i8, i8* %6, i64 20
  %31 = bitcast i8* %30 to i32*
  store i32 5, i32* %31, align 4, !tbaa !0
  %32 = getelementptr inbounds i8, i8* %5, i64 40
  %33 = bitcast i8* %32 to i32*
  store i32 10, i32* %33, align 4, !tbaa !29
  %34 = getelementptr inbounds i8, i8* %6, i64 24
  %35 = bitcast i8* %34 to i32*
  store i32 6, i32* %35, align 4, !tbaa !0
  %36 = getelementptr inbounds i8, i8* %5, i64 48
  %37 = bitcast i8* %36 to i32*
  store i32 11, i32* %37, align 4, !tbaa !29
  %38 = getelementptr inbounds i8, i8* %6, i64 28
  %39 = bitcast i8* %38 to i32*
  store i32 7, i32* %39, align 4, !tbaa !0
  %40 = getelementptr inbounds i8, i8* %5, i64 56
  %41 = bitcast i8* %40 to i32*
  store i32 12, i32* %41, align 4, !tbaa !29
  %42 = bitcast i8* %29 to <4 x i64>*
  store <4 x i64> %23, <4 x i64>* %42, align 8, !tbaa !9
  %43 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %0, i64 0, i32 2
  %44 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %43, align 8, !tbaa !31
  %45 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %44, i64 0, i32 5, i32 0
  %46 = bitcast %struct.rb_code_position_struct** %45 to i8**
  store i8* %5, i8** %46, align 8, !tbaa !33
  %47 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %44, i64 0, i32 5, i32 1
  %48 = bitcast i32** %47 to i8**
  store i8* %6, i8** %48, align 8, !tbaa !42
  %49 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %44, i64 0, i32 1
  store i32 8, i32* %49, align 4, !tbaa !43
  %50 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %44, i64 0, i32 5, i32 2
  store i32 8, i32* %50, align 8, !tbaa !44
  tail call void @rb_iseq_insns_info_encode_positions(%struct.rb_iseq_struct* %0) #10
  %51 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %43, align 8, !tbaa !31
  %52 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %51, i64 0, i32 2
  %53 = bitcast i64** %52 to i8**
  store i8* %7, i8** %53, align 8, !tbaa !45
  store %struct.rb_iseq_struct* %0, %struct.rb_iseq_struct** bitcast (i8** @"stackFramePrecomputed_func_<root>.<static-init>$114" to %struct.rb_iseq_struct**), align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<top (required)>"() #8 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #10
  store i64 %0, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyStrFrozen_<top (required)>"() #8 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #10
  tail call void @rb_gc_register_mark_object(i64 %0) #10
  store i64 %0, i64* @"rubyStrFrozen_<top (required)>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyStrFrozen_test/testdata/compiler/splat.rb"() #8 {
constr:
  %0 = tail call i64 @rb_fstring_new(i8* getelementptr inbounds ([32 x i8], [32 x i8]* @"str_test/testdata/compiler/splat.rb", i64 0, i64 0), i64 31) #10
  tail call void @rb_gc_register_mark_object(i64 %0) #10
  store i64 %0, i64* @"rubyStrFrozen_test/testdata/compiler/splat.rb", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<build-array>"() #8 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_<build-array>", i64 0, i64 0), i64 13) #10
  store i64 %0, i64* @"rubyIdPrecomputed_<build-array>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<expand-splat>"() #8 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @"str_<expand-splat>", i64 0, i64 0), i64 14) #10
  store i64 %0, i64* @"rubyIdPrecomputed_<expand-splat>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_[]"() #8 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @"str_[]", i64 0, i64 0), i64 2) #10
  store i64 %0, i64* @"rubyIdPrecomputed_[]", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_puts() #8 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_puts, i64 0, i64 0), i64 4) #10
  store i64 %0, i64* @rubyIdPrecomputed_puts, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_compiler_splat() local_unnamed_addr #9 {
entry:
  %callArgs.i = alloca [7 x i64], align 16
  %0 = load %struct.rb_vm_struct*, %struct.rb_vm_struct** @ruby_current_vm_ptr, align 8, !tbaa !10
  %1 = getelementptr inbounds %struct.rb_vm_struct, %struct.rb_vm_struct* %0, i64 0, i32 17
  %2 = load i64, i64* %1, align 8, !tbaa !46
  %3 = bitcast [7 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 56, i8* nonnull %3)
  %"stackFrame_func_<root>.<static-init>$114.i" = load i8*, i8** @"stackFramePrecomputed_func_<root>.<static-init>$114", align 8
  %"rubyId_[].i" = load i64, i64* @"rubyIdPrecomputed_[]", align 8
  %rubyId_puts.i = load i64, i64* @rubyIdPrecomputed_puts, align 8
  %4 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !10
  %5 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %4, i64 0, i32 2
  %6 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %5, align 8, !tbaa !12
  %7 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %6, i64 0, i32 2
  %8 = bitcast %struct.rb_iseq_struct** %7 to i8**
  store i8* %"stackFrame_func_<root>.<static-init>$114.i", i8** %8, align 8, !tbaa !15
  %9 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %6, i64 0, i32 4
  %10 = load i64*, i64** %9, align 8, !tbaa !17
  %11 = load i64, i64* %10, align 8, !tbaa !9
  %12 = and i64 %11, -129
  store i64 %12, i64* %10, align 8, !tbaa !9
  %13 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %6, i64 0, i32 0
  %14 = getelementptr inbounds i8, i8* %"stackFrame_func_<root>.<static-init>$114.i", i64 16
  %15 = bitcast i8* %14 to %struct.rb_iseq_constant_body**
  %16 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %15, align 8, !tbaa !31
  %17 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %16, i64 0, i32 2
  %18 = load i64*, i64** %17, align 8, !tbaa !45
  %19 = getelementptr inbounds i64, i64* %18, i64 1
  store i64* %19, i64** %13, align 8, !tbaa !10
  %20 = load %struct.rb_vm_struct*, %struct.rb_vm_struct** @ruby_current_vm_ptr, align 8, !tbaa !10
  %21 = getelementptr inbounds %struct.rb_vm_struct, %struct.rb_vm_struct* %20, i64 0, i32 17
  %22 = load i64, i64* %21, align 8, !tbaa !46
  %23 = icmp eq i64 %22, %2
  br i1 %23, label %typeTestSuccess.i, label %typeTestFail.i, !prof !22

typeTestSuccess.i:                                ; preds = %entry
  %callArgsAddr.i = getelementptr inbounds [7 x i64], [7 x i64]* %callArgs.i, i64 0, i64 0
  %callArgsAddr103.i = getelementptr inbounds [7 x i64], [7 x i64]* %callArgs.i, i64 0, i64 1
  %callArgsAddr105.i = getelementptr inbounds [7 x i64], [7 x i64]* %callArgs.i, i64 0, i64 2
  %24 = bitcast [7 x i64]* %callArgs.i to <4 x i64>*
  store <4 x i64> <i64 3, i64 5, i64 7, i64 9>, <4 x i64>* %24, align 16
  %callArgsAddr109.i = getelementptr inbounds [7 x i64], [7 x i64]* %callArgs.i, i64 0, i64 4
  %25 = bitcast i64* %callArgsAddr109.i to <2 x i64>*
  store <2 x i64> <i64 11, i64 13>, <2 x i64>* %25, align 16
  %callArgsAddr113.i = getelementptr inbounds [7 x i64], [7 x i64]* %callArgs.i, i64 0, i64 6
  store i64 15, i64* %callArgsAddr113.i, align 16
  %26 = call i64 @rb_ary_new_from_values(i64 7, i64* nonnull %callArgsAddr.i) #10
  store i64 %26, i64* %callArgsAddr.i, align 16
  %27 = bitcast i64* %callArgsAddr103.i to <2 x i64>*
  store <2 x i64> <i64 3, i64 5>, <2 x i64>* %27, align 8
  %28 = inttoptr i64 %26 to %struct.RBasic*
  %29 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %28, i64 0, i32 0
  %30 = load i64, i64* %29, align 8, !tbaa !4, !noalias !56
  %31 = and i64 %30, 8192
  %32 = icmp eq i64 %31, 0
  br i1 %32, label %36, label %33

33:                                               ; preds = %typeTestSuccess.i
  %34 = lshr i64 %30, 15
  %35 = and i64 %34, 3
  br label %rb_array_len.exit.i.i

36:                                               ; preds = %typeTestSuccess.i
  %37 = inttoptr i64 %26 to %struct.RArray*
  %38 = getelementptr inbounds %struct.RArray, %struct.RArray* %37, i64 0, i32 1, i32 0, i32 0
  %39 = load i64, i64* %38, align 8, !tbaa !7, !noalias !56
  br label %rb_array_len.exit.i.i

rb_array_len.exit.i.i:                            ; preds = %36, %33
  %40 = phi i64 [ %35, %33 ], [ %39, %36 ]
  %41 = trunc i64 %40 to i32
  %42 = sub i32 3, %41
  %43 = icmp sgt i32 %42, 0
  br i1 %43, label %44, label %sorbet_splatIntrinsic.exit.i

44:                                               ; preds = %rb_array_len.exit.i.i
  %45 = call i64 @rb_ary_dup(i64 %26) #10, !noalias !56
  br label %46

46:                                               ; preds = %46, %44
  %47 = phi i32 [ 0, %44 ], [ %49, %46 ]
  %48 = call i64 @rb_ary_push(i64 %45, i64 8) #10, !noalias !56
  %49 = add nuw nsw i32 %47, 1
  %50 = icmp eq i32 %49, %42
  br i1 %50, label %sorbet_splatIntrinsic.exit.i, label %46

sorbet_splatIntrinsic.exit.i:                     ; preds = %46, %rb_array_len.exit.i.i
  %51 = phi i64 [ %26, %rb_array_len.exit.i.i ], [ %45, %46 ]
  %52 = and i64 %51, 7
  %53 = icmp ne i64 %52, 0
  %54 = and i64 %51, -9
  %55 = icmp eq i64 %54, 0
  %56 = or i1 %53, %55
  br i1 %56, label %sorbet_isa_Array.exit.thread.i, label %sorbet_isa_Array.exit.i, !prof !59

sorbet_isa_Array.exit.thread.i:                   ; preds = %sorbet_splatIntrinsic.exit.i
  store i64 1, i64* %callArgsAddr.i, align 16
  br label %"alternativeCallIntrinsic_Array_[]157.i"

sorbet_isa_Array.exit.i:                          ; preds = %sorbet_splatIntrinsic.exit.i
  %57 = inttoptr i64 %51 to %struct.RBasic*
  %58 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 0
  %59 = load i64, i64* %58, align 8, !tbaa !4
  %60 = and i64 %59, 31
  %61 = icmp eq i64 %60, 7
  store i64 1, i64* %callArgsAddr.i, align 16
  br i1 %61, label %"fastSymCallIntrinsic_Array_[]158.i", label %"alternativeCallIntrinsic_Array_[]157.i", !prof !22

typeTestFail.i:                                   ; preds = %entry
  tail call fastcc void @sorbet_cast_failure(i64 %2) #10
  unreachable

afterSend154.i:                                   ; preds = %"fastSymCallIntrinsic_Array_[]158.i", %"alternativeCallIntrinsic_Array_[]157.i"
  %"symIntrinsicRawPhi_[]13914.i" = phi i64 [ %103, %"fastSymCallIntrinsic_Array_[]158.i" ], [ %"call_via_vm_[]152.i", %"alternativeCallIntrinsic_Array_[]157.i" ]
  %"symIntrinsicRawPhi_[]812.i" = phi i64 [ %102, %"fastSymCallIntrinsic_Array_[]158.i" ], [ %"call_via_vm_[].i", %"alternativeCallIntrinsic_Array_[]157.i" ]
  %"symIntrinsicRawPhi_[]155.i" = phi i64 [ %104, %"fastSymCallIntrinsic_Array_[]158.i" ], [ %"call_via_vm_[]168.i", %"alternativeCallIntrinsic_Array_[]157.i" ]
  %62 = getelementptr inbounds i64, i64* %18, i64 2
  store i64* %62, i64** %13, align 8, !tbaa !10
  store i64 %"symIntrinsicRawPhi_[]812.i", i64* %callArgsAddr.i, align 16
  store i64 %"symIntrinsicRawPhi_[]13914.i", i64* %callArgsAddr103.i, align 8
  store i64 %"symIntrinsicRawPhi_[]155.i", i64* %callArgsAddr105.i, align 16
  %63 = call i64 @rb_ary_new_from_values(i64 3, i64* nonnull %callArgsAddr.i) #10
  store i64 %63, i64* %callArgsAddr.i, align 16
  %64 = call fastcc i64 @sorbet_callFunc(i64 %2, i64 %rubyId_puts.i, i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_puts) #10
  %65 = getelementptr inbounds i64, i64* %18, i64 4
  store i64* %65, i64** %13, align 8, !tbaa !10
  %66 = bitcast [7 x i64]* %callArgs.i to <2 x i64>*
  store <2 x i64> <i64 3, i64 5>, <2 x i64>* %66, align 16
  %67 = call i64 @rb_ary_new_from_values(i64 2, i64* nonnull %callArgsAddr.i) #10
  store i64 %67, i64* %callArgsAddr.i, align 16
  store <2 x i64> <i64 3, i64 5>, <2 x i64>* %27, align 8
  %68 = inttoptr i64 %67 to %struct.RBasic*
  %69 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %68, i64 0, i32 0
  %70 = load i64, i64* %69, align 8, !tbaa !4, !noalias !60
  %71 = and i64 %70, 8192
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %76, label %73

73:                                               ; preds = %afterSend154.i
  %74 = lshr i64 %70, 15
  %75 = and i64 %74, 3
  br label %rb_array_len.exit.i1.i

76:                                               ; preds = %afterSend154.i
  %77 = inttoptr i64 %67 to %struct.RArray*
  %78 = getelementptr inbounds %struct.RArray, %struct.RArray* %77, i64 0, i32 1, i32 0, i32 0
  %79 = load i64, i64* %78, align 8, !tbaa !7, !noalias !60
  br label %rb_array_len.exit.i1.i

rb_array_len.exit.i1.i:                           ; preds = %76, %73
  %80 = phi i64 [ %75, %73 ], [ %79, %76 ]
  %81 = trunc i64 %80 to i32
  %82 = sub i32 3, %81
  %83 = icmp sgt i32 %82, 0
  br i1 %83, label %84, label %sorbet_splatIntrinsic.exit2.i

84:                                               ; preds = %rb_array_len.exit.i1.i
  %85 = call i64 @rb_ary_dup(i64 %67) #10, !noalias !60
  br label %86

86:                                               ; preds = %86, %84
  %87 = phi i32 [ 0, %84 ], [ %89, %86 ]
  %88 = call i64 @rb_ary_push(i64 %85, i64 8) #10, !noalias !60
  %89 = add nuw nsw i32 %87, 1
  %90 = icmp eq i32 %89, %82
  br i1 %90, label %sorbet_splatIntrinsic.exit2.i, label %86

sorbet_splatIntrinsic.exit2.i:                    ; preds = %86, %rb_array_len.exit.i1.i
  %91 = phi i64 [ %67, %rb_array_len.exit.i1.i ], [ %85, %86 ]
  %92 = and i64 %91, 7
  %93 = icmp ne i64 %92, 0
  %94 = and i64 %91, -9
  %95 = icmp eq i64 %94, 0
  %96 = or i1 %93, %95
  br i1 %96, label %sorbet_isa_Array.exit3.thread.i, label %sorbet_isa_Array.exit3.i, !prof !59

sorbet_isa_Array.exit3.thread.i:                  ; preds = %sorbet_splatIntrinsic.exit2.i
  store i64 1, i64* %callArgsAddr.i, align 16
  br label %"alternativeCallIntrinsic_Array_[]244.i"

sorbet_isa_Array.exit3.i:                         ; preds = %sorbet_splatIntrinsic.exit2.i
  %97 = inttoptr i64 %91 to %struct.RBasic*
  %98 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %97, i64 0, i32 0
  %99 = load i64, i64* %98, align 8, !tbaa !4
  %100 = and i64 %99, 31
  %101 = icmp eq i64 %100, 7
  store i64 1, i64* %callArgsAddr.i, align 16
  br i1 %101, label %"fastSymCallIntrinsic_Array_[]245.i", label %"alternativeCallIntrinsic_Array_[]244.i", !prof !22

"alternativeCallIntrinsic_Array_[]157.i":         ; preds = %sorbet_isa_Array.exit.i, %sorbet_isa_Array.exit.thread.i
  %"call_via_vm_[].i" = call fastcc i64 @sorbet_callFunc(i64 %51, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[]") #10
  store i64 -3, i64* %callArgsAddr.i, align 16
  %"call_via_vm_[]152.i" = call fastcc i64 @sorbet_callFunc(i64 %51, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].1") #10
  store i64 -1, i64* %callArgsAddr.i, align 16
  %"call_via_vm_[]168.i" = call fastcc i64 @sorbet_callFunc(i64 %51, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].2") #10
  br label %afterSend154.i

"fastSymCallIntrinsic_Array_[]158.i":             ; preds = %sorbet_isa_Array.exit.i
  %102 = call i64 @rb_ary_entry(i64 %51, i64 0) #10
  store i64 -3, i64* %callArgsAddr.i, align 16
  %103 = call i64 @rb_ary_entry(i64 %51, i64 -2) #10
  store i64 -1, i64* %callArgsAddr.i, align 16
  %104 = call i64 @rb_ary_entry(i64 %51, i64 -1) #10
  br label %afterSend154.i

afterSend241.i:                                   ; preds = %"fastSymCallIntrinsic_Array_[]245.i", %"alternativeCallIntrinsic_Array_[]244.i"
  %"symIntrinsicRawPhi_[]22623.i" = phi i64 [ %145, %"fastSymCallIntrinsic_Array_[]245.i" ], [ %"call_via_vm_[]239.i", %"alternativeCallIntrinsic_Array_[]244.i" ]
  %"symIntrinsicRawPhi_[]2101721.i" = phi i64 [ %144, %"fastSymCallIntrinsic_Array_[]245.i" ], [ %"call_via_vm_[]223.i", %"alternativeCallIntrinsic_Array_[]244.i" ]
  %"symIntrinsicRawPhi_[]242.i" = phi i64 [ %146, %"fastSymCallIntrinsic_Array_[]245.i" ], [ %"call_via_vm_[]255.i", %"alternativeCallIntrinsic_Array_[]244.i" ]
  %105 = getelementptr inbounds i64, i64* %18, i64 5
  store i64* %105, i64** %13, align 8, !tbaa !10
  store i64 %"symIntrinsicRawPhi_[]2101721.i", i64* %callArgsAddr.i, align 16
  store i64 %"symIntrinsicRawPhi_[]22623.i", i64* %callArgsAddr103.i, align 8
  store i64 %"symIntrinsicRawPhi_[]242.i", i64* %callArgsAddr105.i, align 16
  %106 = call i64 @rb_ary_new_from_values(i64 3, i64* nonnull %callArgsAddr.i) #10
  store i64 %106, i64* %callArgsAddr.i, align 16
  %107 = call fastcc i64 @sorbet_callFunc(i64 %2, i64 %rubyId_puts.i, i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_puts.6) #10
  %108 = getelementptr inbounds i64, i64* %18, i64 7
  store i64* %108, i64** %13, align 8, !tbaa !10
  %109 = call i64 @rb_ary_new() #10
  store i64 %109, i64* %callArgsAddr.i, align 16
  store <2 x i64> <i64 3, i64 5>, <2 x i64>* %27, align 8
  %110 = inttoptr i64 %109 to %struct.RBasic*
  %111 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %110, i64 0, i32 0
  %112 = load i64, i64* %111, align 8, !tbaa !4, !noalias !63
  %113 = and i64 %112, 8192
  %114 = icmp eq i64 %113, 0
  br i1 %114, label %118, label %115

115:                                              ; preds = %afterSend241.i
  %116 = lshr i64 %112, 15
  %117 = and i64 %116, 3
  br label %rb_array_len.exit.i4.i

118:                                              ; preds = %afterSend241.i
  %119 = inttoptr i64 %109 to %struct.RArray*
  %120 = getelementptr inbounds %struct.RArray, %struct.RArray* %119, i64 0, i32 1, i32 0, i32 0
  %121 = load i64, i64* %120, align 8, !tbaa !7, !noalias !63
  br label %rb_array_len.exit.i4.i

rb_array_len.exit.i4.i:                           ; preds = %118, %115
  %122 = phi i64 [ %117, %115 ], [ %121, %118 ]
  %123 = trunc i64 %122 to i32
  %124 = sub i32 3, %123
  %125 = icmp sgt i32 %124, 0
  br i1 %125, label %126, label %sorbet_splatIntrinsic.exit5.i

126:                                              ; preds = %rb_array_len.exit.i4.i
  %127 = call i64 @rb_ary_dup(i64 %109) #10, !noalias !63
  br label %128

128:                                              ; preds = %128, %126
  %129 = phi i32 [ 0, %126 ], [ %131, %128 ]
  %130 = call i64 @rb_ary_push(i64 %127, i64 8) #10, !noalias !63
  %131 = add nuw nsw i32 %129, 1
  %132 = icmp eq i32 %131, %124
  br i1 %132, label %sorbet_splatIntrinsic.exit5.i, label %128

sorbet_splatIntrinsic.exit5.i:                    ; preds = %128, %rb_array_len.exit.i4.i
  %133 = phi i64 [ %109, %rb_array_len.exit.i4.i ], [ %127, %128 ]
  %134 = and i64 %133, 7
  %135 = icmp ne i64 %134, 0
  %136 = and i64 %133, -9
  %137 = icmp eq i64 %136, 0
  %138 = or i1 %135, %137
  br i1 %138, label %sorbet_isa_Array.exit6.thread.i, label %sorbet_isa_Array.exit6.i, !prof !59

sorbet_isa_Array.exit6.thread.i:                  ; preds = %sorbet_splatIntrinsic.exit5.i
  store i64 1, i64* %callArgsAddr.i, align 16
  br label %"alternativeCallIntrinsic_Array_[]328.i"

sorbet_isa_Array.exit6.i:                         ; preds = %sorbet_splatIntrinsic.exit5.i
  %139 = inttoptr i64 %133 to %struct.RBasic*
  %140 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %139, i64 0, i32 0
  %141 = load i64, i64* %140, align 8, !tbaa !4
  %142 = and i64 %141, 31
  %143 = icmp eq i64 %142, 7
  store i64 1, i64* %callArgsAddr.i, align 16
  br i1 %143, label %"fastSymCallIntrinsic_Array_[]329.i", label %"alternativeCallIntrinsic_Array_[]328.i", !prof !22

"alternativeCallIntrinsic_Array_[]244.i":         ; preds = %sorbet_isa_Array.exit3.i, %sorbet_isa_Array.exit3.thread.i
  %"call_via_vm_[]223.i" = call fastcc i64 @sorbet_callFunc(i64 %91, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].3") #10
  store i64 -3, i64* %callArgsAddr.i, align 16
  %"call_via_vm_[]239.i" = call fastcc i64 @sorbet_callFunc(i64 %91, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].4") #10
  store i64 -1, i64* %callArgsAddr.i, align 16
  %"call_via_vm_[]255.i" = call fastcc i64 @sorbet_callFunc(i64 %91, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].5") #10
  br label %afterSend241.i

"fastSymCallIntrinsic_Array_[]245.i":             ; preds = %sorbet_isa_Array.exit3.i
  %144 = call i64 @rb_ary_entry(i64 %91, i64 0) #10
  store i64 -3, i64* %callArgsAddr.i, align 16
  %145 = call i64 @rb_ary_entry(i64 %91, i64 -2) #10
  store i64 -1, i64* %callArgsAddr.i, align 16
  %146 = call i64 @rb_ary_entry(i64 %91, i64 -1) #10
  br label %afterSend241.i

"alternativeCallIntrinsic_Array_[]328.i":         ; preds = %sorbet_isa_Array.exit6.i, %sorbet_isa_Array.exit6.thread.i
  %"call_via_vm_[]307.i" = call fastcc i64 @sorbet_callFunc(i64 %133, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].7") #10
  store i64 -3, i64* %callArgsAddr.i, align 16
  %"call_via_vm_[]323.i" = call fastcc i64 @sorbet_callFunc(i64 %133, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].8") #10
  store i64 -1, i64* %callArgsAddr.i, align 16
  %"call_via_vm_[]339.i" = call fastcc i64 @sorbet_callFunc(i64 %133, i64 %"rubyId_[].i", i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @"ic_call_via_vm_[].9") #10
  br label %"func_<root>.<static-init>$114.exit"

"fastSymCallIntrinsic_Array_[]329.i":             ; preds = %sorbet_isa_Array.exit6.i
  %147 = call i64 @rb_ary_entry(i64 %133, i64 0) #10
  store i64 -3, i64* %callArgsAddr.i, align 16
  %148 = call i64 @rb_ary_entry(i64 %133, i64 -2) #10
  store i64 -1, i64* %callArgsAddr.i, align 16
  %149 = call i64 @rb_ary_entry(i64 %133, i64 -1) #10
  br label %"func_<root>.<static-init>$114.exit"

"func_<root>.<static-init>$114.exit":             ; preds = %"alternativeCallIntrinsic_Array_[]328.i", %"fastSymCallIntrinsic_Array_[]329.i"
  %"symIntrinsicRawPhi_[]31032.i" = phi i64 [ %148, %"fastSymCallIntrinsic_Array_[]329.i" ], [ %"call_via_vm_[]323.i", %"alternativeCallIntrinsic_Array_[]328.i" ]
  %"symIntrinsicRawPhi_[]2942630.i" = phi i64 [ %147, %"fastSymCallIntrinsic_Array_[]329.i" ], [ %"call_via_vm_[]307.i", %"alternativeCallIntrinsic_Array_[]328.i" ]
  %"symIntrinsicRawPhi_[]326.i" = phi i64 [ %149, %"fastSymCallIntrinsic_Array_[]329.i" ], [ %"call_via_vm_[]339.i", %"alternativeCallIntrinsic_Array_[]328.i" ]
  %150 = getelementptr inbounds i64, i64* %18, i64 8
  store i64* %150, i64** %13, align 8, !tbaa !10
  store i64 %"symIntrinsicRawPhi_[]2942630.i", i64* %callArgsAddr.i, align 16
  store i64 %"symIntrinsicRawPhi_[]31032.i", i64* %callArgsAddr103.i, align 8
  store i64 %"symIntrinsicRawPhi_[]326.i", i64* %callArgsAddr105.i, align 16
  %151 = call i64 @rb_ary_new_from_values(i64 3, i64* nonnull %callArgsAddr.i) #10
  store i64 %151, i64* %callArgsAddr.i, align 16
  %152 = call fastcc i64 @sorbet_callFunc(i64 %2, i64 %rubyId_puts.i, i64* nonnull %callArgsAddr.i, %struct.FunctionInlineCache* nonnull @ic_call_via_vm_puts.10) #10
  call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %3)
  ret void
}

attributes #0 = { "addedToSilenceEmptyAttrsError" }
attributes #1 = { nounwind ssp uwtable }
attributes #2 = { norecurse nounwind readnone ssp uwtable }
attributes #3 = { noreturn }
attributes #4 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #5 = { nofree norecurse nounwind ssp uwtable }
attributes #6 = { argmemonly nounwind }
attributes #7 = { norecurse nounwind readonly ssp uwtable }
attributes #8 = { nounwind ssp }
attributes #9 = { nounwind sspreq }
attributes #10 = { nounwind }
attributes #11 = { noreturn nounwind }

!0 = !{!1, !1, i64 0}
!1 = !{!"int", !2, i64 0}
!2 = !{!"omnipotent char", !3, i64 0}
!3 = !{!"Simple C/C++ TBAA"}
!4 = !{!5, !6, i64 0}
!5 = !{!"RBasic", !6, i64 0, !6, i64 8}
!6 = !{!"long", !2, i64 0}
!7 = !{!2, !2, i64 0}
!8 = !{i32 1407}
!9 = !{!6, !6, i64 0}
!10 = !{!11, !11, i64 0}
!11 = !{!"any pointer", !2, i64 0}
!12 = !{!13, !11, i64 16}
!13 = !{!"rb_execution_context_struct", !11, i64 0, !6, i64 8, !11, i64 16, !11, i64 24, !11, i64 32, !1, i64 40, !1, i64 44, !11, i64 48, !11, i64 56, !11, i64 64, !6, i64 72, !6, i64 80, !11, i64 88, !6, i64 96, !11, i64 104, !11, i64 112, !6, i64 120, !6, i64 128, !2, i64 136, !2, i64 137, !6, i64 144, !14, i64 152}
!14 = !{!"", !11, i64 0, !11, i64 8, !6, i64 16, !2, i64 24}
!15 = !{!16, !11, i64 16}
!16 = !{!"rb_control_frame_struct", !11, i64 0, !11, i64 8, !11, i64 16, !6, i64 24, !11, i64 32, !11, i64 40, !11, i64 48}
!17 = !{!16, !11, i64 32}
!18 = !{!19, !19, i64 0}
!19 = !{!"long long", !2, i64 0}
!20 = !{!21, !19, i64 8}
!21 = !{!"FunctionInlineCache", !11, i64 0, !19, i64 8, !19, i64 16}
!22 = !{!"branch_weights", i32 2000, i32 1}
!23 = !{!24, !11, i64 24}
!24 = !{!"RClass", !5, i64 0, !6, i64 16, !11, i64 24, !11, i64 32}
!25 = !{!26, !19, i64 56}
!26 = !{!"rb_classext_struct", !11, i64 0, !11, i64 8, !11, i64 16, !11, i64 24, !11, i64 32, !11, i64 40, !11, i64 48, !19, i64 56, !6, i64 64, !6, i64 72, !11, i64 80}
!27 = !{!21, !19, i64 16}
!28 = !{!21, !11, i64 0}
!29 = !{!30, !1, i64 0}
!30 = !{!"iseq_insn_info_entry", !1, i64 0, !1, i64 4}
!31 = !{!32, !11, i64 16}
!32 = !{!"rb_iseq_struct", !6, i64 0, !6, i64 8, !11, i64 16, !2, i64 24}
!33 = !{!34, !11, i64 120}
!34 = !{!"rb_iseq_constant_body", !2, i64 0, !1, i64 4, !11, i64 8, !35, i64 16, !37, i64 64, !40, i64 120, !11, i64 152, !11, i64 160, !11, i64 168, !11, i64 176, !11, i64 184, !11, i64 192, !11, i64 200, !41, i64 208, !1, i64 240, !1, i64 244, !1, i64 248, !1, i64 252, !1, i64 256, !11, i64 264, !6, i64 272, !11, i64 280, !2, i64 288}
!35 = !{!"", !36, i64 0, !1, i64 4, !1, i64 8, !1, i64 12, !1, i64 16, !1, i64 20, !1, i64 24, !1, i64 28, !11, i64 32, !11, i64 40}
!36 = !{!"", !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0, !1, i64 0}
!37 = !{!"rb_iseq_location_struct", !6, i64 0, !6, i64 8, !6, i64 16, !6, i64 24, !1, i64 32, !38, i64 36}
!38 = !{!"rb_code_location_struct", !39, i64 0, !39, i64 8}
!39 = !{!"rb_code_position_struct", !1, i64 0, !1, i64 4}
!40 = !{!"iseq_insn_info", !11, i64 0, !11, i64 8, !1, i64 16, !11, i64 24}
!41 = !{!"", !6, i64 0, !6, i64 8, !6, i64 16, !11, i64 24}
!42 = !{!34, !11, i64 128}
!43 = !{!34, !1, i64 4}
!44 = !{!34, !1, i64 136}
!45 = !{!34, !11, i64 8}
!46 = !{!47, !6, i64 448}
!47 = !{!"rb_vm_struct", !6, i64 0, !48, i64 8, !11, i64 216, !11, i64 224, !11, i64 232, !19, i64 240, !49, i64 248, !50, i64 312, !50, i64 328, !50, i64 344, !50, i64 360, !6, i64 376, !1, i64 384, !1, i64 388, !1, i64 388, !1, i64 388, !1, i64 388, !1, i64 392, !6, i64 400, !2, i64 408, !6, i64 448, !6, i64 456, !6, i64 464, !6, i64 472, !6, i64 480, !6, i64 488, !6, i64 496, !11, i64 504, !11, i64 512, !53, i64 520, !54, i64 808, !11, i64 832, !11, i64 840, !1, i64 848, !1, i64 852, !50, i64 856, !49, i64 872, !6, i64 936, !6, i64 944, !6, i64 952, !6, i64 960, !6, i64 968, !1, i64 976, !6, i64 984, !11, i64 992, !11, i64 1000, !11, i64 1008, !11, i64 1016, !55, i64 1024, !2, i64 1056}
!48 = !{!"rb_global_vm_lock_struct", !11, i64 0, !49, i64 8, !50, i64 72, !11, i64 88, !1, i64 96, !52, i64 104, !52, i64 152, !1, i64 200, !1, i64 204}
!49 = !{!"_opaque_pthread_mutex_t", !6, i64 0, !2, i64 8}
!50 = !{!"list_head", !51, i64 0}
!51 = !{!"list_node", !11, i64 0, !11, i64 8}
!52 = !{!"_opaque_pthread_cond_t", !6, i64 0, !2, i64 8}
!53 = !{!"", !2, i64 0, !2, i64 256}
!54 = !{!"rb_hook_list_struct", !11, i64 0, !1, i64 8, !1, i64 12, !1, i64 16}
!55 = !{!"", !6, i64 0, !6, i64 8, !6, i64 16, !6, i64 24}
!56 = !{!57}
!57 = distinct !{!57, !58, !"sorbet_splatIntrinsic: argument 0"}
!58 = distinct !{!58, !"sorbet_splatIntrinsic"}
!59 = !{!"branch_weights", i32 1073205, i32 2146410443}
!60 = !{!61}
!61 = distinct !{!61, !62, !"sorbet_splatIntrinsic: argument 0"}
!62 = distinct !{!62, !"sorbet_splatIntrinsic"}
!63 = !{!64}
!64 = distinct !{!64, !65, !"sorbet_splatIntrinsic: argument 0"}
!65 = distinct !{!65, !"sorbet_splatIntrinsic"}
