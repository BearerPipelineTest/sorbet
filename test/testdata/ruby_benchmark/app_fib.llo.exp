; ModuleID = 'payload'
source_filename = "compiler/IREmitter/Payload/payload.c"
target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.1, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.1 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.rb_execution_context_struct = type { i64*, i64, %struct.rb_control_frame_struct*, %struct.rb_vm_tag*, %struct.rb_vm_protect_tag*, i32, i32, %struct.rb_fiber_struct*, %struct.rb_thread_struct*, %struct.st_table*, i64, i64, i64*, i64, %struct.rb_ensure_list*, %struct.rb_trace_arg_struct*, i64, i64, i8, i8, i64, %struct.anon.19 }
%struct.rb_control_frame_struct = type { i64*, i64*, %struct.rb_iseq_struct*, i64, i64*, i8*, i64* }
%struct.rb_iseq_struct = type { i64, i64, %struct.rb_iseq_constant_body*, %union.anon.16 }
%struct.rb_iseq_constant_body = type { i32, i32, i64*, %struct.anon.2, %struct.rb_iseq_location_struct, %struct.iseq_insn_info, i64*, %struct.iseq_catch_table*, %struct.rb_iseq_struct*, %struct.rb_iseq_struct*, %union.iseq_inline_storage_entry*, %struct.rb_call_info*, %struct.rb_call_cache*, %struct.anon.15, i32, i32, i32, i32, i32, i8 }
%struct.anon.2 = type { %struct.anon.3, i32, i32, i32, i32, i32, i32, i32, i64*, %struct.rb_iseq_param_keyword* }
%struct.anon.3 = type { i8, [3 x i8] }
%struct.rb_iseq_param_keyword = type { i32, i32, i32, i32, i64*, i64* }
%struct.rb_iseq_location_struct = type { i64, i64, i64, i64, i32, %struct.rb_code_location_struct }
%struct.rb_code_location_struct = type { %struct.rb_code_position_struct, %struct.rb_code_position_struct }
%struct.rb_code_position_struct = type { i32, i32 }
%struct.iseq_insn_info = type { %struct.iseq_insn_info_entry*, i32*, i32, %struct.succ_index_table* }
%struct.iseq_insn_info_entry = type opaque
%struct.succ_index_table = type opaque
%struct.iseq_catch_table = type opaque
%union.iseq_inline_storage_entry = type { %struct.iseq_inline_cache_entry }
%struct.iseq_inline_cache_entry = type { i64, %struct.rb_cref_struct*, %union.anon.12 }
%struct.rb_cref_struct = type { i64, i64, i64, %struct.rb_cref_struct*, %struct.rb_scope_visi_struct }
%struct.rb_scope_visi_struct = type { i8, [3 x i8] }
%union.anon.12 = type { i64 }
%struct.rb_call_info = type { i64, i32, i32 }
%struct.rb_call_cache = type { i64, i64, %struct.rb_callable_method_entry_struct*, i64 (%struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, %struct.rb_calling_info*, %struct.rb_call_info*, %struct.rb_call_cache*)*, %union.anon.14 }
%struct.rb_callable_method_entry_struct = type { i64, i64, %struct.rb_method_definition_struct*, i64, i64 }
%struct.rb_method_definition_struct = type { i64, %union.anon.13, i64 }
%union.anon.13 = type { %struct.rb_method_cfunc_struct }
%struct.rb_method_cfunc_struct = type { i64 (...)*, i64 (i64 (...)*, i64, i32, i64*)*, i32 }
%struct.rb_calling_info = type { i64, i64, i32 }
%union.anon.14 = type { i32 }
%struct.anon.15 = type { i64, i64, i64, i64* }
%union.anon.16 = type { %struct.anon.17 }
%struct.anon.17 = type { i64, i32 }
%struct.rb_vm_tag = type { i64, i64, [38 x i32], %struct.rb_vm_tag*, i32 }
%struct.rb_vm_protect_tag = type { %struct.rb_vm_protect_tag* }
%struct.rb_fiber_struct = type opaque
%struct.rb_thread_struct = type { %struct.list_node, i64, %struct.rb_vm_struct*, %struct.rb_execution_context_struct*, i64, %struct.rb_calling_info*, i64, i64, %struct._opaque_pthread_t*, i8, i8, i32, %struct.native_thread_data_struct, i8*, i64, i64, i64, i64, %struct._opaque_pthread_mutex_t, %struct.rb_unblock_callback, i64, %struct.rb_mutex_struct*, %struct.rb_thread_list_struct*, %union.anon.9, i32, i64, %struct.rb_fiber_struct*, [38 x i32], i64 }
%struct.list_node = type { %struct.list_node*, %struct.list_node* }
%struct.rb_vm_struct = type { i64, %struct.rb_global_vm_lock_struct, %struct.rb_thread_struct*, %struct.rb_thread_struct*, i8*, i64, %struct._opaque_pthread_mutex_t, %struct.list_head, %struct.list_head, %struct.list_head, %struct.list_head, i64, i32, i8, i32, i64, [5 x i64], i64, i64, i64, i64, i64, i64, i64, %struct.st_table*, %struct.st_table*, %struct.anon.5, %struct.rb_hook_list_struct, %struct.st_table*, %struct.rb_postponed_job_struct*, i32, i32, %struct.list_head, %struct._opaque_pthread_mutex_t, i64, i64, i64, i64, i64, i32, i64, %struct.rb_objspace*, %struct.rb_at_exit_list*, i64*, %struct.st_table*, %struct.anon.6, [28 x i16] }
%struct.rb_global_vm_lock_struct = type { %struct.rb_thread_struct*, %struct._opaque_pthread_mutex_t, %struct.list_head, %struct.rb_thread_struct*, i32, %struct._opaque_pthread_cond_t, %struct._opaque_pthread_cond_t, i32, i32 }
%struct._opaque_pthread_cond_t = type { i64, [40 x i8] }
%struct.anon.5 = type { [32 x i64], [32 x i8] }
%struct.rb_hook_list_struct = type { %struct.rb_event_hook_struct*, i32, i32, i32 }
%struct.rb_event_hook_struct = type opaque
%struct.rb_postponed_job_struct = type opaque
%struct.list_head = type { %struct.list_node }
%struct.rb_objspace = type opaque
%struct.rb_at_exit_list = type { void (%struct.rb_vm_struct*)*, %struct.rb_at_exit_list* }
%struct.anon.6 = type { i64, i64, i64, i64 }
%struct._opaque_pthread_t = type { i64, %struct.__darwin_pthread_handler_rec*, [8176 x i8] }
%struct.__darwin_pthread_handler_rec = type { void (i8*)*, i8*, %struct.__darwin_pthread_handler_rec* }
%struct.native_thread_data_struct = type { %union.anon.7, %struct.anon.8 }
%union.anon.7 = type { %struct.list_node }
%struct.anon.8 = type { %struct._opaque_pthread_cond_t, %struct._opaque_pthread_cond_t }
%struct._opaque_pthread_mutex_t = type { i64, [56 x i8] }
%struct.rb_unblock_callback = type { void (i8*)*, i8* }
%struct.rb_mutex_struct = type opaque
%struct.rb_thread_list_struct = type { %struct.rb_thread_list_struct*, %struct.rb_thread_struct* }
%union.anon.9 = type { %struct.anon.10 }
%struct.anon.10 = type { i64, i64 }
%struct.st_table = type { i8, i8, i8, i32, %struct.st_hash_type*, i64, i64*, i64, i64, %struct.st_table_entry* }
%struct.st_hash_type = type { i32 (...)*, i64 (...)* }
%struct.st_table_entry = type opaque
%struct.rb_ensure_list = type { %struct.rb_ensure_list*, %struct.rb_ensure_entry }
%struct.rb_ensure_entry = type { i64, i64 (...)*, i64 }
%struct.rb_trace_arg_struct = type { i32, %struct.rb_execution_context_struct*, %struct.rb_control_frame_struct*, i64, i64, i64, i64, i64, i32, i32, i64 }
%struct.anon.19 = type { i64*, i64*, i64, [37 x i32] }
%struct.RBasic = type { i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%union.anon.0 = type { i64 }
%struct.OnigEncodingTypeST = type { i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i8*, i32, i32, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8**, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i32 (i32, i32*, i32, i8*)*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, i8*, %struct.OnigCaseFoldCodeItem*, %struct.OnigEncodingTypeST*)*, i32 (%struct.OnigEncodingTypeST*, i8*, i8*)*, i32 (i32, i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i32*, i32**, %struct.OnigEncodingTypeST*)*, i8* (i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32*, i8**, i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32, i32 }
%struct.OnigCaseFoldCodeItem = type { i32, i32, [3 x i32] }
%struct.rb_ast_body_struct = type { %struct.RNode*, i64, i32 }
%struct.RNode = type { i64, %union.anon.20, %union.anon.21, %union.anon.22, %struct.rb_code_location_struct, i32 }
%union.anon.20 = type { %struct.RNode* }
%union.anon.21 = type { %struct.RNode* }
%union.anon.22 = type { %struct.RNode* }
%struct.rb_compile_option_struct = type { i16, i32 }
%struct.RTypedData = type { %struct.RBasic, %struct.rb_data_type_struct*, i64, i8* }
%struct.sorbet_Closure = type { i32, [0 x i64] }
%struct.RFloat = type { %struct.RBasic, double }

@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@rb_cObject = external local_unnamed_addr constant i64, align 8
@ruby_vm_global_constant_state = external local_unnamed_addr global i64, align 8
@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@.str.1 = private unnamed_addr constant [29 x i8] c"wrong constant name %li\0B%li\0B\00", align 1
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.2 = private unnamed_addr constant [36 x i8] c"%li\0B does not refer to class/module\00", align 1
@sorbet_getConstantAt.rb_intern_id_cache = internal unnamed_addr global i64 0, align 8
@.str.3 = private unnamed_addr constant [14 x i8] c"const_missing\00", align 1
@.str.4 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.7 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@.str.8 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@closureInfo = constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.8, i32 0, i32 0), %struct.anon.1 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@rb_cData = external local_unnamed_addr constant i64, align 8
@rb_cModule = external local_unnamed_addr constant i64, align 8
@ruby_current_execution_context_ptr = external local_unnamed_addr global %struct.rb_execution_context_struct*, align 8
@"rubyIdPrecomputed_<top (required)>" = internal unnamed_addr global i64 0, align 8
@"str_<top (required)>" = private unnamed_addr constant [17 x i8] c"<top (required)>\00", align 1
@"str_test/testdata/ruby_benchmark/app_fib.rb" = private unnamed_addr constant [40 x i8] c"test/testdata/ruby_benchmark/app_fib.rb\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@str_HasFib = private unnamed_addr constant [7 x i8] c"HasFib\00", align 1
@rubyIdPrecomputed_fib = internal unnamed_addr global i64 0, align 8
@str_fib = private unnamed_addr constant [4 x i8] c"fib\00", align 1
@str_sig = private unnamed_addr constant [4 x i8] c"sig\00", align 1
@str_Integer = private unnamed_addr constant [8 x i8] c"Integer\00", align 1
@"str_T.class_of(HasFib)" = private unnamed_addr constant [19 x i8] c"T.class_of(HasFib)\00", align 1
@"rubyIdPrecomputed_<" = internal unnamed_addr global i64 0, align 8
@"str_<" = private unnamed_addr constant [2 x i8] c"<\00", align 1
@rubyIdPrecomputed_- = internal unnamed_addr global i64 0, align 8
@str_- = private unnamed_addr constant [2 x i8] c"-\00", align 1
@"rubyIdPrecomputed_+" = internal unnamed_addr global i64 0, align 8
@"str_+" = private unnamed_addr constant [2 x i8] c"+\00", align 1
@rubyIdPrecomputed_final = internal unnamed_addr global i64 0, align 8
@str_final = private unnamed_addr constant [6 x i8] c"final\00", align 1
@rubyIdPrecomputed_sig = internal unnamed_addr global i64 0, align 8
@"str_T::Sig::WithoutRuntime" = private unnamed_addr constant [23 x i8] c"T::Sig::WithoutRuntime\00", align 1
@rubyIdPrecomputed_n = internal unnamed_addr global i64 0, align 8
@str_n = private unnamed_addr constant [2 x i8] c"n\00", align 1
@rubyIdPrecomputed_params = internal unnamed_addr global i64 0, align 8
@str_params = private unnamed_addr constant [7 x i8] c"params\00", align 1
@rubyIdPrecomputed_returns = internal unnamed_addr global i64 0, align 8
@str_returns = private unnamed_addr constant [8 x i8] c"returns\00", align 1
@llvm.global_ctors = appending global [11 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<top (required)>", i8* bitcast (i64* @"rubyIdPrecomputed_<top (required)>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_fib, i8* bitcast (i64* @rubyIdPrecomputed_fib to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<", i8* bitcast (i64* @"rubyIdPrecomputed_<" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_-, i8* bitcast (i64* @rubyIdPrecomputed_- to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_+", i8* bitcast (i64* @"rubyIdPrecomputed_+" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_final, i8* bitcast (i64* @rubyIdPrecomputed_final to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_sig, i8* bitcast (i64* @rubyIdPrecomputed_sig to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_n, i8* bitcast (i64* @rubyIdPrecomputed_n to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_params, i8* bitcast (i64* @rubyIdPrecomputed_params to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_returns, i8* bitcast (i64* @rubyIdPrecomputed_returns to i8*) }]
@guard_epoch_HasFib = linkonce local_unnamed_addr global i64 0
@guarded_const_HasFib = linkonce local_unnamed_addr global i64 0
@"guard_epoch_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@"guarded_const_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@rb_cInteger = external local_unnamed_addr constant i64

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i8* @rb_id2name(i64 %0) #19
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #19
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !0
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #19
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !5
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #2

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #1

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #2

declare i64 @rb_str_new(i8*, i64) local_unnamed_addr #1

declare i64 @rb_hash_new() local_unnamed_addr #1

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #1

declare i64 @rb_id2sym(i64) local_unnamed_addr #1

declare i8* @rb_obj_classname(i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstantAt(i64 %0, i64 %1) unnamed_addr #3 {
  %3 = tail call i64 @rb_id2sym(i64 %1) #19
  %4 = tail call %struct.OnigEncodingTypeST* @rb_enc_get(i64 %3) #19
  %5 = tail call i8* @rb_id2name(i64 %1) #19
  %6 = tail call i64 @strlen(i8* nonnull dereferenceable(1) %5)
  %7 = getelementptr inbounds i8, i8* %5, i64 %6
  %8 = icmp sgt i64 %6, 0
  br i1 %8, label %9, label %.loopexit11

9:                                                ; preds = %2
  %10 = ptrtoint i8* %5 to i64
  br label %13

.loopexit10:                                      ; preds = %91, %44, %41, %28, %107
  %11 = phi i64 [ %108, %107 ], [ %3, %28 ], [ %3, %44 ], [ %3, %41 ], [ %66, %91 ]
  %12 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %12, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.1, i64 0, i64 0), i64 %14, i64 %11) #20
  unreachable

13:                                               ; preds = %115, %9
  %14 = phi i64 [ %0, %9 ], [ %116, %115 ]
  %15 = phi i8* [ %5, %9 ], [ %50, %115 ]
  %16 = phi i8* [ %5, %9 ], [ %49, %115 ]
  %17 = icmp ult i8* %16, %7
  br i1 %17, label %18, label %28

18:                                               ; preds = %13
  %19 = load i8, i8* %16, align 1, !tbaa !5
  %20 = icmp eq i8 %19, 58
  br i1 %20, label %28, label %.preheader

21:                                               ; preds = %.preheader
  %22 = load i8, i8* %25, align 1, !tbaa !5
  %23 = icmp eq i8 %22, 58
  br i1 %23, label %.loopexit, label %.preheader

.preheader:                                       ; preds = %18, %21
  %24 = phi i8* [ %25, %21 ], [ %16, %18 ]
  %25 = getelementptr inbounds i8, i8* %24, i64 1
  %26 = icmp eq i8* %25, %7
  br i1 %26, label %.loopexit, label %21

.loopexit:                                        ; preds = %21, %.preheader
  %.lcssa = phi i8* [ %25, %21 ], [ %7, %.preheader ]
  %27 = icmp ult i8* %.lcssa, %7
  br label %28

28:                                               ; preds = %.loopexit, %18, %13
  %29 = phi i8* [ %16, %13 ], [ %16, %18 ], [ %.lcssa, %.loopexit ]
  %30 = phi i1 [ false, %13 ], [ true, %18 ], [ %27, %.loopexit ]
  %31 = icmp eq i8* %15, %29
  br i1 %31, label %.loopexit10, label %32

32:                                               ; preds = %28
  %33 = ptrtoint i8* %29 to i64
  %34 = ptrtoint i8* %15 to i64
  %35 = sub i64 %33, %34
  %36 = tail call i64 @rb_check_id_cstr(i8* %15, i64 %35, %struct.OnigEncodingTypeST* %4) #19
  %37 = sub i64 %34, %10
  br i1 %30, label %38, label %48

38:                                               ; preds = %32
  %39 = load i8, i8* %29, align 1, !tbaa !5
  %40 = icmp eq i8 %39, 58
  br i1 %40, label %41, label %48

41:                                               ; preds = %38
  %42 = getelementptr inbounds i8, i8* %29, i64 2
  %43 = icmp ult i8* %42, %7
  br i1 %43, label %44, label %.loopexit10

44:                                               ; preds = %41
  %45 = getelementptr inbounds i8, i8* %29, i64 1
  %46 = load i8, i8* %45, align 1, !tbaa !5
  %47 = icmp eq i8 %46, 58
  br i1 %47, label %48, label %.loopexit10

48:                                               ; preds = %44, %38, %32
  %49 = phi i8* [ %29, %38 ], [ %29, %32 ], [ %42, %44 ]
  %50 = phi i8* [ %15, %38 ], [ %15, %32 ], [ %42, %44 ]
  %51 = and i64 %14, 7
  %52 = icmp ne i64 %51, 0
  %53 = and i64 %14, -9
  %54 = icmp eq i64 %53, 0
  %55 = or i1 %52, %54
  br i1 %55, label %61, label %56

56:                                               ; preds = %48
  %57 = inttoptr i64 %14 to %struct.RBasic*
  %58 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 0
  %59 = load i64, i64* %58, align 8, !tbaa !0
  %60 = and i64 %59, 30
  %switch = icmp eq i64 %60, 2
  br i1 %switch, label %63, label %61

61:                                               ; preds = %56, %48
  %62 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %62, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.2, i64 0, i64 0), i64 %3) #20
  unreachable

63:                                               ; preds = %56
  %64 = icmp eq i64 %36, 0
  br i1 %64, label %65, label %104

65:                                               ; preds = %63
  %66 = tail call i64 @rb_str_subseq(i64 %3, i64 %37, i64 %35) #19
  %67 = and i64 %66, 7
  %68 = icmp ne i64 %67, 0
  %69 = and i64 %66, -9
  %70 = icmp eq i64 %69, 0
  %71 = or i1 %68, %70
  br i1 %71, label %rb_obj_freeze_inline.exit, label %72

72:                                               ; preds = %65
  %73 = inttoptr i64 %66 to %struct.RBasic*
  %74 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 0
  %75 = load i64, i64* %74, align 8, !tbaa !0
  %76 = and i64 %75, 31
  %77 = icmp eq i64 %76, 27
  br i1 %77, label %rb_obj_freeze_inline.exit, label %78

78:                                               ; preds = %72
  %79 = or i64 %75, 2048
  store i64 %79, i64* %74, align 8, !tbaa !0
  %80 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 1
  %81 = load i64, i64* %80, align 8, !tbaa !7
  %82 = icmp ne i64 %81, 0
  %83 = and i64 %75, 4096
  %84 = icmp eq i64 %83, 0
  %85 = and i1 %84, %82
  br i1 %85, label %86, label %rb_obj_freeze_inline.exit

86:                                               ; preds = %78
  tail call void @rb_freeze_singleton_class(i64 %66) #19
  br label %rb_obj_freeze_inline.exit

rb_obj_freeze_inline.exit:                        ; preds = %65, %72, %78, %86
  %87 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %89, label %91

89:                                               ; preds = %rb_obj_freeze_inline.exit
  %90 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.3, i64 0, i64 0), i64 13) #19
  store i64 %90, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  br label %91

91:                                               ; preds = %89, %rb_obj_freeze_inline.exit
  %92 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %93 = tail call i32 @rb_is_const_name(i64 %66) #19
  %94 = icmp eq i32 %93, 0
  br i1 %94, label %.loopexit10, label %rb_class_of.exit

rb_class_of.exit:                                 ; preds = %91
  %95 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 1
  %96 = load i64, i64* %95, align 8, !tbaa !6
  %97 = tail call i32 @rb_method_basic_definition_p(i64 %96, i64 %92) #19
  %98 = icmp eq i32 %97, 0
  br i1 %98, label %99, label %102

99:                                               ; preds = %rb_class_of.exit
  %100 = tail call i64 @rb_str_intern(i64 %66) #19
  %101 = tail call i64 @rb_const_missing(i64 %14, i64 %100) #19
  br label %115

102:                                              ; preds = %rb_class_of.exit
  %103 = tail call i64 @rb_mod_const_missing(i64 %14, i64 %66) #20
  unreachable

104:                                              ; preds = %63
  %105 = tail call i32 @rb_is_const_id(i64 %36) #6
  %106 = icmp eq i32 %105, 0
  br i1 %106, label %107, label %109

107:                                              ; preds = %104
  %108 = tail call i64 @rb_id2sym(i64 %36) #19
  br label %.loopexit10

109:                                              ; preds = %104
  %110 = icmp eq i64 %37, 0
  br i1 %110, label %111, label %113

111:                                              ; preds = %109
  %112 = tail call i64 @rb_const_get(i64 %14, i64 %36) #19
  br label %115

113:                                              ; preds = %109
  %114 = tail call i64 @rb_const_get_from(i64 %14, i64 %36) #19
  br label %115

115:                                              ; preds = %113, %111, %99
  %116 = phi i64 [ %101, %99 ], [ %112, %111 ], [ %114, %113 ]
  %117 = icmp ult i8* %49, %7
  br i1 %117, label %13, label %.loopexit11

.loopexit11:                                      ; preds = %115, %2
  %118 = phi i64 [ %0, %2 ], [ %116, %115 ]
  ret i64 %118
}

declare %struct.OnigEncodingTypeST* @rb_enc_get(i64) local_unnamed_addr #1

; Function Attrs: argmemonly nofree nounwind readonly
declare i64 @strlen(i8* nocapture) local_unnamed_addr #4

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #5

declare i64 @rb_check_id_cstr(i8*, i64, %struct.OnigEncodingTypeST*) local_unnamed_addr #1

declare i64 @rb_str_subseq(i64, i64, i64) local_unnamed_addr #1

declare i32 @rb_is_const_name(i64) local_unnamed_addr #1

declare i32 @rb_method_basic_definition_p(i64, i64) local_unnamed_addr #1

declare i64 @rb_str_intern(i64) local_unnamed_addr #1

declare i64 @rb_const_missing(i64, i64) local_unnamed_addr #1

; Function Attrs: noreturn
declare i64 @rb_mod_const_missing(i64, i64) local_unnamed_addr #5

; Function Attrs: nounwind readnone
declare i32 @rb_is_const_id(i64) local_unnamed_addr #6

declare i64 @rb_const_get(i64, i64) local_unnamed_addr #1

declare i64 @rb_const_get_from(i64, i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstant(i8* %0, i64 %1) unnamed_addr #3 {
  %3 = load i64, i64* @rb_cObject, align 8, !tbaa !6
  %4 = tail call i64 @rb_intern2(i8* %0, i64 %1) #19
  %5 = tail call fastcc i64 @sorbet_getConstantAt(i64 %3, i64 %4)
  ret i64 %5
}

declare i64 @rb_define_class(i8*, i64) local_unnamed_addr #1

declare void @rb_define_singleton_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #1

declare i64 @rb_funcallv(i64, i64, i32, i64*) local_unnamed_addr #1

declare i64 @rb_block_call(i64, i64, i32, i64*, i64 (...)*, i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32 %0) unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.4, i64 0, i64 0), i32 %0, i32 1) #19
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !6
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #19
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #1

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64 %0, i8* %1, i8* %2) unnamed_addr #7 {
  %4 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  %5 = tail call i8* @rb_obj_classname(i64 %0) #19
  tail call void (i64, i8*, ...) @rb_raise(i64 %4, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.7, i64 0, i64 0), i8* %1, i8* %2, i8* %5, i64 %0) #20
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_raiseArity(i32 %0) unnamed_addr #8 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #20
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #5

; Function Attrs: inaccessiblememonly
declare i32 @ruby_stack_check() local_unnamed_addr #9

declare i8* @ruby_xmalloc(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8* %0) #0 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #19
  ret void
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #1

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly %0) #10 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

declare i64 @rb_data_typed_object_wrap(i64, i8*, %struct.rb_data_type_struct*) local_unnamed_addr #1

declare %struct.rb_iseq_struct* @rb_iseq_new_with_opt(%struct.rb_ast_body_struct*, i64, i64, i64, i64, %struct.rb_iseq_struct*, i32, %struct.rb_compile_option_struct*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #6

; Function Attrs: nounwind readnone
declare i64 @rb_class_inherited_p(i64, i64) local_unnamed_addr #6

declare void @rb_hash_bulk_insert(i64, i64*, i64) local_unnamed_addr #1

declare i64 @rb_big_plus(i64, i64) local_unnamed_addr #1

declare i64 @rb_complex_plus(i64, i64) local_unnamed_addr #1

declare i64 @rb_num_coerce_bin(i64, i64, i64) local_unnamed_addr #1

declare i64 @rb_int2big(i64) local_unnamed_addr #1

declare i64 @rb_big_minus(i64, i64) local_unnamed_addr #1

declare i64 @rb_float_new_in_heap(double) local_unnamed_addr #1

declare void @rb_ary_detransient(i64) local_unnamed_addr #1

declare void @rb_freeze_singleton_class(i64) local_unnamed_addr #1

; Function Attrs: nounwind readnone speculatable willreturn
declare { i64, i1 } @llvm.sadd.with.overflow.i64(i64, i64) #11

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<top (required)>"() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #19
  store i64 %0, i64* @"rubyIdPrecomputed_<top (required)>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #19
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_fib() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_fib, i64 0, i64 0), i64 3) #19
  store i64 %0, i64* @rubyIdPrecomputed_fib, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_ruby_benchmark_app_fib() local_unnamed_addr #13 {
afterSymCallIntrinsic_unsafe.i:
  %0 = alloca i64, align 8
  %callArgs.i.i.i = alloca [2 x i64], align 8
  %1 = alloca i64, align 8
  %callArgs.i = alloca [1 x i64], align 8
  %2 = load i64, i64* @rb_cObject, align 8
  %3 = bitcast [1 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %3)
  %rubyId_fib.i = load i64, i64* @rubyIdPrecomputed_fib, align 8
  %4 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #19
  %5 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([40 x i8], [40 x i8]* @"str_test/testdata/ruby_benchmark/app_fib.rb", i64 0, i64 0), i64 39) #19
  %6 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([40 x i8], [40 x i8]* @"str_test/testdata/ruby_benchmark/app_fib.rb", i64 0, i64 0), i64 39) #19
  %7 = bitcast i64* %1 to %struct.rb_compile_option_struct*
  %8 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !10
  %9 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %8, i64 0, i32 2
  %10 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %9, align 8, !tbaa !12
  %11 = bitcast i64* %1 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %11) #19
  store i64 0, i64* %1, align 8
  %12 = call %struct.rb_iseq_struct* @rb_iseq_new_with_opt(%struct.rb_ast_body_struct* null, i64 %4, i64 %5, i64 %6, i64 7, %struct.rb_iseq_struct* null, i32 0, %struct.rb_compile_option_struct* nonnull %7) #19
  %13 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %12, i64 0, i32 2
  %14 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %13, align 8, !tbaa !15
  %15 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %14, i64 0, i32 2
  %16 = bitcast i64** %15 to i64*
  %17 = load i64, i64* %16, align 8, !tbaa !17
  %18 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %10, i64 0, i32 2
  store %struct.rb_iseq_struct* %12, %struct.rb_iseq_struct** %18, align 8, !tbaa !26
  %19 = bitcast %struct.rb_control_frame_struct* %10 to i64*
  store i64 %17, i64* %19, align 8, !tbaa !28
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %11) #19
  %callArgsAddr.i = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs.i, i64 0, i64 0
  store i64 %2, i64* %callArgsAddr.i, align 8
  %20 = call i64 @rb_define_class(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib, i64 0, i64 0), i64 %2) #19
  %21 = load i64, i64* @guard_epoch_HasFib, align 8
  %22 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  %needTakeSlowPath = icmp eq i64 %21, %22
  br i1 %needTakeSlowPath, label %24, label %23, !prof !31

23:                                               ; preds = %afterSymCallIntrinsic_unsafe.i
  call void @const_recompute_HasFib() #19
  br label %24

24:                                               ; preds = %afterSymCallIntrinsic_unsafe.i, %23
  %25 = load i64, i64* @guarded_const_HasFib, align 8
  %26 = load i64, i64* @guard_epoch_HasFib, align 8
  %27 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  %guardUpdated = icmp eq i64 %26, %27
  call void @llvm.assume(i1 %guardUpdated)
  %28 = bitcast [2 x i64]* %callArgs.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %28) #19
  %29 = call i8* @ruby_xmalloc(i64 16) #19
  %30 = bitcast i8* %29 to i32*
  store i32 1, i32* %30, align 8, !tbaa !8
  %31 = load i64, i64* @rb_cData, align 8, !tbaa !6
  %32 = call i64 @rb_data_typed_object_wrap(i64 %31, i8* %29, %struct.rb_data_type_struct* nonnull @closureInfo) #19
  %33 = inttoptr i64 %32 to %struct.RTypedData*
  %34 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %33, i64 0, i32 3
  %35 = bitcast i8** %34 to %struct.sorbet_Closure**
  %36 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %35, align 8, !tbaa !32
  %37 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %36, i64 0, i32 1, i64 0
  store i64 8, i64* %37, align 8
  %rubyId_final.i.i.i = load i64, i64* @rubyIdPrecomputed_final, align 8
  %rubyId_sig.i.i.i = load i64, i64* @rubyIdPrecomputed_sig, align 8
  %rubyId_fib.i.i.i = load i64, i64* @rubyIdPrecomputed_fib, align 8
  %38 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %35, align 8, !tbaa !32
  %39 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %38, i64 0, i32 1, i64 0
  store i64 %25, i64* %39, align 8
  %40 = call i64 @rb_str_new(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @"str_<top (required)>", i64 0, i64 0), i64 16) #19
  %41 = call i64 @rb_str_new(i8* getelementptr inbounds ([40 x i8], [40 x i8]* @"str_test/testdata/ruby_benchmark/app_fib.rb", i64 0, i64 0), i64 39) #19
  %42 = call i64 @rb_str_new(i8* getelementptr inbounds ([40 x i8], [40 x i8]* @"str_test/testdata/ruby_benchmark/app_fib.rb", i64 0, i64 0), i64 39) #19
  %43 = bitcast i64* %0 to %struct.rb_compile_option_struct*
  %44 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !10
  %45 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %44, i64 0, i32 2
  %46 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %45, align 8, !tbaa !12
  %47 = bitcast i64* %0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %47) #19
  store i64 0, i64* %0, align 8
  %48 = call %struct.rb_iseq_struct* @rb_iseq_new_with_opt(%struct.rb_ast_body_struct* null, i64 %40, i64 %41, i64 %42, i64 7, %struct.rb_iseq_struct* null, i32 0, %struct.rb_compile_option_struct* nonnull %43) #19
  %49 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %48, i64 0, i32 2
  %50 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %49, align 8, !tbaa !15
  %51 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %50, i64 0, i32 2
  %52 = bitcast i64** %51 to i64*
  %53 = load i64, i64* %52, align 8, !tbaa !17
  %54 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %46, i64 0, i32 2
  store %struct.rb_iseq_struct* %48, %struct.rb_iseq_struct** %54, align 8, !tbaa !26
  %55 = bitcast %struct.rb_control_frame_struct* %46 to i64*
  store i64 %53, i64* %55, align 8, !tbaa !28
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %47) #19
  %56 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %35, align 8, !tbaa !32
  %57 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %56, i64 0, i32 1, i64 0
  %58 = load i64, i64* %57, align 8
  %59 = icmp eq i64 %58, %25
  br i1 %59, label %"func_<root>.<static-init>$111.exit", label %60

60:                                               ; preds = %24
  %61 = load i64, i64* @rb_cModule, align 8, !tbaa !6
  %62 = call i64 @rb_obj_is_kind_of(i64 %58, i64 %61) #6
  %63 = icmp eq i64 %62, 0
  br i1 %63, label %codeRepl, label %sorbet_isa_class_of.exit.i.i.i, !prof !34

sorbet_isa_class_of.exit.i.i.i:                   ; preds = %60
  %64 = call i64 @rb_class_inherited_p(i64 %58, i64 %25) #6
  %65 = icmp eq i64 %64, 0
  br i1 %65, label %codeRepl, label %"func_<root>.<static-init>$111.exit", !prof !35, !misexpect !36

codeRepl:                                         ; preds = %60, %sorbet_isa_class_of.exit.i.i.i
  call fastcc void @Init_test_testdata_ruby_benchmark_app_fib.cold.1(i64 %58) #21
  unreachable

"func_<root>.<static-init>$111.exit":             ; preds = %24, %sorbet_isa_class_of.exit.i.i.i
  %rawSym.i.i.i = call i64 @rb_id2sym(i64 %rubyId_final.i.i.i) #19
  %callArgsAddr.i.i.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i.i.i, i64 0, i64 0
  store i64 %rawSym.i.i.i, i64* %callArgsAddr.i.i.i, align 8
  %66 = load i64, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  %67 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  %needTakeSlowPath6 = icmp eq i64 %66, %67
  br i1 %needTakeSlowPath6, label %69, label %68, !prof !31

68:                                               ; preds = %"func_<root>.<static-init>$111.exit"
  call void @"const_recompute_T::Sig::WithoutRuntime"() #19
  br label %69

69:                                               ; preds = %"func_<root>.<static-init>$111.exit", %68
  %70 = load i64, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  %71 = load i64, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  %72 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  %guardUpdated7 = icmp eq i64 %71, %72
  call void @llvm.assume(i1 %guardUpdated7)
  %73 = call i64 @rb_block_call(i64 %70, i64 %rubyId_sig.i.i.i, i32 1, i64* nonnull %callArgsAddr.i.i.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_HasFib.<static-init>$block_1" to i64 (...)*), i64 %32) #19
  store i64 %2, i64* %callArgsAddr.i.i.i, align 8
  %rawSym45.i.i.i = call i64 @rb_id2sym(i64 %rubyId_fib.i.i.i) #19
  call void @rb_define_singleton_method(i64 %25, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_fib, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @func_HasFib.fib to i64 (...)*), i32 -1) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %28) #19
  store i64 69, i64* %callArgsAddr.i, align 8
  %74 = call i64 @rb_funcallv(i64 %25, i64 %rubyId_fib.i, i32 1, i64* nonnull %callArgsAddr.i) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %3)
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @func_HasFib.fib(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #14 {
functionEntryInitializers:
  %0 = alloca i64, align 8
  %callArgs = alloca [1 x i64], align 8
  %"rubyId_+" = load i64, i64* @"rubyIdPrecomputed_+", align 8
  %1 = icmp eq i32 %argc, 1
  br i1 %1, label %fillRequiredArgs, label %argCountFailBlock, !prof !37, !misexpect !38

BB3:                                              ; preds = %sorbet_rb_int_lt.exit
  %2 = and i64 %rawArg_n, 1
  %3 = icmp eq i64 %2, 0
  br i1 %3, label %12, label %4, !prof !35

4:                                                ; preds = %BB3
  %5 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %rawArg_n, i64 -2)
  %6 = extractvalue { i64, i1 } %5, 1
  %7 = extractvalue { i64, i1 } %5, 0
  br i1 %6, label %8, label %sorbet_rb_int_minus.exit

8:                                                ; preds = %4
  %9 = ashr i64 %7, 1
  %10 = xor i64 %9, -9223372036854775808
  %11 = call i64 @rb_int2big(i64 %10) #19
  br label %sorbet_rb_int_minus.exit

12:                                               ; preds = %BB3
  %13 = and i64 %rawArg_n, 7
  %14 = icmp ne i64 %13, 0
  %15 = and i64 %rawArg_n, -9
  %16 = icmp eq i64 %15, 0
  %17 = or i1 %14, %16
  br i1 %17, label %26, label %18

18:                                               ; preds = %12
  %19 = inttoptr i64 %rawArg_n to %struct.RBasic*
  %20 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %19, i64 0, i32 0
  %21 = load i64, i64* %20, align 8, !tbaa !0
  %22 = and i64 %21, 31
  %23 = icmp eq i64 %22, 10
  br i1 %23, label %24, label %26

24:                                               ; preds = %18
  %25 = call i64 @rb_big_minus(i64 %rawArg_n, i64 3) #19
  br label %sorbet_rb_int_minus.exit

26:                                               ; preds = %18, %12
  %27 = call i64 @rb_num_coerce_bin(i64 %rawArg_n, i64 3, i64 45) #19
  br label %sorbet_rb_int_minus.exit

sorbet_rb_int_minus.exit:                         ; preds = %4, %8, %24, %26
  %28 = phi i64 [ %27, %26 ], [ %25, %24 ], [ %11, %8 ], [ %7, %4 ]
  store i64 %28, i64* %callArgsAddr, align 8
  %29 = call i32 @ruby_stack_check() #19
  %directSendResult = call i64 @func_HasFib.fib(i32 1, i64* nonnull %callArgsAddr, i64 %selfRaw)
  %30 = and i64 %rawArg_n, 1
  %31 = icmp eq i64 %30, 0
  br i1 %31, label %40, label %32, !prof !35

32:                                               ; preds = %sorbet_rb_int_minus.exit
  %33 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %rawArg_n, i64 -4)
  %34 = extractvalue { i64, i1 } %33, 1
  %35 = extractvalue { i64, i1 } %33, 0
  br i1 %34, label %36, label %sorbet_rb_int_minus.exit134

36:                                               ; preds = %32
  %37 = ashr i64 %35, 1
  %38 = xor i64 %37, -9223372036854775808
  %39 = call i64 @rb_int2big(i64 %38) #19
  br label %sorbet_rb_int_minus.exit134

40:                                               ; preds = %sorbet_rb_int_minus.exit
  %41 = and i64 %rawArg_n, 7
  %42 = icmp ne i64 %41, 0
  %43 = and i64 %rawArg_n, -9
  %44 = icmp eq i64 %43, 0
  %45 = or i1 %42, %44
  br i1 %45, label %54, label %46

46:                                               ; preds = %40
  %47 = inttoptr i64 %rawArg_n to %struct.RBasic*
  %48 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %47, i64 0, i32 0
  %49 = load i64, i64* %48, align 8, !tbaa !0
  %50 = and i64 %49, 31
  %51 = icmp eq i64 %50, 10
  br i1 %51, label %52, label %54

52:                                               ; preds = %46
  %53 = call i64 @rb_big_minus(i64 %rawArg_n, i64 5) #19
  br label %sorbet_rb_int_minus.exit134

54:                                               ; preds = %46, %40
  %55 = call i64 @rb_num_coerce_bin(i64 %rawArg_n, i64 5, i64 45) #19
  br label %sorbet_rb_int_minus.exit134

sorbet_rb_int_minus.exit134:                      ; preds = %32, %36, %52, %54
  %56 = phi i64 [ %55, %54 ], [ %53, %52 ], [ %39, %36 ], [ %35, %32 ]
  store i64 %56, i64* %callArgsAddr, align 8
  %57 = call i32 @ruby_stack_check() #19
  %directSendResult88 = call i64 @func_HasFib.fib(i32 1, i64* nonnull %callArgsAddr, i64 %selfRaw)
  %58 = and i64 %directSendResult, 1
  %59 = icmp eq i64 %58, 0
  store i64 %directSendResult88, i64* %callArgsAddr, align 8
  br i1 %59, label %"slowSymCallIntrinsic_+", label %"fastSymCallIntrinsic_+", !prof !35, !misexpect !36

BB4:                                              ; preds = %183, %181, %172, %170, %164, %117, %101, %96, %sorbet_rb_int_lt.exit, %"slowSymCallIntrinsic_+"
  %"<returnMethodTemp>.sroa.0.0" = phi i64 [ %93, %"slowSymCallIntrinsic_+" ], [ 3, %sorbet_rb_int_lt.exit ], [ %184, %183 ], [ %182, %181 ], [ %118, %117 ], [ %104, %101 ], [ %100, %96 ], [ %173, %172 ], [ %169, %164 ], [ -9223372036854775806, %170 ]
  ret i64 %"<returnMethodTemp>.sroa.0.0"

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %rawArg_n = load i64, i64* %argArray, align 8
  %60 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_fib, i64 0, i64 0), i64 3) #19
  %61 = load i64, i64* @guard_epoch_HasFib, align 8
  %62 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  %needTakeSlowPath = icmp eq i64 %61, %62
  br i1 %needTakeSlowPath, label %64, label %63, !prof !31

63:                                               ; preds = %fillRequiredArgs
  tail call void @const_recompute_HasFib() #19
  br label %64

64:                                               ; preds = %fillRequiredArgs, %63
  %65 = load i64, i64* @guarded_const_HasFib, align 8
  %66 = load i64, i64* @guard_epoch_HasFib, align 8
  %67 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  %guardUpdated = icmp eq i64 %66, %67
  tail call void @llvm.assume(i1 %guardUpdated)
  %68 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([40 x i8], [40 x i8]* @"str_test/testdata/ruby_benchmark/app_fib.rb", i64 0, i64 0), i64 39) #19
  %69 = tail call i64 @rb_str_new(i8* getelementptr inbounds ([40 x i8], [40 x i8]* @"str_test/testdata/ruby_benchmark/app_fib.rb", i64 0, i64 0), i64 39) #19
  %70 = bitcast i64* %0 to %struct.rb_compile_option_struct*
  %71 = load %struct.rb_execution_context_struct*, %struct.rb_execution_context_struct** @ruby_current_execution_context_ptr, align 8, !tbaa !10
  %72 = getelementptr inbounds %struct.rb_execution_context_struct, %struct.rb_execution_context_struct* %71, i64 0, i32 2
  %73 = load %struct.rb_control_frame_struct*, %struct.rb_control_frame_struct** %72, align 8, !tbaa !12
  %74 = bitcast i64* %0 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %74) #19
  store i64 0, i64* %0, align 8
  %75 = call %struct.rb_iseq_struct* @rb_iseq_new_with_opt(%struct.rb_ast_body_struct* null, i64 %60, i64 %68, i64 %69, i64 11, %struct.rb_iseq_struct* null, i32 0, %struct.rb_compile_option_struct* nonnull %70) #19
  %76 = getelementptr inbounds %struct.rb_iseq_struct, %struct.rb_iseq_struct* %75, i64 0, i32 2
  %77 = load %struct.rb_iseq_constant_body*, %struct.rb_iseq_constant_body** %76, align 8, !tbaa !15
  %78 = getelementptr inbounds %struct.rb_iseq_constant_body, %struct.rb_iseq_constant_body* %77, i64 0, i32 2
  %79 = bitcast i64** %78 to i64*
  %80 = load i64, i64* %79, align 8, !tbaa !17
  %81 = getelementptr inbounds %struct.rb_control_frame_struct, %struct.rb_control_frame_struct* %73, i64 0, i32 2
  store %struct.rb_iseq_struct* %75, %struct.rb_iseq_struct** %81, align 8, !tbaa !26
  %82 = bitcast %struct.rb_control_frame_struct* %73 to i64*
  store i64 %80, i64* %82, align 8, !tbaa !28
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %74) #19
  %83 = and i64 %rawArg_n, 1
  %84 = icmp eq i64 %83, 0
  br i1 %84, label %codeRepl, label %typeTestSuccess23, !prof !35, !misexpect !36

codeRepl:                                         ; preds = %64
  call fastcc void @func_HasFib.fib.cold.1(i64 %rawArg_n) #21
  unreachable

typeTestSuccess23:                                ; preds = %64
  %85 = icmp eq i64 %65, %selfRaw
  br i1 %85, label %sorbet_rb_int_lt.exit, label %86

86:                                               ; preds = %typeTestSuccess23
  %87 = load i64, i64* @rb_cModule, align 8, !tbaa !6
  %88 = call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %87) #6
  %89 = icmp eq i64 %88, 0
  br i1 %89, label %codeRepl130, label %sorbet_isa_class_of.exit, !prof !34

sorbet_isa_class_of.exit:                         ; preds = %86
  %90 = call i64 @rb_class_inherited_p(i64 %selfRaw, i64 %65) #6
  %91 = icmp eq i64 %90, 0
  br i1 %91, label %codeRepl130, label %sorbet_rb_int_lt.exit, !prof !35, !misexpect !36

sorbet_rb_int_lt.exit:                            ; preds = %sorbet_isa_class_of.exit, %typeTestSuccess23
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  store i64 7, i64* %callArgsAddr, align 8
  %92 = icmp slt i64 %rawArg_n, 6
  br i1 %92, label %BB4, label %BB3

codeRepl130:                                      ; preds = %86, %sorbet_isa_class_of.exit
  call fastcc void @func_HasFib.fib.cold.2(i64 %selfRaw) #21
  unreachable

"slowSymCallIntrinsic_+":                         ; preds = %sorbet_rb_int_minus.exit134
  %93 = call i64 @rb_funcallv(i64 %directSendResult, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #19
  br label %BB4

"fastSymCallIntrinsic_+":                         ; preds = %sorbet_rb_int_minus.exit134
  %94 = and i64 %directSendResult88, 1
  %95 = icmp eq i64 %94, 0
  br i1 %95, label %105, label %96, !prof !35

96:                                               ; preds = %"fastSymCallIntrinsic_+"
  %97 = add nsw i64 %directSendResult88, -1
  %98 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %directSendResult, i64 %97) #19
  %99 = extractvalue { i64, i1 } %98, 1
  %100 = extractvalue { i64, i1 } %98, 0
  br i1 %99, label %101, label %BB4

101:                                              ; preds = %96
  %102 = ashr i64 %100, 1
  %103 = xor i64 %102, -9223372036854775808
  %104 = call i64 @rb_int2big(i64 %103) #19, !noalias !39
  br label %BB4

105:                                              ; preds = %"fastSymCallIntrinsic_+"
  %106 = and i64 %directSendResult88, 7
  %107 = icmp ne i64 %106, 0
  %108 = and i64 %directSendResult88, -9
  %109 = icmp eq i64 %108, 0
  %110 = or i1 %107, %109
  br i1 %110, label %119, label %111

111:                                              ; preds = %105
  %112 = inttoptr i64 %directSendResult88 to %struct.RBasic*
  %113 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %112, i64 0, i32 0
  %114 = load i64, i64* %113, align 8, !tbaa !0, !noalias !39
  %115 = and i64 %114, 31
  %116 = icmp eq i64 %115, 10
  br i1 %116, label %117, label %119

117:                                              ; preds = %111
  %118 = call i64 @rb_big_plus(i64 %directSendResult88, i64 %directSendResult) #19, !noalias !39
  br label %BB4

119:                                              ; preds = %111, %105
  %120 = and i64 %directSendResult, 3
  %121 = icmp eq i64 %120, 2
  br i1 %121, label %134, label %122

122:                                              ; preds = %119
  %123 = and i64 %directSendResult, 7
  %124 = icmp ne i64 %123, 0
  %125 = and i64 %directSendResult, -9
  %126 = icmp eq i64 %125, 0
  %127 = or i1 %124, %126
  br i1 %127, label %174, label %128

128:                                              ; preds = %122
  %129 = inttoptr i64 %directSendResult to %struct.RBasic*
  %130 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %129, i64 0, i32 0
  %131 = load i64, i64* %130, align 8, !tbaa !0, !noalias !39
  %132 = and i64 %131, 31
  %133 = icmp eq i64 %132, 4
  br i1 %133, label %134, label %174

134:                                              ; preds = %128, %119
  %135 = ashr i64 %directSendResult, 1
  %136 = sitofp i64 %135 to double
  %137 = and i64 %directSendResult88, 3
  %138 = icmp eq i64 %137, 2
  br i1 %138, label %139, label %150

139:                                              ; preds = %134
  %140 = icmp eq i64 %directSendResult88, -9223372036854775806
  br i1 %140, label %rb_float_value_inline.exit.i, label %141

141:                                              ; preds = %139
  %142 = lshr i64 %directSendResult88, 63
  %143 = sub nuw nsw i64 2, %142
  %144 = and i64 %directSendResult88, 4
  %145 = or i64 %143, %144
  %146 = lshr i64 %directSendResult88, 3
  %147 = shl nuw i64 %145, 61
  %148 = or i64 %147, %146
  %149 = bitcast i64 %148 to double
  br label %rb_float_value_inline.exit.i

150:                                              ; preds = %134
  %151 = inttoptr i64 %directSendResult88 to %struct.RFloat*
  %152 = getelementptr inbounds %struct.RFloat, %struct.RFloat* %151, i64 0, i32 1
  %153 = load double, double* %152, align 8, !tbaa !42, !noalias !39
  br label %rb_float_value_inline.exit.i

rb_float_value_inline.exit.i:                     ; preds = %150, %141, %139
  %154 = phi double [ %153, %150 ], [ %149, %141 ], [ 0.000000e+00, %139 ]
  %155 = fadd double %154, %136
  %156 = bitcast double %155 to i64
  %157 = icmp eq i64 %156, 3458764513820540928
  br i1 %157, label %172, label %158

158:                                              ; preds = %rb_float_value_inline.exit.i
  %159 = lshr i64 %156, 60
  %160 = trunc i64 %159 to i32
  %161 = and i32 %160, 7
  %162 = add nsw i32 %161, -3
  %163 = icmp ugt i32 %162, 1
  br i1 %163, label %170, label %164

164:                                              ; preds = %158
  %165 = shl i64 %156, 3
  %166 = lshr i64 %156, 61
  %167 = and i64 %166, 4
  %168 = or i64 %165, %167
  %169 = or i64 %168, 2
  br label %BB4

170:                                              ; preds = %158
  %171 = icmp eq i64 %156, 0
  br i1 %171, label %BB4, label %172

172:                                              ; preds = %170, %rb_float_value_inline.exit.i
  %173 = call i64 @rb_float_new_in_heap(double %155) #19, !noalias !39
  br label %BB4

174:                                              ; preds = %128, %122
  br i1 %110, label %183, label %175

175:                                              ; preds = %174
  %176 = inttoptr i64 %directSendResult88 to %struct.RBasic*
  %177 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %176, i64 0, i32 0
  %178 = load i64, i64* %177, align 8, !tbaa !0, !noalias !39
  %179 = and i64 %178, 31
  %180 = icmp eq i64 %179, 14
  br i1 %180, label %181, label %183

181:                                              ; preds = %175
  %182 = call i64 @rb_complex_plus(i64 %directSendResult88, i64 %directSendResult) #19, !noalias !39
  br label %BB4

183:                                              ; preds = %175, %174
  %184 = call i64 @rb_num_coerce_bin(i64 %directSendResult, i64 %directSendResult88, i64 43) #19, !noalias !39
  br label %BB4
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<"() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_<", i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @"rubyIdPrecomputed_<", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_-() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_-, i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @rubyIdPrecomputed_-, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_+"() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_+", i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @"rubyIdPrecomputed_+", align 8
  ret void
}

; Function Attrs: ssp
define internal i64 @"func_HasFib.<static-init>$block_1"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readonly %argArray, i64 %blockArg) #15 {
functionEntryInitializers:
  %callArgs = alloca [2 x i64], align 8
  %rubyId_n = load i64, i64* @rubyIdPrecomputed_n, align 8
  %rubyId_params = load i64, i64* @rubyIdPrecomputed_params, align 8
  %rubyId_returns = load i64, i64* @rubyIdPrecomputed_returns, align 8
  %arrayExpansionSizeGuard = icmp eq i32 %argc, 1
  br i1 %arrayExpansionSizeGuard, label %argArrayExpandArrayTest, label %fillRequiredArgs

argArrayExpandArrayTest:                          ; preds = %functionEntryInitializers
  %arg1_maybeExpandToFullArgs = load i64, i64* %argArray, align 8
  %0 = and i64 %arg1_maybeExpandToFullArgs, 7
  %1 = icmp ne i64 %0, 0
  %2 = and i64 %arg1_maybeExpandToFullArgs, -9
  %3 = icmp eq i64 %2, 0
  %4 = or i1 %1, %3
  br i1 %4, label %fillRequiredArgs, label %sorbet_isa_Array.exit

sorbet_isa_Array.exit:                            ; preds = %argArrayExpandArrayTest
  %5 = inttoptr i64 %arg1_maybeExpandToFullArgs to %struct.RBasic*
  %6 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %5, i64 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !0
  %8 = and i64 %7, 33554463
  %9 = icmp eq i64 %8, 33554439
  br i1 %9, label %10, label %fillRequiredArgs

10:                                               ; preds = %sorbet_isa_Array.exit
  tail call void @rb_ary_detransient(i64 %arg1_maybeExpandToFullArgs) #19
  br label %fillRequiredArgs

fillRequiredArgs:                                 ; preds = %sorbet_isa_Array.exit, %argArrayExpandArrayTest, %10, %functionEntryInitializers
  %rawSym = tail call i64 @rb_id2sym(i64 %rubyId_n)
  %callArgsAddr = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 0
  store i64 %rawSym, i64* %callArgsAddr, align 8
  %11 = load i64, i64* @rb_cInteger, align 8
  %callArgsAddr15 = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 1
  store i64 %11, i64* %callArgsAddr15, align 8
  %12 = tail call i64 @rb_hash_new() #19, !noalias !45
  call void @rb_hash_bulk_insert(i64 2, i64* nonnull %callArgsAddr, i64 %12) #19
  store i64 %12, i64* %callArgsAddr, align 8
  %13 = inttoptr i64 %captures to %struct.RTypedData*
  %14 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %13, i64 0, i32 3
  %15 = bitcast i8** %14 to %struct.sorbet_Closure**
  %16 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %15, align 8, !tbaa !32
  %17 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %16, i64 0, i32 1, i64 0
  %18 = load i64, i64* %17, align 8
  %19 = call i64 @rb_funcallv(i64 %18, i64 %rubyId_params, i32 1, i64* nonnull %callArgsAddr) #19
  store i64 %11, i64* %callArgsAddr, align 8
  %20 = call i64 @rb_funcallv(i64 %19, i64 %rubyId_returns, i32 1, i64* nonnull %callArgsAddr) #19
  ret i64 %20
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_final() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_final, i64 0, i64 0), i64 5) #19
  store i64 %0, i64* @rubyIdPrecomputed_final, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_sig() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i64 3) #19
  store i64 %0, i64* @rubyIdPrecomputed_sig, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_n() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_n, i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @rubyIdPrecomputed_n, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_params() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_params, i64 0, i64 0), i64 6) #19
  store i64 %0, i64* @rubyIdPrecomputed_params, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_returns() #12 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_returns, i64 0, i64 0), i64 7) #19
  store i64 %0, i64* @rubyIdPrecomputed_returns, align 8
  ret void
}

; Function Attrs: cold minsize noreturn nounwind sspreq
define internal fastcc void @Init_test_testdata_ruby_benchmark_app_fib.cold.1(i64 %0) unnamed_addr #16 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(HasFib)", i64 0, i64 0)) #19
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_HasFib.fib.cold.1(i64 %rawArg_n) unnamed_addr #17 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %rawArg_n, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_Integer, i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_HasFib.fib.cold.2(i64 %selfRaw) unnamed_addr #17 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(HasFib)", i64 0, i64 0))
  unreachable
}

; Function Attrs: nounwind willreturn
declare void @llvm.assume(i1) #18

; Function Attrs: ssp
define linkonce void @const_recompute_HasFib() local_unnamed_addr #15 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib, i64 0, i64 0), i64 6)
  store i64 %1, i64* @guarded_const_HasFib, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  store i64 %2, i64* @guard_epoch_HasFib, align 8
  ret void
}

; Function Attrs: ssp
define linkonce void @"const_recompute_T::Sig::WithoutRuntime"() local_unnamed_addr #15 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([23 x i8], [23 x i8]* @"str_T::Sig::WithoutRuntime", i64 0, i64 0), i64 22)
  store i64 %1, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !29
  store i64 %2, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  ret void
}

attributes #0 = { nounwind ssp uwtable }
attributes #1 = { "addedToSilenceEmptyAttrsError" }
attributes #2 = { argmemonly nounwind willreturn }
attributes #3 = { noinline nounwind ssp uwtable }
attributes #4 = { argmemonly nofree nounwind readonly }
attributes #5 = { noreturn }
attributes #6 = { nounwind readnone }
attributes #7 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #8 = { noreturn nounwind ssp uwtable }
attributes #9 = { inaccessiblememonly "addedToSilenceEmptyAttrsError" }
attributes #10 = { norecurse nounwind readnone ssp uwtable }
attributes #11 = { nounwind readnone speculatable willreturn }
attributes #12 = { nounwind ssp }
attributes #13 = { nounwind sspreq }
attributes #14 = { nounwind sspreq uwtable }
attributes #15 = { ssp }
attributes #16 = { cold minsize noreturn nounwind sspreq }
attributes #17 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #18 = { nounwind willreturn }
attributes #19 = { nounwind }
attributes #20 = { noreturn nounwind }
attributes #21 = { noinline }

!0 = !{!1, !2, i64 0}
!1 = !{!"RBasic", !2, i64 0, !2, i64 8}
!2 = !{!"long", !3, i64 0}
!3 = !{!"omnipotent char", !4, i64 0}
!4 = !{!"Simple C/C++ TBAA"}
!5 = !{!3, !3, i64 0}
!6 = !{!2, !2, i64 0}
!7 = !{!1, !2, i64 8}
!8 = !{!9, !9, i64 0}
!9 = !{!"int", !3, i64 0}
!10 = !{!11, !11, i64 0}
!11 = !{!"any pointer", !3, i64 0}
!12 = !{!13, !11, i64 16}
!13 = !{!"rb_execution_context_struct", !11, i64 0, !2, i64 8, !11, i64 16, !11, i64 24, !11, i64 32, !9, i64 40, !9, i64 44, !11, i64 48, !11, i64 56, !11, i64 64, !2, i64 72, !2, i64 80, !11, i64 88, !2, i64 96, !11, i64 104, !11, i64 112, !2, i64 120, !2, i64 128, !3, i64 136, !3, i64 137, !2, i64 144, !14, i64 152}
!14 = !{!"", !11, i64 0, !11, i64 8, !2, i64 16, !3, i64 24}
!15 = !{!16, !11, i64 16}
!16 = !{!"rb_iseq_struct", !2, i64 0, !2, i64 8, !11, i64 16, !3, i64 24}
!17 = !{!18, !11, i64 8}
!18 = !{!"rb_iseq_constant_body", !3, i64 0, !9, i64 4, !11, i64 8, !19, i64 16, !21, i64 64, !24, i64 120, !11, i64 152, !11, i64 160, !11, i64 168, !11, i64 176, !11, i64 184, !11, i64 192, !11, i64 200, !25, i64 208, !9, i64 240, !9, i64 244, !9, i64 248, !9, i64 252, !9, i64 256, !3, i64 260}
!19 = !{!"", !20, i64 0, !9, i64 4, !9, i64 8, !9, i64 12, !9, i64 16, !9, i64 20, !9, i64 24, !9, i64 28, !11, i64 32, !11, i64 40}
!20 = !{!"", !9, i64 0, !9, i64 0, !9, i64 0, !9, i64 0, !9, i64 0, !9, i64 0, !9, i64 0, !9, i64 0}
!21 = !{!"rb_iseq_location_struct", !2, i64 0, !2, i64 8, !2, i64 16, !2, i64 24, !9, i64 32, !22, i64 36}
!22 = !{!"rb_code_location_struct", !23, i64 0, !23, i64 8}
!23 = !{!"rb_code_position_struct", !9, i64 0, !9, i64 4}
!24 = !{!"iseq_insn_info", !11, i64 0, !11, i64 8, !9, i64 16, !11, i64 24}
!25 = !{!"", !2, i64 0, !2, i64 8, !2, i64 16, !11, i64 24}
!26 = !{!27, !11, i64 16}
!27 = !{!"rb_control_frame_struct", !11, i64 0, !11, i64 8, !11, i64 16, !2, i64 24, !11, i64 32, !11, i64 40, !11, i64 48}
!28 = !{!27, !11, i64 0}
!29 = !{!30, !30, i64 0}
!30 = !{!"long long", !3, i64 0}
!31 = !{!"branch_weights", i32 10000, i32 1}
!32 = !{!33, !11, i64 32}
!33 = !{!"RTypedData", !1, i64 0, !11, i64 16, !2, i64 24, !11, i64 32}
!34 = !{!"branch_weights", i32 1073205, i32 2146410443}
!35 = !{!"branch_weights", i32 1, i32 2000}
!36 = !{!"misexpect", i64 0, i64 2000, i64 1}
!37 = !{!"branch_weights", i32 4000000, i32 4001}
!38 = !{!"misexpect", i64 1, i64 2000, i64 1}
!39 = !{!40}
!40 = distinct !{!40, !41, !"sorbet_rb_int_plus: argument 0"}
!41 = distinct !{!41, !"sorbet_rb_int_plus"}
!42 = !{!43, !44, i64 16}
!43 = !{!"RFloat", !1, i64 0, !44, i64 16}
!44 = !{!"double", !3, i64 0}
!45 = !{!46}
!46 = distinct !{!46, !47, !"sorbet_buildHashIntrinsic: argument 0"}
!47 = distinct !{!47, !"sorbet_buildHashIntrinsic"}
