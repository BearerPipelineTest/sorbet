source_filename = "compiler/IRHelpers/payload.c"
target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-darwin18.2.0"

%struct.rb_data_type_struct = type { i8*, %struct.anon.1, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.1 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.RBasic = type { i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%union.anon.0 = type { i64 }
%struct.OnigEncodingTypeST = type { i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i8*, i32, i32, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8**, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i32 (i32, i32*, i32, i8*)*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, i8*, %struct.OnigCaseFoldCodeItem*, %struct.OnigEncodingTypeST*)*, i32 (%struct.OnigEncodingTypeST*, i8*, i8*)*, i32 (i32, i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i32*, i32**, %struct.OnigEncodingTypeST*)*, i8* (i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32*, i8**, i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32, i32 }
%struct.OnigCaseFoldCodeItem = type { i32, i32, [3 x i32] }
%struct.RFloat = type { %struct.RBasic, double }
%struct.RTypedData = type { %struct.RBasic, %struct.rb_data_type_struct*, i64, i8* }
%struct.sorbet_Closure = type { i32, [0 x i64] }

@.str = private unnamed_addr constant [16 x i8] c"ERROR: %s is 0\0A\00", align 1
@.str.1 = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@rb_cObject = external local_unnamed_addr constant i64, align 8
@ruby_vm_global_constant_state = external local_unnamed_addr global i64, align 8
@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@.str.4 = private unnamed_addr constant [29 x i8] c"wrong constant name %li\0B%li\0B\00", align 1
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.5 = private unnamed_addr constant [36 x i8] c"%li\0B does not refer to class/module\00", align 1
@.str.6 = private unnamed_addr constant [5 x i8] c"func\00", align 1
@.str.7 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.10 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@.str.11 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@closureInfo = constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.11, i32 0, i32 0), %struct.anon.1 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@rb_cData = external local_unnamed_addr constant i64, align 8
@rb_cModule = external local_unnamed_addr constant i64, align 8
@rb_cInteger = external local_unnamed_addr constant i64, align 8
@guard_epoch_T = linkonce local_unnamed_addr global i64 0
@guarded_const_T = linkonce local_unnamed_addr global i64 0
@str_T = private unnamed_addr constant [2 x i8] c"T\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@guard_epoch_Object = linkonce local_unnamed_addr global i64 0
@guarded_const_Object = linkonce local_unnamed_addr global i64 0
@str_Object = private unnamed_addr constant [7 x i8] c"Object\00", align 1
@rubyIdPrecomputed_fib = internal unnamed_addr global i64 0, align 8
@guard_epoch_HasFib = linkonce local_unnamed_addr global i64 0
@guarded_const_HasFib = linkonce local_unnamed_addr global i64 0
@str_HasFib.1 = private unnamed_addr constant [7 x i8] c"HasFib\00", align 1
@str_Integer = private unnamed_addr constant [8 x i8] c"Integer\00", align 1
@"rubyIdPrecomputed_<" = internal unnamed_addr global i64 0, align 8
@"str_<" = private unnamed_addr constant [2 x i8] c"<\00", align 1
@rubyIdPrecomputed_- = internal unnamed_addr global i64 0, align 8
@str_- = private unnamed_addr constant [2 x i8] c"-\00", align 1
@"rubyIdPrecomputed_+" = internal unnamed_addr global i64 0, align 8
@"str_+" = private unnamed_addr constant [2 x i8] c"+\00", align 1
@str_cast.4 = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@"str_T.class_of(HasFib).5" = private unnamed_addr constant [19 x i8] c"T.class_of(HasFib)\00", align 1
@rubyIdPrecomputed_final = internal unnamed_addr global i64 0, align 8
@str_final = private unnamed_addr constant [6 x i8] c"final\00", align 1
@rubyIdPrecomputed_sig = internal unnamed_addr global i64 0, align 8
@str_sig.6 = private unnamed_addr constant [4 x i8] c"sig\00", align 1
@"guard_epoch_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@"guarded_const_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@"str_T::Sig::WithoutRuntime" = private unnamed_addr constant [23 x i8] c"T::Sig::WithoutRuntime\00", align 1
@rubyIdPrecomputed_n = internal unnamed_addr global i64 0, align 8
@str_n = private unnamed_addr constant [2 x i8] c"n\00", align 1
@rubyIdPrecomputed_params = internal unnamed_addr global i64 0, align 8
@str_params = private unnamed_addr constant [7 x i8] c"params\00", align 1
@rubyIdPrecomputed_returns = internal unnamed_addr global i64 0, align 8
@str_returns = private unnamed_addr constant [8 x i8] c"returns\00", align 1
@llvm.global_ctors = appending global [10 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_fib, i8* bitcast (i64* @rubyIdPrecomputed_fib to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<", i8* bitcast (i64* @"rubyIdPrecomputed_<" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_-, i8* bitcast (i64* @rubyIdPrecomputed_- to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_+", i8* bitcast (i64* @"rubyIdPrecomputed_+" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_final, i8* bitcast (i64* @rubyIdPrecomputed_final to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_sig, i8* bitcast (i64* @rubyIdPrecomputed_sig to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_n, i8* bitcast (i64* @rubyIdPrecomputed_n to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_params, i8* bitcast (i64* @rubyIdPrecomputed_params to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_returns, i8* bitcast (i64* @rubyIdPrecomputed_returns to i8*) }]
@str_fib.7 = private unnamed_addr constant [4 x i8] c"fib\00", align 1

; Function Attrs: nounwind ssp uwtable
define weak void @dbg_sorbet_validate_id(i64, i8*) local_unnamed_addr #0 {
  %3 = icmp eq i64 %0, 0
  br i1 %3, label %4, label %6, !prof !0

4:                                                ; preds = %2
  %5 = tail call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str, i64 0, i64 0), i8* %1)
  tail call void @abort() #18
  unreachable

6:                                                ; preds = %2
  ret void
}

; Function Attrs: nofree nounwind
declare i32 @printf(i8* nocapture readonly, ...) local_unnamed_addr #1

; Function Attrs: cold noreturn
declare void @abort() local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64) local_unnamed_addr #0 {
  %2 = tail call i8* @rb_id2name(i64 %0) #19
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64) local_unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.1, i64 0, i64 0), i64 %0) #19
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !1
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.1, i64 0, i64 0), i64 %0) #19
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !6
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #3

declare i64 @rb_hash_new() local_unnamed_addr #3

declare i64 @rb_hash_aset(i64, i64, i64) local_unnamed_addr #3

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #3

declare i64 @rb_id2sym(i64) local_unnamed_addr #3

declare i8* @rb_obj_classname(i64) local_unnamed_addr #3

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstantAt(i64, i64) unnamed_addr #4 {
  %3 = tail call i64 @rb_id2sym(i64 %1) #19
  %4 = tail call %struct.OnigEncodingTypeST* @rb_enc_get(i64 %3) #19
  %5 = tail call i8* @rb_id2name(i64 %1) #19
  %6 = tail call i64 @strlen(i8* %5)
  %7 = getelementptr inbounds i8, i8* %5, i64 %6
  %8 = icmp sgt i64 %6, 0
  br i1 %8, label %9, label %.loopexit11

9:                                                ; preds = %2
  %10 = ptrtoint i8* %5 to i64
  br label %13

.loopexit10:                                      ; preds = %rb_obj_freeze_inline.exit, %44, %41, %28, %101
  %11 = phi i64 [ %102, %101 ], [ %3, %28 ], [ %3, %44 ], [ %3, %41 ], [ %66, %rb_obj_freeze_inline.exit ]
  %12 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !7
  tail call void (i64, i8*, ...) @rb_raise(i64 %12, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.4, i64 0, i64 0), i64 %14, i64 %11) #20
  unreachable

13:                                               ; preds = %109, %9
  %14 = phi i64 [ %0, %9 ], [ %110, %109 ]
  %15 = phi i8* [ %5, %9 ], [ %50, %109 ]
  %16 = phi i8* [ %5, %9 ], [ %49, %109 ]
  %17 = icmp ult i8* %16, %7
  br i1 %17, label %18, label %28

18:                                               ; preds = %13
  %19 = load i8, i8* %16, align 1, !tbaa !6
  %20 = icmp eq i8 %19, 58
  br i1 %20, label %28, label %.preheader

21:                                               ; preds = %.preheader
  %22 = load i8, i8* %25, align 1, !tbaa !6
  %23 = icmp eq i8 %22, 58
  br i1 %23, label %.loopexit, label %.preheader

.preheader:                                       ; preds = %18, %21
  %24 = phi i8* [ %25, %21 ], [ %16, %18 ]
  %25 = getelementptr inbounds i8, i8* %24, i64 1
  %26 = icmp eq i8* %25, %7
  br i1 %26, label %.loopexit, label %21

.loopexit:                                        ; preds = %21, %.preheader
  %.lcssa = phi i8* [ %25, %21 ], [ %7, %.preheader ]
  %27 = icmp ult i8* %.lcssa, %7
  br label %28

28:                                               ; preds = %.loopexit, %18, %13
  %29 = phi i8* [ %16, %13 ], [ %16, %18 ], [ %.lcssa, %.loopexit ]
  %30 = phi i1 [ false, %13 ], [ true, %18 ], [ %27, %.loopexit ]
  %31 = icmp eq i8* %15, %29
  br i1 %31, label %.loopexit10, label %32

32:                                               ; preds = %28
  %33 = ptrtoint i8* %29 to i64
  %34 = ptrtoint i8* %15 to i64
  %35 = sub i64 %33, %34
  %36 = tail call i64 @rb_check_id_cstr(i8* %15, i64 %35, %struct.OnigEncodingTypeST* %4) #19
  %37 = sub i64 %34, %10
  br i1 %30, label %38, label %48

38:                                               ; preds = %32
  %39 = load i8, i8* %29, align 1, !tbaa !6
  %40 = icmp eq i8 %39, 58
  br i1 %40, label %41, label %48

41:                                               ; preds = %38
  %42 = getelementptr inbounds i8, i8* %29, i64 2
  %43 = icmp ult i8* %42, %7
  br i1 %43, label %44, label %.loopexit10

44:                                               ; preds = %41
  %45 = getelementptr inbounds i8, i8* %29, i64 1
  %46 = load i8, i8* %45, align 1, !tbaa !6
  %47 = icmp eq i8 %46, 58
  br i1 %47, label %48, label %.loopexit10

48:                                               ; preds = %44, %38, %32
  %49 = phi i8* [ %29, %38 ], [ %29, %32 ], [ %42, %44 ]
  %50 = phi i8* [ %15, %38 ], [ %15, %32 ], [ %42, %44 ]
  %51 = and i64 %14, 7
  %52 = icmp ne i64 %51, 0
  %53 = and i64 %14, -9
  %54 = icmp eq i64 %53, 0
  %55 = or i1 %52, %54
  br i1 %55, label %61, label %56

56:                                               ; preds = %48
  %57 = inttoptr i64 %14 to %struct.RBasic*
  %58 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 0
  %59 = load i64, i64* %58, align 8, !tbaa !1
  %60 = and i64 %59, 30
  %switch = icmp eq i64 %60, 2
  br i1 %switch, label %63, label %61

61:                                               ; preds = %56, %48
  %62 = load i64, i64* @rb_eTypeError, align 8, !tbaa !7
  tail call void (i64, i8*, ...) @rb_raise(i64 %62, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.5, i64 0, i64 0), i64 %3) #20
  unreachable

63:                                               ; preds = %56
  %64 = icmp eq i64 %36, 0
  br i1 %64, label %65, label %98

65:                                               ; preds = %63
  %66 = tail call i64 @rb_str_subseq(i64 %3, i64 %37, i64 %35) #19
  %67 = and i64 %66, 7
  %68 = icmp ne i64 %67, 0
  %69 = and i64 %66, -9
  %70 = icmp eq i64 %69, 0
  %71 = or i1 %68, %70
  br i1 %71, label %rb_obj_freeze_inline.exit, label %72

72:                                               ; preds = %65
  %73 = inttoptr i64 %66 to %struct.RBasic*
  %74 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 0
  %75 = load i64, i64* %74, align 8, !tbaa !1
  %76 = and i64 %75, 31
  %77 = icmp eq i64 %76, 27
  br i1 %77, label %rb_obj_freeze_inline.exit, label %78

78:                                               ; preds = %72
  %79 = or i64 %75, 2048
  store i64 %79, i64* %74, align 8, !tbaa !1
  %80 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 1
  %81 = load i64, i64* %80, align 8, !tbaa !8
  %82 = icmp ne i64 %81, 0
  %83 = and i64 %75, 4096
  %84 = icmp eq i64 %83, 0
  %85 = and i1 %84, %82
  br i1 %85, label %86, label %rb_obj_freeze_inline.exit

86:                                               ; preds = %78
  tail call void @rb_freeze_singleton_class(i64 %66) #19
  br label %rb_obj_freeze_inline.exit

rb_obj_freeze_inline.exit:                        ; preds = %65, %72, %78, %86
  %87 = tail call i32 @rb_is_const_name(i64 %66) #19
  %88 = icmp eq i32 %87, 0
  br i1 %88, label %.loopexit10, label %rb_class_of.exit

rb_class_of.exit:                                 ; preds = %rb_obj_freeze_inline.exit
  %89 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 1
  %90 = load i64, i64* %89, align 8, !tbaa !7
  %91 = tail call i32 @rb_method_basic_definition_p(i64 %90, i64 2737) #19
  %92 = icmp eq i32 %91, 0
  br i1 %92, label %93, label %96

93:                                               ; preds = %rb_class_of.exit
  %94 = tail call i64 @rb_str_intern(i64 %66) #19
  %95 = tail call i64 @rb_const_missing(i64 %14, i64 %94) #19
  br label %109

96:                                               ; preds = %rb_class_of.exit
  %97 = tail call i64 @rb_mod_const_missing(i64 %14, i64 %66) #20
  unreachable

98:                                               ; preds = %63
  %99 = tail call i32 @rb_is_const_id(i64 %36) #7
  %100 = icmp eq i32 %99, 0
  br i1 %100, label %101, label %103

101:                                              ; preds = %98
  %102 = tail call i64 @rb_id2sym(i64 %36) #19
  br label %.loopexit10

103:                                              ; preds = %98
  %104 = icmp eq i64 %37, 0
  br i1 %104, label %105, label %107

105:                                              ; preds = %103
  %106 = tail call i64 @rb_const_get(i64 %14, i64 %36) #19
  br label %109

107:                                              ; preds = %103
  %108 = tail call i64 @rb_const_get_from(i64 %14, i64 %36) #19
  br label %109

109:                                              ; preds = %107, %105, %93
  %110 = phi i64 [ %95, %93 ], [ %106, %105 ], [ %108, %107 ]
  %111 = icmp ult i8* %49, %7
  br i1 %111, label %13, label %.loopexit11

.loopexit11:                                      ; preds = %109, %2
  %112 = phi i64 [ %0, %2 ], [ %110, %109 ]
  ret i64 %112
}

declare %struct.OnigEncodingTypeST* @rb_enc_get(i64) local_unnamed_addr #3

; Function Attrs: argmemonly nofree nounwind readonly
declare i64 @strlen(i8* nocapture) local_unnamed_addr #5

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #6

declare i64 @rb_check_id_cstr(i8*, i64, %struct.OnigEncodingTypeST*) local_unnamed_addr #3

declare i64 @rb_str_subseq(i64, i64, i64) local_unnamed_addr #3

declare i32 @rb_is_const_name(i64) local_unnamed_addr #3

declare i32 @rb_method_basic_definition_p(i64, i64) local_unnamed_addr #3

declare i64 @rb_str_intern(i64) local_unnamed_addr #3

declare i64 @rb_const_missing(i64, i64) local_unnamed_addr #3

; Function Attrs: noreturn
declare i64 @rb_mod_const_missing(i64, i64) local_unnamed_addr #6

; Function Attrs: nounwind readnone
declare i32 @rb_is_const_id(i64) local_unnamed_addr #7

declare i64 @rb_const_get(i64, i64) local_unnamed_addr #3

declare i64 @rb_const_get_from(i64, i64) local_unnamed_addr #3

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstant(i8*, i64) unnamed_addr #4 {
  %3 = load i64, i64* @rb_cObject, align 8, !tbaa !7
  %4 = tail call i64 @rb_intern2(i8* %0, i64 %1) #19
  %5 = tail call fastcc i64 @sorbet_getConstantAt(i64 %3, i64 %4)
  ret i64 %5
}

declare i64 @rb_define_class(i8*, i64) local_unnamed_addr #3

declare void @rb_define_singleton_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #3

declare i64 @rb_funcallv(i64, i64, i32, i64*) local_unnamed_addr #3

declare i64 @rb_block_call(i64, i64, i32, i64*, i64 (...)*, i64) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32) unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.7, i64 0, i64 0), i32 %0, i32 1) #19
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !7
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #19
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #3

; Function Attrs: cold noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64, i8*, i8*) unnamed_addr #8 {
  %4 = load i64, i64* @rb_eTypeError, align 8, !tbaa !7
  %5 = tail call i8* @rb_obj_classname(i64 %0) #19
  tail call void (i64, i8*, ...) @rb_raise(i64 %4, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.10, i64 0, i64 0), i8* %1, i8* %2, i8* %5, i64 %0) #20
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_rb_error_arity(i32) unnamed_addr #9 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #20
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #6

declare i32 @ruby_stack_check() local_unnamed_addr #3

declare i8* @ruby_xmalloc(i64) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8*) #0 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !9
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #19
  ret void
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #3

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly) #10 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !9
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

declare i64 @rb_data_typed_object_wrap(i64, i8*, %struct.rb_data_type_struct*) local_unnamed_addr #3

declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #3

; Function Attrs: nounwind readonly
declare i64 @rb_class_inherited_p(i64, i64) local_unnamed_addr #11

declare i64 @rb_big_plus(i64, i64) local_unnamed_addr #3

declare i64 @rb_complex_plus(i64, i64) local_unnamed_addr #3

declare i64 @rb_num_coerce_bin(i64, i64, i64) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_int_minus(i64, i64 %.val) unnamed_addr #0 {
  %2 = and i64 %0, 1
  %3 = icmp eq i64 %2, 0
  br i1 %3, label %82, label %4, !prof !0

4:                                                ; preds = %1
  %5 = and i64 %.val, 1
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %16, label %7, !prof !0

7:                                                ; preds = %4
  %8 = add nsw i64 %.val, -1
  %9 = tail call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %0, i64 %8) #19
  %10 = extractvalue { i64, i1 } %9, 1
  %11 = extractvalue { i64, i1 } %9, 0
  br i1 %10, label %12, label %rb_fix_minus_fix.exit

12:                                               ; preds = %7
  %13 = ashr i64 %11, 1
  %14 = xor i64 %13, -9223372036854775808
  %15 = tail call i64 @rb_int2big(i64 %14) #19
  br label %rb_fix_minus_fix.exit

16:                                               ; preds = %4
  %17 = and i64 %.val, 7
  %18 = icmp ne i64 %17, 0
  %19 = and i64 %.val, -9
  %20 = icmp eq i64 %19, 0
  %21 = or i1 %18, %20
  br i1 %21, label %32, label %22

22:                                               ; preds = %16
  %23 = inttoptr i64 %.val to %struct.RBasic*
  %24 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %23, i64 0, i32 0
  %25 = load i64, i64* %24, align 8, !tbaa !1
  %26 = and i64 %25, 31
  %27 = icmp eq i64 %26, 10
  br i1 %27, label %28, label %32

28:                                               ; preds = %22
  %29 = ashr i64 %0, 1
  %30 = tail call i64 @rb_int2big(i64 %29) #19
  %31 = tail call i64 @rb_big_minus(i64 %30, i64 %.val) #19
  br label %rb_fix_minus_fix.exit

32:                                               ; preds = %22, %16
  %33 = and i64 %.val, 3
  %34 = icmp eq i64 %33, 2
  br i1 %34, label %42, label %35

35:                                               ; preds = %32
  br i1 %21, label %96, label %36

36:                                               ; preds = %35
  %37 = inttoptr i64 %.val to %struct.RBasic*
  %38 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %37, i64 0, i32 0
  %39 = load i64, i64* %38, align 8, !tbaa !1
  %40 = and i64 %39, 31
  %41 = icmp eq i64 %40, 4
  br i1 %41, label %55, label %96

42:                                               ; preds = %32
  %43 = ashr i64 %0, 1
  %44 = sitofp i64 %43 to double
  %45 = icmp eq i64 %.val, -9223372036854775806
  br i1 %45, label %rb_float_value_inline.exit, label %46

46:                                               ; preds = %42
  %47 = lshr i64 %.val, 63
  %48 = sub nuw nsw i64 2, %47
  %49 = and i64 %.val, 4
  %50 = or i64 %48, %49
  %51 = lshr i64 %.val, 3
  %52 = shl nuw i64 %50, 61
  %53 = or i64 %52, %51
  %54 = bitcast i64 %53 to double
  br label %rb_float_value_inline.exit

55:                                               ; preds = %36
  %56 = ashr i64 %0, 1
  %57 = sitofp i64 %56 to double
  %58 = inttoptr i64 %.val to %struct.RFloat*
  %59 = getelementptr inbounds %struct.RFloat, %struct.RFloat* %58, i64 0, i32 1
  %60 = load double, double* %59, align 8, !tbaa !11
  br label %rb_float_value_inline.exit

rb_float_value_inline.exit:                       ; preds = %42, %46, %55
  %61 = phi double [ %57, %55 ], [ %44, %46 ], [ %44, %42 ]
  %62 = phi double [ %60, %55 ], [ %54, %46 ], [ 0.000000e+00, %42 ]
  %63 = fsub double %61, %62
  %64 = bitcast double %63 to i64
  %65 = icmp eq i64 %64, 3458764513820540928
  br i1 %65, label %80, label %66

66:                                               ; preds = %rb_float_value_inline.exit
  %67 = lshr i64 %64, 60
  %68 = trunc i64 %67 to i32
  %69 = and i32 %68, 7
  %70 = add nsw i32 %69, -3
  %71 = icmp ugt i32 %70, 1
  br i1 %71, label %78, label %72

72:                                               ; preds = %66
  %73 = shl i64 %64, 3
  %74 = lshr i64 %64, 61
  %75 = and i64 %74, 4
  %76 = or i64 %73, %75
  %77 = or i64 %76, 2
  br label %rb_fix_minus_fix.exit

78:                                               ; preds = %66
  %79 = icmp eq i64 %64, 0
  br i1 %79, label %rb_fix_minus_fix.exit, label %80

80:                                               ; preds = %78, %rb_float_value_inline.exit
  %81 = tail call i64 @rb_float_new_in_heap(double %63) #19
  br label %rb_fix_minus_fix.exit

82:                                               ; preds = %1
  %83 = and i64 %0, 7
  %84 = icmp ne i64 %83, 0
  %85 = and i64 %0, -9
  %86 = icmp eq i64 %85, 0
  %87 = or i1 %84, %86
  br i1 %87, label %96, label %88

88:                                               ; preds = %82
  %89 = inttoptr i64 %0 to %struct.RBasic*
  %90 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %89, i64 0, i32 0
  %91 = load i64, i64* %90, align 8, !tbaa !1
  %92 = and i64 %91, 31
  %93 = icmp eq i64 %92, 10
  br i1 %93, label %94, label %96

94:                                               ; preds = %88
  %95 = tail call i64 @rb_big_minus(i64 %0, i64 %.val) #19
  br label %rb_fix_minus_fix.exit

96:                                               ; preds = %88, %82, %36, %35
  %97 = tail call i64 @rb_num_coerce_bin(i64 %0, i64 %.val, i64 45) #19
  br label %rb_fix_minus_fix.exit

rb_fix_minus_fix.exit:                            ; preds = %80, %78, %72, %12, %7, %96, %94, %28
  %98 = phi i64 [ %97, %96 ], [ %31, %28 ], [ %95, %94 ], [ %15, %12 ], [ %11, %7 ], [ %81, %80 ], [ %77, %72 ], [ -9223372036854775806, %78 ]
  ret i64 %98
}

declare i64 @rb_int2big(i64) local_unnamed_addr #3

declare i64 @rb_big_minus(i64, i64) local_unnamed_addr #3

declare i64 @rb_float_new_in_heap(double) local_unnamed_addr #3

declare void @rb_freeze_singleton_class(i64) local_unnamed_addr #3

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.sadd.with.overflow.i64(i64, i64) #12

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.ssub.with.overflow.i64(i64, i64) #12

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #19
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_fib() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_fib.7, i64 0, i64 0), i64 3) #19
  store i64 %0, i64* @rubyIdPrecomputed_fib, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_ruby_benchmark_app_fib() local_unnamed_addr #14 {
typeTestSuccess.i:
  %callArgs.i.i.i = alloca [2 x i64], align 8
  %callArgs.i = alloca [1 x i64], align 8
  %0 = load i64, i64* @rb_cObject, align 8
  %1 = bitcast [1 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1)
  %rubyId_fib.i = load i64, i64* @rubyIdPrecomputed_fib, align 8
  %2 = load i64, i64* @guard_epoch_T, align 8
  %3 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath.i = icmp eq i64 %2, %3
  br i1 %canTakeFastPath.i, label %afterSymCallIntrinsic_unsafe.i, label %const_slowPath.i, !prof !16

const_slowPath.i:                                 ; preds = %typeTestSuccess.i
  %4 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_T, i64 0, i64 0), i64 1) #19
  store i64 %4, i64* @guarded_const_T, align 8
  %5 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %5, i64* @guard_epoch_T, align 8
  br label %afterSymCallIntrinsic_unsafe.i

afterSymCallIntrinsic_unsafe.i:                   ; preds = %const_slowPath.i, %typeTestSuccess.i
  %6 = phi i64 [ %5, %const_slowPath.i ], [ %2, %typeTestSuccess.i ]
  %callArgsAddr3.i = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs.i, i64 0, i64 0
  store i64 %0, i64* %callArgsAddr3.i, align 8
  %7 = load i64, i64* @guard_epoch_Object, align 8
  %canTakeFastPath40.i = icmp eq i64 %7, %6
  br i1 %canTakeFastPath40.i, label %afterSymCallIntrinsic_unsafe.const_continue38_crit_edge.i, label %const_slowPath39.i, !prof !16

afterSymCallIntrinsic_unsafe.const_continue38_crit_edge.i: ; preds = %afterSymCallIntrinsic_unsafe.i
  %.pre18.i = load i64, i64* @guarded_const_Object, align 8
  br label %const_continue38.i

const_continue38.i:                               ; preds = %const_slowPath39.i, %afterSymCallIntrinsic_unsafe.const_continue38_crit_edge.i
  %8 = phi i64 [ %.pre18.i, %afterSymCallIntrinsic_unsafe.const_continue38_crit_edge.i ], [ %61, %const_slowPath39.i ]
  %9 = tail call i64 @rb_define_class(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 %8) #19
  %10 = load i64, i64* @guard_epoch_HasFib, align 8
  %11 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath.i.i = icmp eq i64 %10, %11
  br i1 %canTakeFastPath.i.i, label %entry.const_continue_crit_edge.i.i, label %const_slowPath.i.i, !prof !16

entry.const_continue_crit_edge.i.i:               ; preds = %const_continue38.i
  %.pre.i.i = load i64, i64* @guarded_const_HasFib, align 8
  br label %const_continue.i.i

const_continue.i.i:                               ; preds = %const_slowPath.i.i, %entry.const_continue_crit_edge.i.i
  %12 = phi i64 [ %.pre.i.i, %entry.const_continue_crit_edge.i.i ], [ %56, %const_slowPath.i.i ]
  %13 = bitcast [2 x i64]* %callArgs.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %13) #19
  %14 = tail call i8* @ruby_xmalloc(i64 16) #19
  %15 = bitcast i8* %14 to i32*
  store i32 1, i32* %15, align 8, !tbaa !9
  %16 = load i64, i64* @rb_cData, align 8, !tbaa !7
  %17 = tail call i64 @rb_data_typed_object_wrap(i64 %16, i8* %14, %struct.rb_data_type_struct* nonnull @closureInfo) #19
  %18 = inttoptr i64 %17 to %struct.RTypedData*
  %19 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %18, i64 0, i32 3
  %20 = bitcast i8** %19 to %struct.sorbet_Closure**
  %21 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %20, align 8, !tbaa !17
  %22 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %21, i64 0, i32 1, i64 0
  store i64 8, i64* %22, align 8
  %rubyId_final.i.i.i = load i64, i64* @rubyIdPrecomputed_final, align 8
  %rubyId_sig.i.i.i = load i64, i64* @rubyIdPrecomputed_sig, align 8
  %rubyId_fib.i.i.i = load i64, i64* @rubyIdPrecomputed_fib, align 8
  %23 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %20, align 8, !tbaa !17
  %24 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %23, i64 0, i32 1, i64 0
  store i64 %12, i64* %24, align 8
  %25 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %20, align 8, !tbaa !17
  %26 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %25, i64 0, i32 1, i64 0
  %27 = load i64, i64* %26, align 8
  %28 = load i64, i64* @guard_epoch_HasFib, align 8
  %29 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath.i.i.i = icmp eq i64 %28, %29
  br i1 %canTakeFastPath.i.i.i, label %functionEntryInitializers.const_continue_crit_edge.i.i.i, label %const_slowPath.i.i.i, !prof !16

functionEntryInitializers.const_continue_crit_edge.i.i.i: ; preds = %const_continue.i.i
  %.pre.i.i.i = load i64, i64* @guarded_const_HasFib, align 8
  br label %const_continue.i.i.i

const_continue.i.i.i:                             ; preds = %const_slowPath.i.i.i, %functionEntryInitializers.const_continue_crit_edge.i.i.i
  %30 = phi i64 [ %.pre.i.i.i, %functionEntryInitializers.const_continue_crit_edge.i.i.i ], [ %38, %const_slowPath.i.i.i ]
  %31 = icmp eq i64 %27, %30
  br i1 %31, label %typeTestSuccess.i.i.i, label %32

32:                                               ; preds = %const_continue.i.i.i
  %33 = load i64, i64* @rb_cModule, align 8, !tbaa !7
  %34 = tail call i64 @rb_obj_is_kind_of(i64 %27, i64 %33) #19
  %35 = icmp eq i64 %34, 0
  br i1 %35, label %typeTestFail.i.i.i, label %sorbet_isa_class_of.exit.i.i.i, !prof !20

sorbet_isa_class_of.exit.i.i.i:                   ; preds = %32
  %36 = tail call i64 @rb_class_inherited_p(i64 %27, i64 %30) #11
  %37 = icmp eq i64 %36, 0
  br i1 %37, label %typeTestFail.i.i.i, label %typeTestSuccess.i.i.i, !prof !0

const_slowPath.i.i.i:                             ; preds = %const_continue.i.i
  %38 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 6) #19
  store i64 %38, i64* @guarded_const_HasFib, align 8
  %39 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %39, i64* @guard_epoch_HasFib, align 8
  br label %const_continue.i.i.i

typeTestSuccess.i.i.i:                            ; preds = %sorbet_isa_class_of.exit.i.i.i, %const_continue.i.i.i
  %40 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %20, align 8, !tbaa !17
  %41 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %40, i64 0, i32 1, i64 0
  store i64 %27, i64* %41, align 8
  %rawSym.i.i.i = tail call i64 @rb_id2sym(i64 %rubyId_final.i.i.i) #19
  %callArgsAddr.i.i.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i.i.i, i64 0, i64 0
  store i64 %rawSym.i.i.i, i64* %callArgsAddr.i.i.i, align 8
  %42 = load i64, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  %43 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath27.i.i.i = icmp eq i64 %42, %43
  br i1 %canTakeFastPath27.i.i.i, label %typeTestSuccess.const_continue25_crit_edge.i.i.i, label %const_slowPath26.i.i.i, !prof !16

typeTestSuccess.const_continue25_crit_edge.i.i.i: ; preds = %typeTestSuccess.i.i.i
  %.pre8.i.i.i = load i64, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  br label %const_continue25.i.i.i

typeTestFail.i.i.i:                               ; preds = %sorbet_isa_class_of.exit.i.i.i, %32
  tail call fastcc void @sorbet_cast_failure(i64 %27, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast.4, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(HasFib).5", i64 0, i64 0)) #19
  unreachable

const_continue25.i.i.i:                           ; preds = %const_slowPath26.i.i.i, %typeTestSuccess.const_continue25_crit_edge.i.i.i
  %44 = phi i64 [ %.pre8.i.i.i, %typeTestSuccess.const_continue25_crit_edge.i.i.i ], [ %48, %const_slowPath26.i.i.i ]
  tail call void @dbg_sorbet_validate_id(i64 %rubyId_sig.i.i.i, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6, i64 0, i64 0)) #19, !noalias !21
  %45 = call i64 @rb_block_call(i64 %44, i64 %rubyId_sig.i.i.i, i32 1, i64* nonnull %callArgsAddr.i.i.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_HasFib.<static-init>$block_1" to i64 (...)*), i64 %17) #19
  %46 = load i64, i64* @guard_epoch_T, align 8
  %47 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath32.i.i.i = icmp eq i64 %46, %47
  br i1 %canTakeFastPath32.i.i.i, label %afterSymCallIntrinsic_unsafe.i.i.i, label %const_slowPath31.i.i.i, !prof !16

const_slowPath26.i.i.i:                           ; preds = %typeTestSuccess.i.i.i
  %48 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([23 x i8], [23 x i8]* @"str_T::Sig::WithoutRuntime", i64 0, i64 0), i64 22) #19
  store i64 %48, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  %49 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %49, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  br label %const_continue25.i.i.i

const_slowPath31.i.i.i:                           ; preds = %const_continue25.i.i.i
  %50 = call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_T, i64 0, i64 0), i64 1) #19
  store i64 %50, i64* @guarded_const_T, align 8
  %51 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %51, i64* @guard_epoch_T, align 8
  br label %afterSymCallIntrinsic_unsafe.i.i.i

afterSymCallIntrinsic_unsafe.i.i.i:               ; preds = %const_slowPath31.i.i.i, %const_continue25.i.i.i
  store i64 %0, i64* %callArgsAddr.i.i.i, align 8
  %rawSym46.i.i.i = call i64 @rb_id2sym(i64 %rubyId_fib.i.i.i) #19
  %52 = load i64, i64* @guard_epoch_HasFib, align 8
  %53 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath49.i.i.i = icmp eq i64 %52, %53
  br i1 %canTakeFastPath49.i.i.i, label %afterSymCallIntrinsic_unsafe.const_continue47_crit_edge.i.i.i, label %const_slowPath48.i.i.i, !prof !16

afterSymCallIntrinsic_unsafe.const_continue47_crit_edge.i.i.i: ; preds = %afterSymCallIntrinsic_unsafe.i.i.i
  %.pre10.i.i.i = load i64, i64* @guarded_const_HasFib, align 8
  br label %"Init_func_HasFib.<static-init>.exit.i"

const_slowPath48.i.i.i:                           ; preds = %afterSymCallIntrinsic_unsafe.i.i.i
  %54 = call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 6) #19
  store i64 %54, i64* @guarded_const_HasFib, align 8
  %55 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %55, i64* @guard_epoch_HasFib, align 8
  br label %"Init_func_HasFib.<static-init>.exit.i"

const_slowPath.i.i:                               ; preds = %const_continue38.i
  %56 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 6) #19
  store i64 %56, i64* @guarded_const_HasFib, align 8
  %57 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %57, i64* @guard_epoch_HasFib, align 8
  br label %const_continue.i.i

"Init_func_HasFib.<static-init>.exit.i":          ; preds = %const_slowPath48.i.i.i, %afterSymCallIntrinsic_unsafe.const_continue47_crit_edge.i.i.i
  %58 = phi i64 [ %.pre10.i.i.i, %afterSymCallIntrinsic_unsafe.const_continue47_crit_edge.i.i.i ], [ %54, %const_slowPath48.i.i.i ]
  call void @rb_define_singleton_method(i64 %58, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_fib.7, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @func_HasFib.fib to i64 (...)*), i32 -1) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %13) #19
  store i64 69, i64* %callArgsAddr3.i, align 8
  %59 = load i64, i64* @guard_epoch_HasFib, align 8
  %60 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath47.i = icmp eq i64 %59, %60
  br i1 %canTakeFastPath47.i, label %"Init_func_HasFib.<static-init>.exit.const_continue45_crit_edge.i", label %const_slowPath46.i, !prof !16

"Init_func_HasFib.<static-init>.exit.const_continue45_crit_edge.i": ; preds = %"Init_func_HasFib.<static-init>.exit.i"
  %.pre19.i = load i64, i64* @guarded_const_HasFib, align 8
  br label %"func_<root>.<static-init>$111.exit"

const_slowPath39.i:                               ; preds = %afterSymCallIntrinsic_unsafe.i
  %61 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_Object, i64 0, i64 0), i64 6) #19
  store i64 %61, i64* @guarded_const_Object, align 8
  %62 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %62, i64* @guard_epoch_Object, align 8
  br label %const_continue38.i

const_slowPath46.i:                               ; preds = %"Init_func_HasFib.<static-init>.exit.i"
  %63 = call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 6) #19
  store i64 %63, i64* @guarded_const_HasFib, align 8
  %64 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %64, i64* @guard_epoch_HasFib, align 8
  br label %"func_<root>.<static-init>$111.exit"

"func_<root>.<static-init>$111.exit":             ; preds = %"Init_func_HasFib.<static-init>.exit.const_continue45_crit_edge.i", %const_slowPath46.i
  %65 = phi i64 [ %.pre19.i, %"Init_func_HasFib.<static-init>.exit.const_continue45_crit_edge.i" ], [ %63, %const_slowPath46.i ]
  call void @dbg_sorbet_validate_id(i64 %rubyId_fib.i, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6, i64 0, i64 0)) #19, !noalias !24
  %66 = call i64 @rb_funcallv(i64 %65, i64 %rubyId_fib.i, i32 1, i64* nonnull %callArgsAddr3.i) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1)
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @func_HasFib.fib(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #15 {
functionEntryInitializers:
  %callArgs = alloca [1 x i64], align 8
  %rubyId_fib = load i64, i64* @rubyIdPrecomputed_fib, align 8
  %"rubyId_+" = load i64, i64* @"rubyIdPrecomputed_+", align 8
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !27

BB3:                                              ; preds = %sorbet_rb_int_lt.exit
  store i64 3, i64* %callArgsAddr, align 8
  %rawSendResult39 = tail call fastcc i64 @sorbet_rb_int_minus(i64 %rawArg_n, i64 3)
  %1 = load i64, i64* @guard_epoch_HasFib, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath47 = icmp eq i64 %1, %2
  br i1 %canTakeFastPath47, label %BB3.const_continue45_crit_edge, label %const_slowPath46, !prof !16

BB3.const_continue45_crit_edge:                   ; preds = %BB3
  %.pre115 = load i64, i64* @guarded_const_HasFib, align 8
  br label %const_continue45

BB4:                                              ; preds = %136, %134, %125, %123, %117, %70, %54, %49, %"slowSymCallIntrinsic_+", %sorbet_rb_int_lt.exit
  %"<returnMethodTemp>.sroa.0.0" = phi i64 [ 3, %sorbet_rb_int_lt.exit ], [ %46, %"slowSymCallIntrinsic_+" ], [ %137, %136 ], [ %135, %134 ], [ %71, %70 ], [ %57, %54 ], [ %53, %49 ], [ %126, %125 ], [ %122, %117 ], [ -9223372036854775806, %123 ]
  ret i64 %"<returnMethodTemp>.sroa.0.0"

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_rb_error_arity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %rawArg_n = load i64, i64* %argArray, align 8
  %3 = and i64 %rawArg_n, 1
  %4 = icmp eq i64 %3, 0
  br i1 %4, label %typeTestFail, label %typeTestSuccess21, !prof !0

typeTestFail:                                     ; preds = %fillRequiredArgs
  tail call fastcc void @sorbet_cast_failure(i64 %rawArg_n, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig.6, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_Integer, i64 0, i64 0))
  unreachable

typeTestSuccess21:                                ; preds = %fillRequiredArgs
  %5 = load i64, i64* @guard_epoch_HasFib, align 8
  %6 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath = icmp eq i64 %5, %6
  br i1 %canTakeFastPath, label %typeTestSuccess21.const_continue_crit_edge, label %const_slowPath, !prof !16

typeTestSuccess21.const_continue_crit_edge:       ; preds = %typeTestSuccess21
  %.pre = load i64, i64* @guarded_const_HasFib, align 8
  br label %const_continue

const_continue:                                   ; preds = %typeTestSuccess21.const_continue_crit_edge, %const_slowPath
  %7 = phi i64 [ %.pre, %typeTestSuccess21.const_continue_crit_edge ], [ %15, %const_slowPath ]
  %8 = icmp eq i64 %7, %selfRaw
  br i1 %8, label %sorbet_rb_int_lt.exit, label %9

9:                                                ; preds = %const_continue
  %10 = load i64, i64* @rb_cModule, align 8, !tbaa !7
  %11 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %10) #19
  %12 = icmp eq i64 %11, 0
  br i1 %12, label %typeTestFail25, label %sorbet_isa_class_of.exit, !prof !20

sorbet_isa_class_of.exit:                         ; preds = %9
  %13 = tail call i64 @rb_class_inherited_p(i64 %selfRaw, i64 %7) #11
  %14 = icmp eq i64 %13, 0
  br i1 %14, label %typeTestFail25, label %sorbet_rb_int_lt.exit, !prof !0

const_slowPath:                                   ; preds = %typeTestSuccess21
  %15 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 6) #19
  store i64 %15, i64* @guarded_const_HasFib, align 8
  %16 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %16, i64* @guard_epoch_HasFib, align 8
  br label %const_continue

sorbet_rb_int_lt.exit:                            ; preds = %sorbet_isa_class_of.exit, %const_continue
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  store i64 7, i64* %callArgsAddr, align 8
  %17 = icmp slt i64 %rawArg_n, 6
  br i1 %17, label %BB4, label %BB3

typeTestFail25:                                   ; preds = %sorbet_isa_class_of.exit, %9
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast.4, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(HasFib).5", i64 0, i64 0))
  unreachable

const_continue45:                                 ; preds = %BB3.const_continue45_crit_edge, %const_slowPath46
  %18 = phi i64 [ %.pre115, %BB3.const_continue45_crit_edge ], [ %26, %const_slowPath46 ]
  %19 = icmp eq i64 %18, %selfRaw
  br i1 %19, label %sorbet_isa_class_of.exit110.thread, label %20

sorbet_isa_class_of.exit110.thread:               ; preds = %const_continue45
  store i64 %rawSendResult39, i64* %callArgsAddr, align 8
  br label %fastCallFinal_fib

20:                                               ; preds = %const_continue45
  %21 = load i64, i64* @rb_cModule, align 8, !tbaa !7
  %22 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %21) #19
  %23 = icmp eq i64 %22, 0
  br i1 %23, label %sorbet_isa_class_of.exit110.thread113, label %sorbet_isa_class_of.exit110, !prof !20

sorbet_isa_class_of.exit110.thread113:            ; preds = %20
  store i64 %rawSendResult39, i64* %callArgsAddr, align 8
  br label %slowCallFinal_fib

sorbet_isa_class_of.exit110:                      ; preds = %20
  %24 = tail call i64 @rb_class_inherited_p(i64 %selfRaw, i64 %18) #11
  %25 = icmp eq i64 %24, 0
  store i64 %rawSendResult39, i64* %callArgsAddr, align 8
  br i1 %25, label %slowCallFinal_fib, label %fastCallFinal_fib, !prof !0

const_slowPath46:                                 ; preds = %BB3
  %26 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 6) #19
  store i64 %26, i64* @guarded_const_HasFib, align 8
  %27 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %27, i64* @guard_epoch_HasFib, align 8
  br label %const_continue45

afterCallFinal_fib:                               ; preds = %slowCallFinal_fib, %fastCallFinal_fib
  %finalCallPhi_fib = phi i64 [ %directSendResult, %fastCallFinal_fib ], [ %30, %slowCallFinal_fib ]
  store i64 5, i64* %callArgsAddr, align 8
  %rawSendResult63 = call fastcc i64 @sorbet_rb_int_minus(i64 %rawArg_n, i64 5)
  %28 = load i64, i64* @guard_epoch_HasFib, align 8
  %29 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  %canTakeFastPath73 = icmp eq i64 %28, %29
  br i1 %canTakeFastPath73, label %afterCallFinal_fib.const_continue71_crit_edge, label %const_slowPath72, !prof !16

afterCallFinal_fib.const_continue71_crit_edge:    ; preds = %afterCallFinal_fib
  %.pre116 = load i64, i64* @guarded_const_HasFib, align 8
  br label %const_continue71

slowCallFinal_fib:                                ; preds = %sorbet_isa_class_of.exit110, %sorbet_isa_class_of.exit110.thread113
  tail call void @dbg_sorbet_validate_id(i64 %rubyId_fib, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6, i64 0, i64 0)) #19, !noalias !28
  %30 = call i64 @rb_funcallv(i64 %selfRaw, i64 %rubyId_fib, i32 1, i64* nonnull %callArgsAddr) #19
  br label %afterCallFinal_fib

fastCallFinal_fib:                                ; preds = %sorbet_isa_class_of.exit110, %sorbet_isa_class_of.exit110.thread
  %31 = tail call i32 @ruby_stack_check() #19
  %directSendResult = call i64 @func_HasFib.fib(i32 1, i64* nonnull %callArgsAddr, i64 %selfRaw)
  br label %afterCallFinal_fib

const_continue71:                                 ; preds = %afterCallFinal_fib.const_continue71_crit_edge, %const_slowPath72
  %32 = phi i64 [ %.pre116, %afterCallFinal_fib.const_continue71_crit_edge ], [ %40, %const_slowPath72 ]
  %33 = icmp eq i64 %32, %selfRaw
  br i1 %33, label %sorbet_isa_class_of.exit111.thread, label %34

sorbet_isa_class_of.exit111.thread:               ; preds = %const_continue71
  store i64 %rawSendResult63, i64* %callArgsAddr, align 8
  br label %fastCallFinal_fib76

34:                                               ; preds = %const_continue71
  %35 = load i64, i64* @rb_cModule, align 8, !tbaa !7
  %36 = call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %35) #19
  %37 = icmp eq i64 %36, 0
  br i1 %37, label %sorbet_isa_class_of.exit111.thread114, label %sorbet_isa_class_of.exit111, !prof !20

sorbet_isa_class_of.exit111.thread114:            ; preds = %34
  store i64 %rawSendResult63, i64* %callArgsAddr, align 8
  br label %slowCallFinal_fib75

sorbet_isa_class_of.exit111:                      ; preds = %34
  %38 = call i64 @rb_class_inherited_p(i64 %selfRaw, i64 %32) #11
  %39 = icmp eq i64 %38, 0
  store i64 %rawSendResult63, i64* %callArgsAddr, align 8
  br i1 %39, label %slowCallFinal_fib75, label %fastCallFinal_fib76, !prof !0

const_slowPath72:                                 ; preds = %afterCallFinal_fib
  %40 = call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib.1, i64 0, i64 0), i64 6) #19
  store i64 %40, i64* @guarded_const_HasFib, align 8
  %41 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !14
  store i64 %41, i64* @guard_epoch_HasFib, align 8
  br label %const_continue71

afterCallFinal_fib74:                             ; preds = %slowCallFinal_fib75, %fastCallFinal_fib76
  %finalCallPhi_fib86 = phi i64 [ %directSendResult80, %fastCallFinal_fib76 ], [ %44, %slowCallFinal_fib75 ]
  %42 = and i64 %finalCallPhi_fib, 1
  %43 = icmp eq i64 %42, 0
  store i64 %finalCallPhi_fib86, i64* %callArgsAddr, align 8
  br i1 %43, label %"slowSymCallIntrinsic_+", label %"fastSymCallIntrinsic_+", !prof !0

slowCallFinal_fib75:                              ; preds = %sorbet_isa_class_of.exit111, %sorbet_isa_class_of.exit111.thread114
  call void @dbg_sorbet_validate_id(i64 %rubyId_fib, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6, i64 0, i64 0)) #19, !noalias !31
  %44 = call i64 @rb_funcallv(i64 %selfRaw, i64 %rubyId_fib, i32 1, i64* nonnull %callArgsAddr) #19
  br label %afterCallFinal_fib74

fastCallFinal_fib76:                              ; preds = %sorbet_isa_class_of.exit111, %sorbet_isa_class_of.exit111.thread
  %45 = call i32 @ruby_stack_check() #19
  %directSendResult80 = call i64 @func_HasFib.fib(i32 1, i64* nonnull %callArgsAddr, i64 %selfRaw)
  br label %afterCallFinal_fib74

"slowSymCallIntrinsic_+":                         ; preds = %afterCallFinal_fib74
  call void @dbg_sorbet_validate_id(i64 %"rubyId_+", i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6, i64 0, i64 0)) #19, !noalias !34
  %46 = call i64 @rb_funcallv(i64 %finalCallPhi_fib, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #19
  br label %BB4

"fastSymCallIntrinsic_+":                         ; preds = %afterCallFinal_fib74
  %47 = and i64 %finalCallPhi_fib86, 1
  %48 = icmp eq i64 %47, 0
  br i1 %48, label %58, label %49, !prof !0

49:                                               ; preds = %"fastSymCallIntrinsic_+"
  %50 = add nsw i64 %finalCallPhi_fib86, -1
  %51 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %finalCallPhi_fib, i64 %50) #19
  %52 = extractvalue { i64, i1 } %51, 1
  %53 = extractvalue { i64, i1 } %51, 0
  br i1 %52, label %54, label %BB4

54:                                               ; preds = %49
  %55 = ashr i64 %53, 1
  %56 = xor i64 %55, -9223372036854775808
  %57 = call i64 @rb_int2big(i64 %56) #19, !noalias !37
  br label %BB4

58:                                               ; preds = %"fastSymCallIntrinsic_+"
  %59 = and i64 %finalCallPhi_fib86, 7
  %60 = icmp ne i64 %59, 0
  %61 = and i64 %finalCallPhi_fib86, -9
  %62 = icmp eq i64 %61, 0
  %63 = or i1 %60, %62
  br i1 %63, label %72, label %64

64:                                               ; preds = %58
  %65 = inttoptr i64 %finalCallPhi_fib86 to %struct.RBasic*
  %66 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %65, i64 0, i32 0
  %67 = load i64, i64* %66, align 8, !tbaa !1, !noalias !37
  %68 = and i64 %67, 31
  %69 = icmp eq i64 %68, 10
  br i1 %69, label %70, label %72

70:                                               ; preds = %64
  %71 = call i64 @rb_big_plus(i64 %finalCallPhi_fib86, i64 %finalCallPhi_fib) #19, !noalias !37
  br label %BB4

72:                                               ; preds = %64, %58
  %73 = and i64 %finalCallPhi_fib, 3
  %74 = icmp eq i64 %73, 2
  br i1 %74, label %87, label %75

75:                                               ; preds = %72
  %76 = and i64 %finalCallPhi_fib, 7
  %77 = icmp ne i64 %76, 0
  %78 = and i64 %finalCallPhi_fib, -9
  %79 = icmp eq i64 %78, 0
  %80 = or i1 %77, %79
  br i1 %80, label %127, label %81

81:                                               ; preds = %75
  %82 = inttoptr i64 %finalCallPhi_fib to %struct.RBasic*
  %83 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %82, i64 0, i32 0
  %84 = load i64, i64* %83, align 8, !tbaa !1, !noalias !37
  %85 = and i64 %84, 31
  %86 = icmp eq i64 %85, 4
  br i1 %86, label %87, label %127

87:                                               ; preds = %81, %72
  %88 = ashr i64 %finalCallPhi_fib, 1
  %89 = sitofp i64 %88 to double
  %90 = and i64 %finalCallPhi_fib86, 3
  %91 = icmp eq i64 %90, 2
  br i1 %91, label %92, label %103

92:                                               ; preds = %87
  %93 = icmp eq i64 %finalCallPhi_fib86, -9223372036854775806
  br i1 %93, label %rb_float_value_inline.exit.i, label %94

94:                                               ; preds = %92
  %95 = lshr i64 %finalCallPhi_fib86, 63
  %96 = sub nuw nsw i64 2, %95
  %97 = and i64 %finalCallPhi_fib86, 4
  %98 = or i64 %96, %97
  %99 = lshr i64 %finalCallPhi_fib86, 3
  %100 = shl nuw i64 %98, 61
  %101 = or i64 %100, %99
  %102 = bitcast i64 %101 to double
  br label %rb_float_value_inline.exit.i

103:                                              ; preds = %87
  %104 = inttoptr i64 %finalCallPhi_fib86 to %struct.RFloat*
  %105 = getelementptr inbounds %struct.RFloat, %struct.RFloat* %104, i64 0, i32 1
  %106 = load double, double* %105, align 8, !tbaa !11, !noalias !37
  br label %rb_float_value_inline.exit.i

rb_float_value_inline.exit.i:                     ; preds = %103, %94, %92
  %107 = phi double [ %106, %103 ], [ %102, %94 ], [ 0.000000e+00, %92 ]
  %108 = fadd double %107, %89
  %109 = bitcast double %108 to i64
  %110 = icmp eq i64 %109, 3458764513820540928
  br i1 %110, label %125, label %111

111:                                              ; preds = %rb_float_value_inline.exit.i
  %112 = lshr i64 %109, 60
  %113 = trunc i64 %112 to i32
  %114 = and i32 %113, 7
  %115 = add nsw i32 %114, -3
  %116 = icmp ugt i32 %115, 1
  br i1 %116, label %123, label %117

117:                                              ; preds = %111
  %118 = shl i64 %109, 3
  %119 = lshr i64 %109, 61
  %120 = and i64 %119, 4
  %121 = or i64 %118, %120
  %122 = or i64 %121, 2
  br label %BB4

123:                                              ; preds = %111
  %124 = icmp eq i64 %109, 0
  br i1 %124, label %BB4, label %125

125:                                              ; preds = %123, %rb_float_value_inline.exit.i
  %126 = call i64 @rb_float_new_in_heap(double %108) #19, !noalias !37
  br label %BB4

127:                                              ; preds = %81, %75
  br i1 %63, label %136, label %128

128:                                              ; preds = %127
  %129 = inttoptr i64 %finalCallPhi_fib86 to %struct.RBasic*
  %130 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %129, i64 0, i32 0
  %131 = load i64, i64* %130, align 8, !tbaa !1, !noalias !37
  %132 = and i64 %131, 31
  %133 = icmp eq i64 %132, 14
  br i1 %133, label %134, label %136

134:                                              ; preds = %128
  %135 = call i64 @rb_complex_plus(i64 %finalCallPhi_fib86, i64 %finalCallPhi_fib) #19, !noalias !37
  br label %BB4

136:                                              ; preds = %128, %127
  %137 = call i64 @rb_num_coerce_bin(i64 %finalCallPhi_fib, i64 %finalCallPhi_fib86, i64 43) #19, !noalias !37
  br label %BB4
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<"() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_<", i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @"rubyIdPrecomputed_<", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_-() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_-, i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @rubyIdPrecomputed_-, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_+"() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_+", i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @"rubyIdPrecomputed_+", align 8
  ret void
}

; Function Attrs: ssp
define internal i64 @"func_HasFib.<static-init>$block_1"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readnone %argArray, i64 %blockArg) #16 {
functionEntryInitializers:
  %callArgs = alloca [2 x i64], align 8
  %rubyId_n = load i64, i64* @rubyIdPrecomputed_n, align 8
  %rubyId_params = load i64, i64* @rubyIdPrecomputed_params, align 8
  %rubyId_returns = load i64, i64* @rubyIdPrecomputed_returns, align 8
  %rawSym = tail call i64 @rb_id2sym(i64 %rubyId_n)
  %0 = tail call i64 @rb_hash_new() #19
  %1 = load i64, i64* @rb_cInteger, align 8
  %2 = tail call i64 @rb_hash_aset(i64 %0, i64 %rawSym, i64 %1) #19
  %callArgsAddr = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 0
  store i64 %0, i64* %callArgsAddr, align 8
  %3 = inttoptr i64 %captures to %struct.RTypedData*
  %4 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %3, i64 0, i32 3
  %5 = bitcast i8** %4 to %struct.sorbet_Closure**
  %6 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %5, align 8, !tbaa !17
  %7 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %6, i64 0, i32 1, i64 0
  %8 = load i64, i64* %7, align 8
  tail call void @dbg_sorbet_validate_id(i64 %rubyId_params, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6, i64 0, i64 0)) #19, !noalias !40
  %9 = call i64 @rb_funcallv(i64 %8, i64 %rubyId_params, i32 1, i64* nonnull %callArgsAddr) #19
  store i64 %1, i64* %callArgsAddr, align 8
  call void @dbg_sorbet_validate_id(i64 %rubyId_returns, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6, i64 0, i64 0)) #19, !noalias !43
  %10 = call i64 @rb_funcallv(i64 %9, i64 %rubyId_returns, i32 1, i64* nonnull %callArgsAddr) #19
  ret i64 %10
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_final() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_final, i64 0, i64 0), i64 5) #19
  store i64 %0, i64* @rubyIdPrecomputed_final, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_sig() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig.6, i64 0, i64 0), i64 3) #19
  store i64 %0, i64* @rubyIdPrecomputed_sig, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_n() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_n, i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @rubyIdPrecomputed_n, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_params() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_params, i64 0, i64 0), i64 6) #19
  store i64 %0, i64* @rubyIdPrecomputed_params, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_returns() #13 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_returns, i64 0, i64 0), i64 7) #19
  store i64 %0, i64* @rubyIdPrecomputed_returns, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #17

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #17

attributes #0 = { nounwind ssp uwtable }
attributes #1 = { nofree nounwind }
attributes #2 = { cold noreturn }
attributes #3 = { "addedToSilenceEmptyAttrsError" }
attributes #4 = { noinline nounwind ssp uwtable }
attributes #5 = { argmemonly nofree nounwind readonly }
attributes #6 = { noreturn }
attributes #7 = { nounwind readnone }
attributes #8 = { cold noreturn nounwind optsize ssp uwtable }
attributes #9 = { noreturn nounwind ssp uwtable }
attributes #10 = { norecurse nounwind readnone ssp uwtable }
attributes #11 = { nounwind readonly }
attributes #12 = { nounwind readnone speculatable }
attributes #13 = { nounwind ssp }
attributes #14 = { nounwind sspreq }
attributes #15 = { nounwind sspreq uwtable }
attributes #16 = { ssp }
attributes #17 = { argmemonly nounwind }
attributes #18 = { cold noreturn nounwind }
attributes #19 = { nounwind }
attributes #20 = { noreturn nounwind }

!0 = !{!"branch_weights", i32 1, i32 2000}
!1 = !{!2, !3, i64 0}
!2 = !{!"RBasic", !3, i64 0, !3, i64 8}
!3 = !{!"long", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
!6 = !{!4, !4, i64 0}
!7 = !{!3, !3, i64 0}
!8 = !{!2, !3, i64 8}
!9 = !{!10, !10, i64 0}
!10 = !{!"int", !4, i64 0}
!11 = !{!12, !13, i64 16}
!12 = !{!"RFloat", !2, i64 0, !13, i64 16}
!13 = !{!"double", !4, i64 0}
!14 = !{!15, !15, i64 0}
!15 = !{!"long long", !4, i64 0}
!16 = !{!"branch_weights", i32 2000, i32 1}
!17 = !{!18, !19, i64 32}
!18 = !{!"RTypedData", !2, i64 0, !19, i64 16, !3, i64 24, !19, i64 32}
!19 = !{!"any pointer", !4, i64 0}
!20 = !{!"branch_weights", i32 1073205, i32 2146410443}
!21 = !{!22}
!22 = distinct !{!22, !23, !"sorbet_callFuncBlock: argument 0"}
!23 = distinct !{!23, !"sorbet_callFuncBlock"}
!24 = !{!25}
!25 = distinct !{!25, !26, !"sorbet_callFunc: argument 0"}
!26 = distinct !{!26, !"sorbet_callFunc"}
!27 = !{!"branch_weights", i32 4000000, i32 4001}
!28 = !{!29}
!29 = distinct !{!29, !30, !"sorbet_callFunc: argument 0"}
!30 = distinct !{!30, !"sorbet_callFunc"}
!31 = !{!32}
!32 = distinct !{!32, !33, !"sorbet_callFunc: argument 0"}
!33 = distinct !{!33, !"sorbet_callFunc"}
!34 = !{!35}
!35 = distinct !{!35, !36, !"sorbet_callFunc: argument 0"}
!36 = distinct !{!36, !"sorbet_callFunc"}
!37 = !{!38}
!38 = distinct !{!38, !39, !"sorbet_rb_int_plus: argument 0"}
!39 = distinct !{!39, !"sorbet_rb_int_plus"}
!40 = !{!41}
!41 = distinct !{!41, !42, !"sorbet_callFunc: argument 0"}
!42 = distinct !{!42, !"sorbet_callFunc"}
!43 = !{!44}
!44 = distinct !{!44, !45, !"sorbet_callFunc: argument 0"}
!45 = distinct !{!45, !"sorbet_callFunc"}
