; ModuleID = 'payload'
source_filename = "compiler/IREmitter/Payload/payload.c"
target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"

%struct.rb_data_type_struct = type { i8*, %struct.anon.1, %struct.rb_data_type_struct*, i8*, i64 }
%struct.anon.1 = type { void (i8*)*, void (i8*)*, i64 (i8*)*, [2 x i8*] }
%struct.RBasic = type { i64, i64 }
%struct.RString = type { %struct.RBasic, %union.anon }
%union.anon = type { %struct.anon }
%struct.anon = type { i64, i8*, %union.anon.0 }
%union.anon.0 = type { i64 }
%struct.OnigEncodingTypeST = type { i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i8*, i32, i32, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8**, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i32 (i32, i32*, i32, i8*)*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32, i8*, i8*, %struct.OnigCaseFoldCodeItem*, %struct.OnigEncodingTypeST*)*, i32 (%struct.OnigEncodingTypeST*, i8*, i8*)*, i32 (i32, i32, %struct.OnigEncodingTypeST*)*, i32 (i32, i32*, i32**, %struct.OnigEncodingTypeST*)*, i8* (i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i8*, i8*, %struct.OnigEncodingTypeST*)*, i32 (i32*, i8**, i8*, i8*, i8*, %struct.OnigEncodingTypeST*)*, i32, i32 }
%struct.OnigCaseFoldCodeItem = type { i32, i32, [3 x i32] }
%struct.RTypedData = type { %struct.RBasic, %struct.rb_data_type_struct*, i64, i8* }
%struct.sorbet_Closure = type { i32, [0 x i64] }
%struct.RFloat = type { %struct.RBasic, double }

@.str = private unnamed_addr constant [5 x i8] c"%li\0B\00", align 1
@rb_cObject = external local_unnamed_addr constant i64, align 8
@ruby_vm_global_constant_state = external local_unnamed_addr global i64, align 8
@rb_eRuntimeError = external local_unnamed_addr global i64, align 8
@.str.1 = private unnamed_addr constant [29 x i8] c"wrong constant name %li\0B%li\0B\00", align 1
@rb_eTypeError = external local_unnamed_addr global i64, align 8
@.str.2 = private unnamed_addr constant [36 x i8] c"%li\0B does not refer to class/module\00", align 1
@sorbet_getConstantAt.rb_intern_id_cache = internal unnamed_addr global i64 0, align 8
@.str.3 = private unnamed_addr constant [14 x i8] c"const_missing\00", align 1
@.str.4 = private unnamed_addr constant [50 x i8] c"wrong number of arguments (given %d, expected %d)\00", align 1
@rb_eArgError = external local_unnamed_addr global i64, align 8
@.str.7 = private unnamed_addr constant [45 x i8] c"%s: Expected type %s, got %s with value %li\0B\00", align 1
@.str.8 = private unnamed_addr constant [16 x i8] c"CompiledClosure\00", align 1
@closureInfo = constant %struct.rb_data_type_struct { i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.8, i32 0, i32 0), %struct.anon.1 { void (i8*)* @sorbet_Closure_mark, void (i8*)* inttoptr (i64 -1 to void (i8*)*), i64 (i8*)* @sorbet_Closure_size, [2 x i8*] zeroinitializer }, %struct.rb_data_type_struct* null, i8* null, i64 1 }, align 8
@rb_cData = external local_unnamed_addr constant i64, align 8
@rb_cModule = external local_unnamed_addr constant i64, align 8
@"rubyIdPrecomputed_<static-init>" = internal unnamed_addr global i64 0, align 8
@"str_<static-init>" = private unnamed_addr constant [14 x i8] c"<static-init>\00", align 1
@str_cast = private unnamed_addr constant [5 x i8] c"cast\00", align 1
@rubyIdPrecomputed_unsafe = internal unnamed_addr global i64 0, align 8
@str_unsafe = private unnamed_addr constant [7 x i8] c"unsafe\00", align 1
@str_HasFib = private unnamed_addr constant [7 x i8] c"HasFib\00", align 1
@rubyIdPrecomputed_fib = internal unnamed_addr global i64 0, align 8
@str_fib = private unnamed_addr constant [4 x i8] c"fib\00", align 1
@str_sig = private unnamed_addr constant [4 x i8] c"sig\00", align 1
@str_Integer = private unnamed_addr constant [8 x i8] c"Integer\00", align 1
@"str_T.class_of(HasFib)" = private unnamed_addr constant [19 x i8] c"T.class_of(HasFib)\00", align 1
@"rubyIdPrecomputed_<" = internal unnamed_addr global i64 0, align 8
@"str_<" = private unnamed_addr constant [2 x i8] c"<\00", align 1
@rubyIdPrecomputed_- = internal unnamed_addr global i64 0, align 8
@str_- = private unnamed_addr constant [2 x i8] c"-\00", align 1
@"rubyIdPrecomputed_+" = internal unnamed_addr global i64 0, align 8
@"str_+" = private unnamed_addr constant [2 x i8] c"+\00", align 1
@rubyIdPrecomputed_final = internal unnamed_addr global i64 0, align 8
@str_final = private unnamed_addr constant [6 x i8] c"final\00", align 1
@rubyIdPrecomputed_sig = internal unnamed_addr global i64 0, align 8
@"str_T::Sig::WithoutRuntime" = private unnamed_addr constant [23 x i8] c"T::Sig::WithoutRuntime\00", align 1
@rubyIdPrecomputed_n = internal unnamed_addr global i64 0, align 8
@str_n = private unnamed_addr constant [2 x i8] c"n\00", align 1
@rubyIdPrecomputed_params = internal unnamed_addr global i64 0, align 8
@str_params = private unnamed_addr constant [7 x i8] c"params\00", align 1
@rubyIdPrecomputed_returns = internal unnamed_addr global i64 0, align 8
@str_returns = private unnamed_addr constant [8 x i8] c"returns\00", align 1
@llvm.global_ctors = appending global [11 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<static-init>", i8* bitcast (i64* @"rubyIdPrecomputed_<static-init>" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_unsafe, i8* bitcast (i64* @rubyIdPrecomputed_unsafe to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_fib, i8* bitcast (i64* @rubyIdPrecomputed_fib to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_<", i8* bitcast (i64* @"rubyIdPrecomputed_<" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_-, i8* bitcast (i64* @rubyIdPrecomputed_- to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @"Constr_rubyIdPrecomputed_+", i8* bitcast (i64* @"rubyIdPrecomputed_+" to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_final, i8* bitcast (i64* @rubyIdPrecomputed_final to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_sig, i8* bitcast (i64* @rubyIdPrecomputed_sig to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_n, i8* bitcast (i64* @rubyIdPrecomputed_n to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_params, i8* bitcast (i64* @rubyIdPrecomputed_params to i8*) }, { i32, void ()*, i8* } { i32 0, void ()* @Constr_rubyIdPrecomputed_returns, i8* bitcast (i64* @rubyIdPrecomputed_returns to i8*) }]
@guard_epoch_HasFib = linkonce local_unnamed_addr global i64 0
@guarded_const_HasFib = linkonce local_unnamed_addr global i64 0
@"guard_epoch_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@"guarded_const_T::Sig::WithoutRuntime" = linkonce local_unnamed_addr global i64 0
@rb_cInteger = external local_unnamed_addr constant i64

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_pi(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i8* @rb_id2name(i64 %0) #19
  ret i8* %2
}

declare i8* @rb_id2name(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak i8* @dbg_p(i64 %0) local_unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #19
  %3 = inttoptr i64 %2 to %struct.RBasic*
  %4 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %3, i64 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !0
  %6 = and i64 %5, 8192
  %7 = icmp eq i64 %6, 0
  %8 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str, i64 0, i64 0), i64 %0) #19
  %9 = inttoptr i64 %8 to %struct.RString*
  br i1 %7, label %10, label %13

10:                                               ; preds = %1
  %11 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1
  %12 = bitcast %union.anon* %11 to i8*
  br label %16

13:                                               ; preds = %1
  %14 = getelementptr inbounds %struct.RString, %struct.RString* %9, i64 0, i32 1, i32 0, i32 1
  %15 = load i8*, i8** %14, align 8, !tbaa !5
  br label %16

16:                                               ; preds = %13, %10
  %17 = phi i8* [ %12, %10 ], [ %15, %13 ]
  ret i8* %17
}

declare i64 @rb_sprintf(i8*, ...) local_unnamed_addr #1

declare i64 @rb_hash_new() local_unnamed_addr #1

declare i64 @rb_intern2(i8*, i64) local_unnamed_addr #1

declare i64 @rb_id2sym(i64) local_unnamed_addr #1

declare i8* @rb_obj_classname(i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstantAt(i64 %0, i64 %1) unnamed_addr #2 {
  %3 = tail call i64 @rb_id2sym(i64 %1) #19
  %4 = tail call %struct.OnigEncodingTypeST* @rb_enc_get(i64 %3) #19
  %5 = tail call i8* @rb_id2name(i64 %1) #19
  %6 = tail call i64 @strlen(i8* nonnull dereferenceable(1) %5)
  %7 = getelementptr inbounds i8, i8* %5, i64 %6
  %8 = icmp sgt i64 %6, 0
  br i1 %8, label %9, label %.loopexit11

9:                                                ; preds = %2
  %10 = ptrtoint i8* %5 to i64
  br label %13

.loopexit10:                                      ; preds = %91, %44, %41, %28, %107
  %11 = phi i64 [ %108, %107 ], [ %3, %28 ], [ %3, %44 ], [ %3, %41 ], [ %66, %91 ]
  %12 = load i64, i64* @rb_eRuntimeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %12, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.1, i64 0, i64 0), i64 %14, i64 %11) #20
  unreachable

13:                                               ; preds = %115, %9
  %14 = phi i64 [ %0, %9 ], [ %116, %115 ]
  %15 = phi i8* [ %5, %9 ], [ %50, %115 ]
  %16 = phi i8* [ %5, %9 ], [ %49, %115 ]
  %17 = icmp ult i8* %16, %7
  br i1 %17, label %18, label %28

18:                                               ; preds = %13
  %19 = load i8, i8* %16, align 1, !tbaa !5
  %20 = icmp eq i8 %19, 58
  br i1 %20, label %28, label %.preheader

21:                                               ; preds = %.preheader
  %22 = load i8, i8* %25, align 1, !tbaa !5
  %23 = icmp eq i8 %22, 58
  br i1 %23, label %.loopexit, label %.preheader

.preheader:                                       ; preds = %18, %21
  %24 = phi i8* [ %25, %21 ], [ %16, %18 ]
  %25 = getelementptr inbounds i8, i8* %24, i64 1
  %26 = icmp eq i8* %25, %7
  br i1 %26, label %.loopexit, label %21

.loopexit:                                        ; preds = %21, %.preheader
  %.lcssa = phi i8* [ %25, %21 ], [ %7, %.preheader ]
  %27 = icmp ult i8* %.lcssa, %7
  br label %28

28:                                               ; preds = %.loopexit, %18, %13
  %29 = phi i8* [ %16, %13 ], [ %16, %18 ], [ %.lcssa, %.loopexit ]
  %30 = phi i1 [ false, %13 ], [ true, %18 ], [ %27, %.loopexit ]
  %31 = icmp eq i8* %15, %29
  br i1 %31, label %.loopexit10, label %32

32:                                               ; preds = %28
  %33 = ptrtoint i8* %29 to i64
  %34 = ptrtoint i8* %15 to i64
  %35 = sub i64 %33, %34
  %36 = tail call i64 @rb_check_id_cstr(i8* %15, i64 %35, %struct.OnigEncodingTypeST* %4) #19
  %37 = sub i64 %34, %10
  br i1 %30, label %38, label %48

38:                                               ; preds = %32
  %39 = load i8, i8* %29, align 1, !tbaa !5
  %40 = icmp eq i8 %39, 58
  br i1 %40, label %41, label %48

41:                                               ; preds = %38
  %42 = getelementptr inbounds i8, i8* %29, i64 2
  %43 = icmp ult i8* %42, %7
  br i1 %43, label %44, label %.loopexit10

44:                                               ; preds = %41
  %45 = getelementptr inbounds i8, i8* %29, i64 1
  %46 = load i8, i8* %45, align 1, !tbaa !5
  %47 = icmp eq i8 %46, 58
  br i1 %47, label %48, label %.loopexit10

48:                                               ; preds = %44, %38, %32
  %49 = phi i8* [ %29, %38 ], [ %29, %32 ], [ %42, %44 ]
  %50 = phi i8* [ %15, %38 ], [ %15, %32 ], [ %42, %44 ]
  %51 = and i64 %14, 7
  %52 = icmp ne i64 %51, 0
  %53 = and i64 %14, -9
  %54 = icmp eq i64 %53, 0
  %55 = or i1 %52, %54
  br i1 %55, label %61, label %56

56:                                               ; preds = %48
  %57 = inttoptr i64 %14 to %struct.RBasic*
  %58 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 0
  %59 = load i64, i64* %58, align 8, !tbaa !0
  %60 = and i64 %59, 30
  %switch = icmp eq i64 %60, 2
  br i1 %switch, label %63, label %61

61:                                               ; preds = %56, %48
  %62 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  tail call void (i64, i8*, ...) @rb_raise(i64 %62, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.2, i64 0, i64 0), i64 %3) #20
  unreachable

63:                                               ; preds = %56
  %64 = icmp eq i64 %36, 0
  br i1 %64, label %65, label %104

65:                                               ; preds = %63
  %66 = tail call i64 @rb_str_subseq(i64 %3, i64 %37, i64 %35) #19
  %67 = and i64 %66, 7
  %68 = icmp ne i64 %67, 0
  %69 = and i64 %66, -9
  %70 = icmp eq i64 %69, 0
  %71 = or i1 %68, %70
  br i1 %71, label %rb_obj_freeze_inline.exit, label %72

72:                                               ; preds = %65
  %73 = inttoptr i64 %66 to %struct.RBasic*
  %74 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 0
  %75 = load i64, i64* %74, align 8, !tbaa !0
  %76 = and i64 %75, 31
  %77 = icmp eq i64 %76, 27
  br i1 %77, label %rb_obj_freeze_inline.exit, label %78

78:                                               ; preds = %72
  %79 = or i64 %75, 2048
  store i64 %79, i64* %74, align 8, !tbaa !0
  %80 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %73, i64 0, i32 1
  %81 = load i64, i64* %80, align 8, !tbaa !7
  %82 = icmp ne i64 %81, 0
  %83 = and i64 %75, 4096
  %84 = icmp eq i64 %83, 0
  %85 = and i1 %84, %82
  br i1 %85, label %86, label %rb_obj_freeze_inline.exit

86:                                               ; preds = %78
  tail call void @rb_freeze_singleton_class(i64 %66) #19
  br label %rb_obj_freeze_inline.exit

rb_obj_freeze_inline.exit:                        ; preds = %65, %72, %78, %86
  %87 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %89, label %91

89:                                               ; preds = %rb_obj_freeze_inline.exit
  %90 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.3, i64 0, i64 0), i64 13) #19
  store i64 %90, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  br label %91

91:                                               ; preds = %89, %rb_obj_freeze_inline.exit
  %92 = load i64, i64* @sorbet_getConstantAt.rb_intern_id_cache, align 8, !tbaa !6
  %93 = tail call i32 @rb_is_const_name(i64 %66) #19
  %94 = icmp eq i32 %93, 0
  br i1 %94, label %.loopexit10, label %rb_class_of.exit

rb_class_of.exit:                                 ; preds = %91
  %95 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %57, i64 0, i32 1
  %96 = load i64, i64* %95, align 8, !tbaa !6
  %97 = tail call i32 @rb_method_basic_definition_p(i64 %96, i64 %92) #19
  %98 = icmp eq i32 %97, 0
  br i1 %98, label %99, label %102

99:                                               ; preds = %rb_class_of.exit
  %100 = tail call i64 @rb_str_intern(i64 %66) #19
  %101 = tail call i64 @rb_const_missing(i64 %14, i64 %100) #19
  br label %115

102:                                              ; preds = %rb_class_of.exit
  %103 = tail call i64 @rb_mod_const_missing(i64 %14, i64 %66) #20
  unreachable

104:                                              ; preds = %63
  %105 = tail call i32 @rb_is_const_id(i64 %36) #5
  %106 = icmp eq i32 %105, 0
  br i1 %106, label %107, label %109

107:                                              ; preds = %104
  %108 = tail call i64 @rb_id2sym(i64 %36) #19
  br label %.loopexit10

109:                                              ; preds = %104
  %110 = icmp eq i64 %37, 0
  br i1 %110, label %111, label %113

111:                                              ; preds = %109
  %112 = tail call i64 @rb_const_get(i64 %14, i64 %36) #19
  br label %115

113:                                              ; preds = %109
  %114 = tail call i64 @rb_const_get_from(i64 %14, i64 %36) #19
  br label %115

115:                                              ; preds = %113, %111, %99
  %116 = phi i64 [ %101, %99 ], [ %112, %111 ], [ %114, %113 ]
  %117 = icmp ult i8* %49, %7
  br i1 %117, label %13, label %.loopexit11

.loopexit11:                                      ; preds = %115, %2
  %118 = phi i64 [ %0, %2 ], [ %116, %115 ]
  ret i64 %118
}

declare %struct.OnigEncodingTypeST* @rb_enc_get(i64) local_unnamed_addr #1

; Function Attrs: argmemonly nofree nounwind readonly
declare i64 @strlen(i8* nocapture) local_unnamed_addr #3

; Function Attrs: noreturn
declare void @rb_raise(i64, i8*, ...) local_unnamed_addr #4

declare i64 @rb_check_id_cstr(i8*, i64, %struct.OnigEncodingTypeST*) local_unnamed_addr #1

declare i64 @rb_str_subseq(i64, i64, i64) local_unnamed_addr #1

declare i32 @rb_is_const_name(i64) local_unnamed_addr #1

declare i32 @rb_method_basic_definition_p(i64, i64) local_unnamed_addr #1

declare i64 @rb_str_intern(i64) local_unnamed_addr #1

declare i64 @rb_const_missing(i64, i64) local_unnamed_addr #1

; Function Attrs: noreturn
declare i64 @rb_mod_const_missing(i64, i64) local_unnamed_addr #4

; Function Attrs: nounwind readnone
declare i32 @rb_is_const_id(i64) local_unnamed_addr #5

declare i64 @rb_const_get(i64, i64) local_unnamed_addr #1

declare i64 @rb_const_get_from(i64, i64) local_unnamed_addr #1

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc i64 @sorbet_getConstant(i8* %0, i64 %1) unnamed_addr #2 {
  %3 = load i64, i64* @rb_cObject, align 8, !tbaa !6
  %4 = tail call i64 @rb_intern2(i8* %0, i64 %1) #19
  %5 = tail call fastcc i64 @sorbet_getConstantAt(i64 %3, i64 %4)
  ret i64 %5
}

declare i64 @rb_define_class(i8*, i64) local_unnamed_addr #1

declare void @rb_define_singleton_method(i64, i8*, i64 (...)*, i32) local_unnamed_addr #1

declare i64 @rb_funcallv(i64, i64, i32, i64*) local_unnamed_addr #1

declare i64 @rb_block_call(i64, i64, i32, i64*, i64 (...)*, i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal fastcc i64 @sorbet_rb_arity_error_new(i32 %0) unnamed_addr #0 {
  %2 = tail call i64 (i8*, ...) @rb_sprintf(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.4, i64 0, i64 0), i32 %0, i32 1) #19
  %3 = load i64, i64* @rb_eArgError, align 8, !tbaa !6
  %4 = tail call i64 @rb_exc_new_str(i64 %3, i64 %2) #19
  ret i64 %4
}

declare i64 @rb_exc_new_str(i64, i64) local_unnamed_addr #1

; Function Attrs: cold minsize noreturn nounwind optsize ssp uwtable
define internal fastcc void @sorbet_cast_failure(i64 %0, i8* %1, i8* %2) unnamed_addr #6 {
  %4 = load i64, i64* @rb_eTypeError, align 8, !tbaa !6
  %5 = tail call i8* @rb_obj_classname(i64 %0) #19
  tail call void (i64, i8*, ...) @rb_raise(i64 %4, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.7, i64 0, i64 0), i8* %1, i8* %2, i8* %5, i64 %0) #20
  unreachable
}

; Function Attrs: noreturn nounwind ssp uwtable
define internal fastcc void @sorbet_raiseArity(i32 %0) unnamed_addr #7 {
  %2 = tail call fastcc i64 @sorbet_rb_arity_error_new(i32 %0)
  tail call void @rb_exc_raise(i64 %2) #20
  unreachable
}

; Function Attrs: noreturn
declare void @rb_exc_raise(i64) local_unnamed_addr #4

; Function Attrs: inaccessiblememonly
declare i32 @ruby_stack_check() local_unnamed_addr #8

declare i8* @ruby_xmalloc(i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal void @sorbet_Closure_mark(i8* %0) #0 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  %6 = bitcast i8* %5 to i64*
  tail call void @rb_gc_mark_values(i64 %4, i64* nonnull %6) #19
  ret void
}

declare void @rb_gc_mark_values(i64, i64*) local_unnamed_addr #1

; Function Attrs: norecurse nounwind readnone ssp uwtable
define internal i64 @sorbet_Closure_size(i8* nocapture readonly %0) #9 {
  %2 = bitcast i8* %0 to i32*
  %3 = load i32, i32* %2, align 8, !tbaa !8
  %4 = sext i32 %3 to i64
  %5 = shl nsw i64 %4, 3
  %6 = add nsw i64 %5, 8
  ret i64 %6
}

declare i64 @rb_data_typed_object_wrap(i64, i8*, %struct.rb_data_type_struct*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare i64 @rb_obj_is_kind_of(i64, i64) local_unnamed_addr #5

; Function Attrs: nounwind readnone
declare i64 @rb_class_inherited_p(i64, i64) local_unnamed_addr #5

declare void @rb_hash_bulk_insert(i64, i64*, i64) local_unnamed_addr #1

declare i64 @rb_big_plus(i64, i64) local_unnamed_addr #1

declare i64 @rb_complex_plus(i64, i64) local_unnamed_addr #1

declare i64 @rb_num_coerce_bin(i64, i64, i64) local_unnamed_addr #1

declare i64 @rb_int2big(i64) local_unnamed_addr #1

declare i64 @rb_big_minus(i64, i64) local_unnamed_addr #1

declare i64 @rb_float_new_in_heap(double) local_unnamed_addr #1

declare void @rb_ary_detransient(i64) local_unnamed_addr #1

declare void @rb_freeze_singleton_class(i64) local_unnamed_addr #1

; Function Attrs: nounwind readnone speculatable willreturn
declare { i64, i1 } @llvm.sadd.with.overflow.i64(i64, i64) #10

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<static-init>"() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @"str_<static-init>", i64 0, i64 0), i64 13) #19
  store i64 %0, i64* @"rubyIdPrecomputed_<static-init>", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_unsafe() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_unsafe, i64 0, i64 0), i64 6) #19
  store i64 %0, i64* @rubyIdPrecomputed_unsafe, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_fib() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_fib, i64 0, i64 0), i64 3) #19
  store i64 %0, i64* @rubyIdPrecomputed_fib, align 8
  ret void
}

; Function Attrs: nounwind sspreq
define void @Init_test_testdata_ruby_benchmark_app_fib() local_unnamed_addr #12 {
afterSymCallIntrinsic_unsafe.i:
  %callArgs.i.i.i = alloca [2 x i64], align 8
  %callArgs.i = alloca [1 x i64], align 8
  %0 = load i64, i64* @rb_cObject, align 8
  %1 = bitcast [1 x i64]* %callArgs.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1)
  %rubyId_fib.i = load i64, i64* @rubyIdPrecomputed_fib, align 8
  %callArgsAddr.i = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs.i, i64 0, i64 0
  store i64 %0, i64* %callArgsAddr.i, align 8
  %2 = tail call i64 @rb_define_class(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib, i64 0, i64 0), i64 %0) #19
  %3 = load i64, i64* @guard_epoch_HasFib, align 8
  %4 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath = icmp eq i64 %3, %4
  br i1 %needTakeSlowPath, label %6, label %5, !prof !12

5:                                                ; preds = %afterSymCallIntrinsic_unsafe.i
  tail call void @const_recompute_HasFib() #19
  br label %6

6:                                                ; preds = %afterSymCallIntrinsic_unsafe.i, %5
  %7 = load i64, i64* @guarded_const_HasFib, align 8
  %8 = load i64, i64* @guard_epoch_HasFib, align 8
  %9 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated = icmp eq i64 %8, %9
  tail call void @llvm.assume(i1 %guardUpdated)
  %10 = bitcast [2 x i64]* %callArgs.i.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %10) #19
  %11 = tail call i8* @ruby_xmalloc(i64 16) #19
  %12 = bitcast i8* %11 to i32*
  store i32 1, i32* %12, align 8, !tbaa !8
  %13 = load i64, i64* @rb_cData, align 8, !tbaa !6
  %14 = tail call i64 @rb_data_typed_object_wrap(i64 %13, i8* %11, %struct.rb_data_type_struct* nonnull @closureInfo) #19
  %15 = inttoptr i64 %14 to %struct.RTypedData*
  %16 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %15, i64 0, i32 3
  %17 = bitcast i8** %16 to %struct.sorbet_Closure**
  %18 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %17, align 8, !tbaa !13
  %19 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %18, i64 0, i32 1, i64 0
  store i64 8, i64* %19, align 8
  %rubyId_final.i.i.i = load i64, i64* @rubyIdPrecomputed_final, align 8
  %rubyId_sig.i.i.i = load i64, i64* @rubyIdPrecomputed_sig, align 8
  %rubyId_fib.i.i.i = load i64, i64* @rubyIdPrecomputed_fib, align 8
  %20 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %17, align 8, !tbaa !13
  %21 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %20, i64 0, i32 1, i64 0
  store i64 %7, i64* %21, align 8
  %22 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %17, align 8, !tbaa !13
  %23 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %22, i64 0, i32 1, i64 0
  %24 = load i64, i64* %23, align 8
  %25 = icmp eq i64 %24, %7
  br i1 %25, label %"func_<root>.<static-init>$111.exit", label %26

26:                                               ; preds = %6
  %27 = load i64, i64* @rb_cModule, align 8, !tbaa !6
  %28 = tail call i64 @rb_obj_is_kind_of(i64 %24, i64 %27) #5
  %29 = icmp eq i64 %28, 0
  br i1 %29, label %codeRepl, label %sorbet_isa_class_of.exit.i.i.i, !prof !16

sorbet_isa_class_of.exit.i.i.i:                   ; preds = %26
  %30 = tail call i64 @rb_class_inherited_p(i64 %24, i64 %7) #5
  %31 = icmp eq i64 %30, 0
  br i1 %31, label %codeRepl, label %"func_<root>.<static-init>$111.exit", !prof !17, !misexpect !18

codeRepl:                                         ; preds = %26, %sorbet_isa_class_of.exit.i.i.i
  tail call fastcc void @Init_test_testdata_ruby_benchmark_app_fib.cold.1(i64 %24) #21
  unreachable

"func_<root>.<static-init>$111.exit":             ; preds = %6, %sorbet_isa_class_of.exit.i.i.i
  %rawSym.i.i.i = tail call i64 @rb_id2sym(i64 %rubyId_final.i.i.i) #19
  %callArgsAddr.i.i.i = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs.i.i.i, i64 0, i64 0
  store i64 %rawSym.i.i.i, i64* %callArgsAddr.i.i.i, align 8
  %32 = load i64, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  %33 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath6 = icmp eq i64 %32, %33
  br i1 %needTakeSlowPath6, label %35, label %34, !prof !12

34:                                               ; preds = %"func_<root>.<static-init>$111.exit"
  tail call void @"const_recompute_T::Sig::WithoutRuntime"() #19
  br label %35

35:                                               ; preds = %"func_<root>.<static-init>$111.exit", %34
  %36 = load i64, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  %37 = load i64, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  %38 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated7 = icmp eq i64 %37, %38
  tail call void @llvm.assume(i1 %guardUpdated7)
  %39 = call i64 @rb_block_call(i64 %36, i64 %rubyId_sig.i.i.i, i32 1, i64* nonnull %callArgsAddr.i.i.i, i64 (...)* bitcast (i64 (i64, i64, i32, i64*, i64)* @"func_HasFib.<static-init>$block_1" to i64 (...)*), i64 %14) #19
  store i64 %0, i64* %callArgsAddr.i.i.i, align 8
  %rawSym31.i.i.i = call i64 @rb_id2sym(i64 %rubyId_fib.i.i.i) #19
  call void @rb_define_singleton_method(i64 %7, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_fib, i64 0, i64 0), i64 (...)* bitcast (i64 (i32, i64*, i64)* @func_HasFib.fib to i64 (...)*), i32 -1) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %10) #19
  store i64 69, i64* %callArgsAddr.i, align 8
  %40 = call i64 @rb_funcallv(i64 %7, i64 %rubyId_fib.i, i32 1, i64* nonnull %callArgsAddr.i) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1)
  ret void
}

; Function Attrs: nounwind sspreq uwtable
define i64 @func_HasFib.fib(i32 %argc, i64* nocapture readonly %argArray, i64 %selfRaw) #13 {
functionEntryInitializers:
  %callArgs = alloca [1 x i64], align 8
  %"rubyId_+" = load i64, i64* @"rubyIdPrecomputed_+", align 8
  %0 = icmp eq i32 %argc, 1
  br i1 %0, label %fillRequiredArgs, label %argCountFailBlock, !prof !19, !misexpect !20

BB4:                                              ; preds = %166, %164, %155, %153, %147, %100, %84, %79, %"slowSymCallIntrinsic_+", %sorbet_rb_int_lt.exit
  %"<returnMethodTemp>.sroa.0.0" = phi i64 [ 3, %sorbet_rb_int_lt.exit ], [ %76, %"slowSymCallIntrinsic_+" ], [ %167, %166 ], [ %165, %164 ], [ %101, %100 ], [ %87, %84 ], [ %83, %79 ], [ %156, %155 ], [ %152, %147 ], [ -9223372036854775806, %153 ]
  ret i64 %"<returnMethodTemp>.sroa.0.0"

argCountFailBlock:                                ; preds = %functionEntryInitializers
  tail call fastcc void @sorbet_raiseArity(i32 %argc)
  unreachable

fillRequiredArgs:                                 ; preds = %functionEntryInitializers
  %rawArg_n = load i64, i64* %argArray, align 8
  %1 = and i64 %rawArg_n, 1
  %2 = icmp eq i64 %1, 0
  br i1 %2, label %codeRepl, label %typeTestSuccess21, !prof !17, !misexpect !18

codeRepl:                                         ; preds = %fillRequiredArgs
  tail call fastcc void @func_HasFib.fib.cold.1(i64 %rawArg_n) #21
  unreachable

typeTestSuccess21:                                ; preds = %fillRequiredArgs
  %3 = load i64, i64* @guard_epoch_HasFib, align 8
  %4 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %needTakeSlowPath = icmp eq i64 %3, %4
  br i1 %needTakeSlowPath, label %6, label %5, !prof !12

5:                                                ; preds = %typeTestSuccess21
  tail call void @const_recompute_HasFib() #19
  br label %6

6:                                                ; preds = %typeTestSuccess21, %5
  %7 = load i64, i64* @guarded_const_HasFib, align 8
  %8 = load i64, i64* @guard_epoch_HasFib, align 8
  %9 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  %guardUpdated = icmp eq i64 %8, %9
  tail call void @llvm.assume(i1 %guardUpdated)
  %10 = icmp eq i64 %7, %selfRaw
  br i1 %10, label %sorbet_rb_int_lt.exit, label %11

11:                                               ; preds = %6
  %12 = load i64, i64* @rb_cModule, align 8, !tbaa !6
  %13 = tail call i64 @rb_obj_is_kind_of(i64 %selfRaw, i64 %12) #5
  %14 = icmp eq i64 %13, 0
  br i1 %14, label %codeRepl114, label %sorbet_isa_class_of.exit, !prof !16

sorbet_isa_class_of.exit:                         ; preds = %11
  %15 = tail call i64 @rb_class_inherited_p(i64 %selfRaw, i64 %7) #5
  %16 = icmp eq i64 %15, 0
  br i1 %16, label %codeRepl114, label %sorbet_rb_int_lt.exit, !prof !17, !misexpect !18

sorbet_rb_int_lt.exit:                            ; preds = %sorbet_isa_class_of.exit, %6
  %callArgsAddr = getelementptr inbounds [1 x i64], [1 x i64]* %callArgs, i64 0, i64 0
  store i64 7, i64* %callArgsAddr, align 8
  %17 = icmp slt i64 %rawArg_n, 6
  br i1 %17, label %BB4, label %fastSymCallIntrinsic_-

codeRepl114:                                      ; preds = %11, %sorbet_isa_class_of.exit
  tail call fastcc void @func_HasFib.fib.cold.2(i64 %selfRaw) #21
  unreachable

fastSymCallIntrinsic_-:                           ; preds = %sorbet_rb_int_lt.exit
  %18 = and i64 %rawArg_n, 1
  %19 = icmp eq i64 %18, 0
  br i1 %19, label %28, label %20, !prof !17

20:                                               ; preds = %fastSymCallIntrinsic_-
  %21 = tail call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %rawArg_n, i64 -2)
  %22 = extractvalue { i64, i1 } %21, 1
  %23 = extractvalue { i64, i1 } %21, 0
  br i1 %22, label %24, label %sorbet_rb_int_minus.exit

24:                                               ; preds = %20
  %25 = ashr i64 %23, 1
  %26 = xor i64 %25, -9223372036854775808
  %27 = tail call i64 @rb_int2big(i64 %26) #19
  br label %sorbet_rb_int_minus.exit

28:                                               ; preds = %fastSymCallIntrinsic_-
  %29 = and i64 %rawArg_n, 7
  %30 = icmp ne i64 %29, 0
  %31 = and i64 %rawArg_n, -9
  %32 = icmp eq i64 %31, 0
  %33 = or i1 %30, %32
  br i1 %33, label %42, label %34

34:                                               ; preds = %28
  %35 = inttoptr i64 %rawArg_n to %struct.RBasic*
  %36 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %35, i64 0, i32 0
  %37 = load i64, i64* %36, align 8, !tbaa !0
  %38 = and i64 %37, 31
  %39 = icmp eq i64 %38, 10
  br i1 %39, label %40, label %42

40:                                               ; preds = %34
  %41 = tail call i64 @rb_big_minus(i64 %rawArg_n, i64 3) #19
  br label %sorbet_rb_int_minus.exit

42:                                               ; preds = %34, %28
  %43 = tail call i64 @rb_num_coerce_bin(i64 %rawArg_n, i64 3, i64 45) #19
  br label %sorbet_rb_int_minus.exit

sorbet_rb_int_minus.exit:                         ; preds = %20, %24, %40, %42
  %44 = phi i64 [ %43, %42 ], [ %41, %40 ], [ %27, %24 ], [ %23, %20 ]
  store i64 %44, i64* %callArgsAddr, align 8
  %45 = tail call i32 @ruby_stack_check() #19
  %directSendResult = call i64 @func_HasFib.fib(i32 1, i64* nonnull %callArgsAddr, i64 %selfRaw)
  %46 = and i64 %rawArg_n, 1
  %47 = icmp eq i64 %46, 0
  br i1 %47, label %56, label %48, !prof !17

48:                                               ; preds = %sorbet_rb_int_minus.exit
  %49 = tail call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %rawArg_n, i64 -4)
  %50 = extractvalue { i64, i1 } %49, 1
  %51 = extractvalue { i64, i1 } %49, 0
  br i1 %50, label %52, label %sorbet_rb_int_minus.exit118

52:                                               ; preds = %48
  %53 = ashr i64 %51, 1
  %54 = xor i64 %53, -9223372036854775808
  %55 = tail call i64 @rb_int2big(i64 %54) #19
  br label %sorbet_rb_int_minus.exit118

56:                                               ; preds = %sorbet_rb_int_minus.exit
  %57 = and i64 %rawArg_n, 7
  %58 = icmp ne i64 %57, 0
  %59 = and i64 %rawArg_n, -9
  %60 = icmp eq i64 %59, 0
  %61 = or i1 %58, %60
  br i1 %61, label %70, label %62

62:                                               ; preds = %56
  %63 = inttoptr i64 %rawArg_n to %struct.RBasic*
  %64 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %63, i64 0, i32 0
  %65 = load i64, i64* %64, align 8, !tbaa !0
  %66 = and i64 %65, 31
  %67 = icmp eq i64 %66, 10
  br i1 %67, label %68, label %70

68:                                               ; preds = %62
  %69 = tail call i64 @rb_big_minus(i64 %rawArg_n, i64 5) #19
  br label %sorbet_rb_int_minus.exit118

70:                                               ; preds = %62, %56
  %71 = tail call i64 @rb_num_coerce_bin(i64 %rawArg_n, i64 5, i64 45) #19
  br label %sorbet_rb_int_minus.exit118

sorbet_rb_int_minus.exit118:                      ; preds = %48, %52, %68, %70
  %72 = phi i64 [ %71, %70 ], [ %69, %68 ], [ %55, %52 ], [ %51, %48 ]
  store i64 %72, i64* %callArgsAddr, align 8
  %73 = tail call i32 @ruby_stack_check() #19
  %directSendResult75 = call i64 @func_HasFib.fib(i32 1, i64* nonnull %callArgsAddr, i64 %selfRaw)
  %74 = and i64 %directSendResult, 1
  %75 = icmp eq i64 %74, 0
  store i64 %directSendResult75, i64* %callArgsAddr, align 8
  br i1 %75, label %"slowSymCallIntrinsic_+", label %"fastSymCallIntrinsic_+", !prof !17, !misexpect !18

"slowSymCallIntrinsic_+":                         ; preds = %sorbet_rb_int_minus.exit118
  %76 = call i64 @rb_funcallv(i64 %directSendResult, i64 %"rubyId_+", i32 1, i64* nonnull %callArgsAddr) #19
  br label %BB4

"fastSymCallIntrinsic_+":                         ; preds = %sorbet_rb_int_minus.exit118
  %77 = and i64 %directSendResult75, 1
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %88, label %79, !prof !17

79:                                               ; preds = %"fastSymCallIntrinsic_+"
  %80 = add nsw i64 %directSendResult75, -1
  %81 = tail call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %directSendResult, i64 %80) #19
  %82 = extractvalue { i64, i1 } %81, 1
  %83 = extractvalue { i64, i1 } %81, 0
  br i1 %82, label %84, label %BB4

84:                                               ; preds = %79
  %85 = ashr i64 %83, 1
  %86 = xor i64 %85, -9223372036854775808
  %87 = tail call i64 @rb_int2big(i64 %86) #19, !noalias !21
  br label %BB4

88:                                               ; preds = %"fastSymCallIntrinsic_+"
  %89 = and i64 %directSendResult75, 7
  %90 = icmp ne i64 %89, 0
  %91 = and i64 %directSendResult75, -9
  %92 = icmp eq i64 %91, 0
  %93 = or i1 %90, %92
  br i1 %93, label %102, label %94

94:                                               ; preds = %88
  %95 = inttoptr i64 %directSendResult75 to %struct.RBasic*
  %96 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %95, i64 0, i32 0
  %97 = load i64, i64* %96, align 8, !tbaa !0, !noalias !21
  %98 = and i64 %97, 31
  %99 = icmp eq i64 %98, 10
  br i1 %99, label %100, label %102

100:                                              ; preds = %94
  %101 = tail call i64 @rb_big_plus(i64 %directSendResult75, i64 %directSendResult) #19, !noalias !21
  br label %BB4

102:                                              ; preds = %94, %88
  %103 = and i64 %directSendResult, 3
  %104 = icmp eq i64 %103, 2
  br i1 %104, label %117, label %105

105:                                              ; preds = %102
  %106 = and i64 %directSendResult, 7
  %107 = icmp ne i64 %106, 0
  %108 = and i64 %directSendResult, -9
  %109 = icmp eq i64 %108, 0
  %110 = or i1 %107, %109
  br i1 %110, label %157, label %111

111:                                              ; preds = %105
  %112 = inttoptr i64 %directSendResult to %struct.RBasic*
  %113 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %112, i64 0, i32 0
  %114 = load i64, i64* %113, align 8, !tbaa !0, !noalias !21
  %115 = and i64 %114, 31
  %116 = icmp eq i64 %115, 4
  br i1 %116, label %117, label %157

117:                                              ; preds = %111, %102
  %118 = ashr i64 %directSendResult, 1
  %119 = sitofp i64 %118 to double
  %120 = and i64 %directSendResult75, 3
  %121 = icmp eq i64 %120, 2
  br i1 %121, label %122, label %133

122:                                              ; preds = %117
  %123 = icmp eq i64 %directSendResult75, -9223372036854775806
  br i1 %123, label %rb_float_value_inline.exit.i, label %124

124:                                              ; preds = %122
  %125 = lshr i64 %directSendResult75, 63
  %126 = sub nuw nsw i64 2, %125
  %127 = and i64 %directSendResult75, 4
  %128 = or i64 %126, %127
  %129 = lshr i64 %directSendResult75, 3
  %130 = shl nuw i64 %128, 61
  %131 = or i64 %130, %129
  %132 = bitcast i64 %131 to double
  br label %rb_float_value_inline.exit.i

133:                                              ; preds = %117
  %134 = inttoptr i64 %directSendResult75 to %struct.RFloat*
  %135 = getelementptr inbounds %struct.RFloat, %struct.RFloat* %134, i64 0, i32 1
  %136 = load double, double* %135, align 8, !tbaa !24, !noalias !21
  br label %rb_float_value_inline.exit.i

rb_float_value_inline.exit.i:                     ; preds = %133, %124, %122
  %137 = phi double [ %136, %133 ], [ %132, %124 ], [ 0.000000e+00, %122 ]
  %138 = fadd double %137, %119
  %139 = bitcast double %138 to i64
  %140 = icmp eq i64 %139, 3458764513820540928
  br i1 %140, label %155, label %141

141:                                              ; preds = %rb_float_value_inline.exit.i
  %142 = lshr i64 %139, 60
  %143 = trunc i64 %142 to i32
  %144 = and i32 %143, 7
  %145 = add nsw i32 %144, -3
  %146 = icmp ugt i32 %145, 1
  br i1 %146, label %153, label %147

147:                                              ; preds = %141
  %148 = shl i64 %139, 3
  %149 = lshr i64 %139, 61
  %150 = and i64 %149, 4
  %151 = or i64 %148, %150
  %152 = or i64 %151, 2
  br label %BB4

153:                                              ; preds = %141
  %154 = icmp eq i64 %139, 0
  br i1 %154, label %BB4, label %155

155:                                              ; preds = %153, %rb_float_value_inline.exit.i
  %156 = tail call i64 @rb_float_new_in_heap(double %138) #19, !noalias !21
  br label %BB4

157:                                              ; preds = %111, %105
  br i1 %93, label %166, label %158

158:                                              ; preds = %157
  %159 = inttoptr i64 %directSendResult75 to %struct.RBasic*
  %160 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %159, i64 0, i32 0
  %161 = load i64, i64* %160, align 8, !tbaa !0, !noalias !21
  %162 = and i64 %161, 31
  %163 = icmp eq i64 %162, 14
  br i1 %163, label %164, label %166

164:                                              ; preds = %158
  %165 = tail call i64 @rb_complex_plus(i64 %directSendResult75, i64 %directSendResult) #19, !noalias !21
  br label %BB4

166:                                              ; preds = %158, %157
  %167 = tail call i64 @rb_num_coerce_bin(i64 %directSendResult, i64 %directSendResult75, i64 43) #19, !noalias !21
  br label %BB4
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_<"() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_<", i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @"rubyIdPrecomputed_<", align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_-() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_-, i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @rubyIdPrecomputed_-, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @"Constr_rubyIdPrecomputed_+"() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @"str_+", i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @"rubyIdPrecomputed_+", align 8
  ret void
}

; Function Attrs: ssp
define internal i64 @"func_HasFib.<static-init>$block_1"(i64 %firstYieldArgRaw, i64 %captures, i32 %argc, i64* nocapture readonly %argArray, i64 %blockArg) #14 {
functionEntryInitializers:
  %callArgs = alloca [2 x i64], align 8
  %rubyId_n = load i64, i64* @rubyIdPrecomputed_n, align 8
  %rubyId_params = load i64, i64* @rubyIdPrecomputed_params, align 8
  %rubyId_returns = load i64, i64* @rubyIdPrecomputed_returns, align 8
  %arrayExpansionSizeGuard = icmp eq i32 %argc, 1
  br i1 %arrayExpansionSizeGuard, label %argArrayExpandArrayTest, label %fillRequiredArgs

argArrayExpandArrayTest:                          ; preds = %functionEntryInitializers
  %arg1_maybeExpandToFullArgs = load i64, i64* %argArray, align 8
  %0 = and i64 %arg1_maybeExpandToFullArgs, 7
  %1 = icmp ne i64 %0, 0
  %2 = and i64 %arg1_maybeExpandToFullArgs, -9
  %3 = icmp eq i64 %2, 0
  %4 = or i1 %1, %3
  br i1 %4, label %fillRequiredArgs, label %sorbet_isa_Array.exit

sorbet_isa_Array.exit:                            ; preds = %argArrayExpandArrayTest
  %5 = inttoptr i64 %arg1_maybeExpandToFullArgs to %struct.RBasic*
  %6 = getelementptr inbounds %struct.RBasic, %struct.RBasic* %5, i64 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !0
  %8 = and i64 %7, 33554463
  %9 = icmp eq i64 %8, 33554439
  br i1 %9, label %10, label %fillRequiredArgs

10:                                               ; preds = %sorbet_isa_Array.exit
  tail call void @rb_ary_detransient(i64 %arg1_maybeExpandToFullArgs) #19
  br label %fillRequiredArgs

fillRequiredArgs:                                 ; preds = %sorbet_isa_Array.exit, %argArrayExpandArrayTest, %10, %functionEntryInitializers
  %rawSym = tail call i64 @rb_id2sym(i64 %rubyId_n)
  %callArgsAddr = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 0
  store i64 %rawSym, i64* %callArgsAddr, align 8
  %11 = load i64, i64* @rb_cInteger, align 8
  %callArgsAddr12 = getelementptr inbounds [2 x i64], [2 x i64]* %callArgs, i64 0, i64 1
  store i64 %11, i64* %callArgsAddr12, align 8
  %12 = tail call i64 @rb_hash_new() #19, !noalias !27
  call void @rb_hash_bulk_insert(i64 2, i64* nonnull %callArgsAddr, i64 %12) #19
  store i64 %12, i64* %callArgsAddr, align 8
  %13 = inttoptr i64 %captures to %struct.RTypedData*
  %14 = getelementptr inbounds %struct.RTypedData, %struct.RTypedData* %13, i64 0, i32 3
  %15 = bitcast i8** %14 to %struct.sorbet_Closure**
  %16 = load %struct.sorbet_Closure*, %struct.sorbet_Closure** %15, align 8, !tbaa !13
  %17 = getelementptr inbounds %struct.sorbet_Closure, %struct.sorbet_Closure* %16, i64 0, i32 1, i64 0
  %18 = load i64, i64* %17, align 8
  %19 = call i64 @rb_funcallv(i64 %18, i64 %rubyId_params, i32 1, i64* nonnull %callArgsAddr) #19
  store i64 %11, i64* %callArgsAddr, align 8
  %20 = call i64 @rb_funcallv(i64 %19, i64 %rubyId_returns, i32 1, i64* nonnull %callArgsAddr) #19
  ret i64 %20
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_final() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str_final, i64 0, i64 0), i64 5) #19
  store i64 %0, i64* @rubyIdPrecomputed_final, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_sig() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i64 3) #19
  store i64 %0, i64* @rubyIdPrecomputed_sig, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_n() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str_n, i64 0, i64 0), i64 1) #19
  store i64 %0, i64* @rubyIdPrecomputed_n, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_params() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_params, i64 0, i64 0), i64 6) #19
  store i64 %0, i64* @rubyIdPrecomputed_params, align 8
  ret void
}

; Function Attrs: nounwind ssp
define internal void @Constr_rubyIdPrecomputed_returns() #11 {
constr:
  %0 = tail call i64 @rb_intern2(i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_returns, i64 0, i64 0), i64 7) #19
  store i64 %0, i64* @rubyIdPrecomputed_returns, align 8
  ret void
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #15

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #15

; Function Attrs: cold minsize noreturn nounwind sspreq
define internal fastcc void @Init_test_testdata_ruby_benchmark_app_fib.cold.1(i64 %0) unnamed_addr #16 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(HasFib)", i64 0, i64 0)) #19
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_HasFib.fib.cold.1(i64 %rawArg_n) unnamed_addr #17 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %rawArg_n, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @str_sig, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @str_Integer, i64 0, i64 0))
  unreachable
}

; Function Attrs: cold minsize noreturn nounwind sspreq uwtable
define internal fastcc void @func_HasFib.fib.cold.2(i64 %selfRaw) unnamed_addr #17 {
newFuncRoot:
  tail call fastcc void @sorbet_cast_failure(i64 %selfRaw, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str_cast, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @"str_T.class_of(HasFib)", i64 0, i64 0))
  unreachable
}

; Function Attrs: nounwind willreturn
declare void @llvm.assume(i1) #18

; Function Attrs: ssp
define linkonce void @const_recompute_HasFib() local_unnamed_addr #14 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str_HasFib, i64 0, i64 0), i64 6)
  store i64 %1, i64* @guarded_const_HasFib, align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  store i64 %2, i64* @guard_epoch_HasFib, align 8
  ret void
}

; Function Attrs: ssp
define linkonce void @"const_recompute_T::Sig::WithoutRuntime"() local_unnamed_addr #14 {
  %1 = tail call fastcc i64 @sorbet_getConstant(i8* getelementptr inbounds ([23 x i8], [23 x i8]* @"str_T::Sig::WithoutRuntime", i64 0, i64 0), i64 22)
  store i64 %1, i64* @"guarded_const_T::Sig::WithoutRuntime", align 8
  %2 = load i64, i64* @ruby_vm_global_constant_state, align 8, !tbaa !10
  store i64 %2, i64* @"guard_epoch_T::Sig::WithoutRuntime", align 8
  ret void
}

attributes #0 = { nounwind ssp uwtable }
attributes #1 = { "addedToSilenceEmptyAttrsError" }
attributes #2 = { noinline nounwind ssp uwtable }
attributes #3 = { argmemonly nofree nounwind readonly }
attributes #4 = { noreturn }
attributes #5 = { nounwind readnone }
attributes #6 = { cold minsize noreturn nounwind optsize ssp uwtable }
attributes #7 = { noreturn nounwind ssp uwtable }
attributes #8 = { inaccessiblememonly "addedToSilenceEmptyAttrsError" }
attributes #9 = { norecurse nounwind readnone ssp uwtable }
attributes #10 = { nounwind readnone speculatable willreturn }
attributes #11 = { nounwind ssp }
attributes #12 = { nounwind sspreq }
attributes #13 = { nounwind sspreq uwtable }
attributes #14 = { ssp }
attributes #15 = { argmemonly nounwind willreturn }
attributes #16 = { cold minsize noreturn nounwind sspreq }
attributes #17 = { cold minsize noreturn nounwind sspreq uwtable }
attributes #18 = { nounwind willreturn }
attributes #19 = { nounwind }
attributes #20 = { noreturn nounwind }
attributes #21 = { noinline }

!0 = !{!1, !2, i64 0}
!1 = !{!"RBasic", !2, i64 0, !2, i64 8}
!2 = !{!"long", !3, i64 0}
!3 = !{!"omnipotent char", !4, i64 0}
!4 = !{!"Simple C/C++ TBAA"}
!5 = !{!3, !3, i64 0}
!6 = !{!2, !2, i64 0}
!7 = !{!1, !2, i64 8}
!8 = !{!9, !9, i64 0}
!9 = !{!"int", !3, i64 0}
!10 = !{!11, !11, i64 0}
!11 = !{!"long long", !3, i64 0}
!12 = !{!"branch_weights", i32 10000, i32 1}
!13 = !{!14, !15, i64 32}
!14 = !{!"RTypedData", !1, i64 0, !15, i64 16, !2, i64 24, !15, i64 32}
!15 = !{!"any pointer", !3, i64 0}
!16 = !{!"branch_weights", i32 1073205, i32 2146410443}
!17 = !{!"branch_weights", i32 1, i32 2000}
!18 = !{!"misexpect", i64 0, i64 2000, i64 1}
!19 = !{!"branch_weights", i32 4000000, i32 4001}
!20 = !{!"misexpect", i64 1, i64 2000, i64 1}
!21 = !{!22}
!22 = distinct !{!22, !23, !"sorbet_rb_int_plus: argument 0"}
!23 = distinct !{!23, !"sorbet_rb_int_plus"}
!24 = !{!25, !26, i64 16}
!25 = !{!"RFloat", !1, i64 0, !26, i64 16}
!26 = !{!"double", !3, i64 0}
!27 = !{!28}
!28 = distinct !{!28, !29, !"sorbet_buildHashIntrinsic: argument 0"}
!29 = distinct !{!29, !"sorbet_buildHashIntrinsic"}
